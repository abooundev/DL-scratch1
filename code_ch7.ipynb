{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파일 설명\n",
    "| 파일명 | 파일 용도 | 관련 절 | 페이지 |\n",
    "|:--   |:--      |:--    |:--      |\n",
    "| apply_filter.py | lena_gray.png 파일에 필터를 적용합니다. |  |  |\n",
    "| gradient_check.py | SimpleCovNet이 기울기를 올바로 계산하는지 확인합니다. |  |  |\n",
    "| params.pkl | 미리 학습된 가중치 값들입니다. |  |  |\n",
    "| simple_convnet.py | “Convolution-ReLU-Pooling-Affine-ReLU-Affine-Softmax” 순으로 흐르는 단순한 합성곱 신경망(CNN)입니다. | 7.5 CNN 구현하기 | 251 |\n",
    "| train_convnet.py | SimpleConvNet으로 MNIST 데이터셋을 학습합니다. | 7.5 CNN 구현하기 | 254 |\n",
    "| visualize_filter.py | 합성곱 1번째 층의 가중치를 학습 전과 후로 나눠 시각화해봅니다. 이미 학습된 가중치 값(params.pkl)을 읽어서 사용하므로 학습 과정은 생략됩니다. | 7.6.1 1번째 층의 가중치 시각화하기 | 254 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple_convnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class SimpleConvNet:\n",
    "    \"\"\"단순한 합성곱 신경망\n",
    "    \n",
    "    conv - relu - pool - affine - relu - affine - softmax\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : 입력 크기（MNIST의 경우엔 784）\n",
    "    hidden_size_list : 각 은닉층의 뉴런 수를 담은 리스트（e.g. [100, 100, 100]）\n",
    "    output_size : 출력 크기（MNIST의 경우엔 10）\n",
    "    activation : 활성화 함수 - 'relu' 혹은 'sigmoid'\n",
    "    weight_init_std : 가중치의 표준편차 지정（e.g. 0.01）\n",
    "        'relu'나 'he'로 지정하면 'He 초깃값'으로 설정\n",
    "        'sigmoid'나 'xavier'로 지정하면 'Xavier 초깃값'으로 설정\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"손실 함수를 구한다.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다（수치미분）.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다(오차역전파법).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_convnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "#from simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3004019847865367\n",
      "=== epoch:1, train acc:0.209, test acc:0.206 ===\n",
      "train loss:2.297608101698613\n",
      "train loss:2.2931956002171034\n",
      "train loss:2.286766898545858\n",
      "train loss:2.274504458979153\n",
      "train loss:2.269881151900904\n",
      "train loss:2.244082377057742\n",
      "train loss:2.2269853763760334\n",
      "train loss:2.1943206493658445\n",
      "train loss:2.2044455615203473\n",
      "train loss:2.178715493412201\n",
      "train loss:2.1430846960981023\n",
      "train loss:2.101173415668006\n",
      "train loss:2.044079889290397\n",
      "train loss:1.9865180559222233\n",
      "train loss:1.9063349028249166\n",
      "train loss:1.8313301527551127\n",
      "train loss:1.7224218010457768\n",
      "train loss:1.6622624769357597\n",
      "train loss:1.7017549863431158\n",
      "train loss:1.5208253061450585\n",
      "train loss:1.4550695711372421\n",
      "train loss:1.4178181898165465\n",
      "train loss:1.2924767367198233\n",
      "train loss:1.2694233183974424\n",
      "train loss:1.1847973230453406\n",
      "train loss:1.1283735852083314\n",
      "train loss:1.0610988018668268\n",
      "train loss:0.9531284835301389\n",
      "train loss:0.8530996710324645\n",
      "train loss:0.8271287792467742\n",
      "train loss:0.7322805924295678\n",
      "train loss:0.7636907729686826\n",
      "train loss:0.6242700847823529\n",
      "train loss:0.731079391397833\n",
      "train loss:0.6482881143519339\n",
      "train loss:0.6238615016839301\n",
      "train loss:0.6470825040110273\n",
      "train loss:0.693880307508756\n",
      "train loss:0.7406917273946612\n",
      "train loss:0.5096125805657451\n",
      "train loss:0.710341900646604\n",
      "train loss:0.5755150625501962\n",
      "train loss:0.9086824070652227\n",
      "train loss:0.6724137413224637\n",
      "train loss:0.5224899295266201\n",
      "train loss:0.5683195053050712\n",
      "train loss:0.544223570648893\n",
      "train loss:0.5575781437790873\n",
      "train loss:0.5321179148746742\n",
      "train loss:0.5706576841570236\n",
      "train loss:0.5861524966049315\n",
      "train loss:0.6768982226553759\n",
      "train loss:0.48439414757920995\n",
      "train loss:0.5686595553311118\n",
      "train loss:0.7201294380189287\n",
      "train loss:0.4887756019098366\n",
      "train loss:0.3976383414635649\n",
      "train loss:0.5588783690986602\n",
      "train loss:0.33789028816828603\n",
      "train loss:0.6303838924166739\n",
      "train loss:0.7165405274522968\n",
      "train loss:0.5511716229651906\n",
      "train loss:0.4766793896463239\n",
      "train loss:0.45506935198163717\n",
      "train loss:0.49915594359985355\n",
      "train loss:0.4311489155132751\n",
      "train loss:0.4839792541015467\n",
      "train loss:0.5487097499406396\n",
      "train loss:0.507160184238169\n",
      "train loss:0.40394304751902077\n",
      "train loss:0.42946470382371893\n",
      "train loss:0.5231814474746639\n",
      "train loss:0.389041371204063\n",
      "train loss:0.44479968701123873\n",
      "train loss:0.45525688936267694\n",
      "train loss:0.5538308714591156\n",
      "train loss:0.40875245746397054\n",
      "train loss:0.3069523792962785\n",
      "train loss:0.3496007896879154\n",
      "train loss:0.3666607089390918\n",
      "train loss:0.36543439967357777\n",
      "train loss:0.35242999775433625\n",
      "train loss:0.3714481750178878\n",
      "train loss:0.4763518417469599\n",
      "train loss:0.37489718958737533\n",
      "train loss:0.34951325978212777\n",
      "train loss:0.4207388659952435\n",
      "train loss:0.4245748614572964\n",
      "train loss:0.38092872183670545\n",
      "train loss:0.4169395295251326\n",
      "train loss:0.44624306254496643\n",
      "train loss:0.4005850188447808\n",
      "train loss:0.3075209292026699\n",
      "train loss:0.3355801369991238\n",
      "train loss:0.4219036206949266\n",
      "train loss:0.39265043401809974\n",
      "train loss:0.3403378420898694\n",
      "train loss:0.2701673821490577\n",
      "train loss:0.42554020206499027\n",
      "train loss:0.3889027731159394\n",
      "train loss:0.32046844186097717\n",
      "train loss:0.435122577267875\n",
      "train loss:0.56635138237254\n",
      "train loss:0.35787250709431573\n",
      "train loss:0.2894028680846339\n",
      "train loss:0.32990815223821957\n",
      "train loss:0.2859544665035424\n",
      "train loss:0.3828807866823494\n",
      "train loss:0.3868533191423155\n",
      "train loss:0.6198088214782023\n",
      "train loss:0.4779238483137454\n",
      "train loss:0.4203585006113633\n",
      "train loss:0.7907807685230346\n",
      "train loss:0.3887991065190175\n",
      "train loss:0.534094453395059\n",
      "train loss:0.3212578788039865\n",
      "train loss:0.3037849155101366\n",
      "train loss:0.499588179764592\n",
      "train loss:0.3177750692286535\n",
      "train loss:0.4277499048440234\n",
      "train loss:0.2975606017647161\n",
      "train loss:0.4058140679222941\n",
      "train loss:0.40761621213728183\n",
      "train loss:0.3170523709075968\n",
      "train loss:0.2923690694190199\n",
      "train loss:0.31088176114697114\n",
      "train loss:0.26942855535558463\n",
      "train loss:0.3396942333372529\n",
      "train loss:0.3205108107112346\n",
      "train loss:0.38547872500724073\n",
      "train loss:0.27304491957403276\n",
      "train loss:0.4242552774768319\n",
      "train loss:0.3974733430737221\n",
      "train loss:0.4031230669185917\n",
      "train loss:0.5167140410807057\n",
      "train loss:0.47721572515174215\n",
      "train loss:0.3642170715286344\n",
      "train loss:0.4943442874968411\n",
      "train loss:0.267297432156377\n",
      "train loss:0.32183369940840933\n",
      "train loss:0.2930110258918955\n",
      "train loss:0.3227452036649213\n",
      "train loss:0.3893573323459507\n",
      "train loss:0.3957316688898949\n",
      "train loss:0.26427380700955144\n",
      "train loss:0.46555716715014084\n",
      "train loss:0.344937370273246\n",
      "train loss:0.2701388751958666\n",
      "train loss:0.2886223219560191\n",
      "train loss:0.31540650708778006\n",
      "train loss:0.3542189010951293\n",
      "train loss:0.3270095580110667\n",
      "train loss:0.29217716076414013\n",
      "train loss:0.3094252878610753\n",
      "train loss:0.2348527209725189\n",
      "train loss:0.3883586263703521\n",
      "train loss:0.4164909303137726\n",
      "train loss:0.32288173214337307\n",
      "train loss:0.3834309208889672\n",
      "train loss:0.4286473703533953\n",
      "train loss:0.24994383067700324\n",
      "train loss:0.36148426776218456\n",
      "train loss:0.4640516263559579\n",
      "train loss:0.32481007139387474\n",
      "train loss:0.22078258877923293\n",
      "train loss:0.24025159367816562\n",
      "train loss:0.20881893178240243\n",
      "train loss:0.4234405272818367\n",
      "train loss:0.1506137495820271\n",
      "train loss:0.4040433145969115\n",
      "train loss:0.1864499908194887\n",
      "train loss:0.41329304171516795\n",
      "train loss:0.4464943637029463\n",
      "train loss:0.4390535042811778\n",
      "train loss:0.3200702336131505\n",
      "train loss:0.3259532526588486\n",
      "train loss:0.348006030154186\n",
      "train loss:0.28476628065239823\n",
      "train loss:0.32279537254088964\n",
      "train loss:0.3170774101728192\n",
      "train loss:0.3967895277975828\n",
      "train loss:0.2654410177437299\n",
      "train loss:0.4664718570960077\n",
      "train loss:0.341830041599582\n",
      "train loss:0.30949948398735194\n",
      "train loss:0.350328812991987\n",
      "train loss:0.2720722775293734\n",
      "train loss:0.2729976452019009\n",
      "train loss:0.3449681117897946\n",
      "train loss:0.2260454665238062\n",
      "train loss:0.2502218698531183\n",
      "train loss:0.23251286802802767\n",
      "train loss:0.364658385237433\n",
      "train loss:0.44551250258048997\n",
      "train loss:0.18318367808522268\n",
      "train loss:0.27680706997221494\n",
      "train loss:0.14130440389166174\n",
      "train loss:0.34814773859292947\n",
      "train loss:0.3264290432828322\n",
      "train loss:0.5100348903105197\n",
      "train loss:0.26922992429443954\n",
      "train loss:0.5468373315198211\n",
      "train loss:0.3723830567912249\n",
      "train loss:0.3927351790390772\n",
      "train loss:0.24998466857915935\n",
      "train loss:0.3314434539034212\n",
      "train loss:0.17664940352226885\n",
      "train loss:0.37611208265498447\n",
      "train loss:0.3593731955665727\n",
      "train loss:0.33511370051762684\n",
      "train loss:0.36343098245198635\n",
      "train loss:0.2416969780427956\n",
      "train loss:0.3216766786306451\n",
      "train loss:0.3314622585067257\n",
      "train loss:0.23431840968816228\n",
      "train loss:0.40468266337764824\n",
      "train loss:0.1794761091114921\n",
      "train loss:0.2187513139122639\n",
      "train loss:0.4528756422110051\n",
      "train loss:0.3369913251092311\n",
      "train loss:0.3896480277672616\n",
      "train loss:0.343856496358142\n",
      "train loss:0.5111029509733408\n",
      "train loss:0.38860446935783344\n",
      "train loss:0.13129396230867432\n",
      "train loss:0.2508481122312109\n",
      "train loss:0.26064831237857605\n",
      "train loss:0.234491746355723\n",
      "train loss:0.24736206790172638\n",
      "train loss:0.22706827557877407\n",
      "train loss:0.1470096048747704\n",
      "train loss:0.19348256221994156\n",
      "train loss:0.2539628042846289\n",
      "train loss:0.3614172099194455\n",
      "train loss:0.2049774484057233\n",
      "train loss:0.2859194226746585\n",
      "train loss:0.29376409014239074\n",
      "train loss:0.1920818832958924\n",
      "train loss:0.26004647514475276\n",
      "train loss:0.1759468833496132\n",
      "train loss:0.24405371005711315\n",
      "train loss:0.2094787655261362\n",
      "train loss:0.2564384739150592\n",
      "train loss:0.43347215089228364\n",
      "train loss:0.30838155269603706\n",
      "train loss:0.2771488942252221\n",
      "train loss:0.26269321933331286\n",
      "train loss:0.36247567239961387\n",
      "train loss:0.26960923573716356\n",
      "train loss:0.2536042157227643\n",
      "train loss:0.2794146457745697\n",
      "train loss:0.39634116912659956\n",
      "train loss:0.3417633389264862\n",
      "train loss:0.29295579166170105\n",
      "train loss:0.20068836282303618\n",
      "train loss:0.20618346826250275\n",
      "train loss:0.3752812267987735\n",
      "train loss:0.3402867726346453\n",
      "train loss:0.34032125608854863\n",
      "train loss:0.16632352065868805\n",
      "train loss:0.16848747378017792\n",
      "train loss:0.33566512372688123\n",
      "train loss:0.15827428964090695\n",
      "train loss:0.25529169586189004\n",
      "train loss:0.3737130491903013\n",
      "train loss:0.09763126059134036\n",
      "train loss:0.1886837624703769\n",
      "train loss:0.3171865327932944\n",
      "train loss:0.18353090873855316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.19863971157938903\n",
      "train loss:0.3213823412218126\n",
      "train loss:0.255686359131368\n",
      "train loss:0.19149565671478347\n",
      "train loss:0.17595008404153237\n",
      "train loss:0.2975947341762547\n",
      "train loss:0.26334227693777\n",
      "train loss:0.3127449270989916\n",
      "train loss:0.1394471890554646\n",
      "train loss:0.3118631887481848\n",
      "train loss:0.24242354735886568\n",
      "train loss:0.17136080729167472\n",
      "train loss:0.2374457179616342\n",
      "train loss:0.23160677532830623\n",
      "train loss:0.3812247210605883\n",
      "train loss:0.23260835210862654\n",
      "train loss:0.35198720219253055\n",
      "train loss:0.2895613541872359\n",
      "train loss:0.3076062877124621\n",
      "train loss:0.38741633459909935\n",
      "train loss:0.2892990189199004\n",
      "train loss:0.20380245905326166\n",
      "train loss:0.3727469739030642\n",
      "train loss:0.20042622270143046\n",
      "train loss:0.2900935110976566\n",
      "train loss:0.18458827880332165\n",
      "train loss:0.3655218216264726\n",
      "train loss:0.26557214938027324\n",
      "train loss:0.21900722734938674\n",
      "train loss:0.2861722765608901\n",
      "train loss:0.17617900354281485\n",
      "train loss:0.29457416214271626\n",
      "train loss:0.18883475527532287\n",
      "train loss:0.4003509031355829\n",
      "train loss:0.20124661231058383\n",
      "train loss:0.2913867970807248\n",
      "train loss:0.20391440291900256\n",
      "train loss:0.25490605240432096\n",
      "train loss:0.3045980874099341\n",
      "train loss:0.28531765104012663\n",
      "train loss:0.14828941759894188\n",
      "train loss:0.2793719670145766\n",
      "train loss:0.28208451374213533\n",
      "train loss:0.24537028489702473\n",
      "train loss:0.22919443327120753\n",
      "train loss:0.2068825354252105\n",
      "train loss:0.2454742902042918\n",
      "train loss:0.2798847426747944\n",
      "train loss:0.2127366994725971\n",
      "train loss:0.18088047899322582\n",
      "train loss:0.28891569616988105\n",
      "train loss:0.3715095546691812\n",
      "train loss:0.21898826718076836\n",
      "train loss:0.3112068152533263\n",
      "train loss:0.2716427425590559\n",
      "train loss:0.15921466434053957\n",
      "train loss:0.18526515918108263\n",
      "train loss:0.371753575254891\n",
      "train loss:0.18074625714601747\n",
      "train loss:0.1606905628143545\n",
      "train loss:0.2106674415698425\n",
      "train loss:0.15945238699687952\n",
      "train loss:0.27665872140968545\n",
      "train loss:0.18160600000820448\n",
      "train loss:0.24743633546652988\n",
      "train loss:0.12951921326007826\n",
      "train loss:0.19278628404467238\n",
      "train loss:0.22034928435240642\n",
      "train loss:0.15384557607777466\n",
      "train loss:0.2446075069694344\n",
      "train loss:0.167141699695123\n",
      "train loss:0.19706872283073593\n",
      "train loss:0.24434490956859903\n",
      "train loss:0.1133471246755859\n",
      "train loss:0.157807645263975\n",
      "train loss:0.3056549552137345\n",
      "train loss:0.20948703000019353\n",
      "train loss:0.20699868373476055\n",
      "train loss:0.27748243752235585\n",
      "train loss:0.18063261703409775\n",
      "train loss:0.1732548492760704\n",
      "train loss:0.2776545223960487\n",
      "train loss:0.2258829306372897\n",
      "train loss:0.27358060535409157\n",
      "train loss:0.15627765502633145\n",
      "train loss:0.18945166852067208\n",
      "train loss:0.08861554758378677\n",
      "train loss:0.16199234941869836\n",
      "train loss:0.16708246138809266\n",
      "train loss:0.36237737330656955\n",
      "train loss:0.142324992826913\n",
      "train loss:0.1502470739478578\n",
      "train loss:0.3057275918930832\n",
      "train loss:0.13362875799593488\n",
      "train loss:0.15334066318047918\n",
      "train loss:0.16644838377769397\n",
      "train loss:0.1790310436939087\n",
      "train loss:0.09760928313163321\n",
      "train loss:0.20025461260178304\n",
      "train loss:0.14840446643510585\n",
      "train loss:0.3703850520406426\n",
      "train loss:0.20220352651606388\n",
      "train loss:0.3364755009137068\n",
      "train loss:0.19516754667536693\n",
      "train loss:0.1659188480242169\n",
      "train loss:0.210676215820017\n",
      "train loss:0.19943915697827996\n",
      "train loss:0.12181232833993937\n",
      "train loss:0.13692226317753378\n",
      "train loss:0.19727111577154097\n",
      "train loss:0.25934939536327645\n",
      "train loss:0.24349971690882607\n",
      "train loss:0.1199012483405996\n",
      "train loss:0.13054244247693647\n",
      "train loss:0.1950029424567074\n",
      "train loss:0.1487172721776025\n",
      "train loss:0.4567313932718882\n",
      "train loss:0.31685913567571466\n",
      "train loss:0.22175581818614\n",
      "train loss:0.17880330296081953\n",
      "train loss:0.2238815535616853\n",
      "train loss:0.09298054699447464\n",
      "train loss:0.1274847293119194\n",
      "train loss:0.18375583822012065\n",
      "train loss:0.2213884826311875\n",
      "train loss:0.16341527913845574\n",
      "train loss:0.10638263122945794\n",
      "train loss:0.2774108138433763\n",
      "train loss:0.20027526323045353\n",
      "train loss:0.24448976782092607\n",
      "train loss:0.08347175579313136\n",
      "train loss:0.15274622085573042\n",
      "train loss:0.18664600904273596\n",
      "train loss:0.17958092603830964\n",
      "train loss:0.2647669571510527\n",
      "train loss:0.16705414901492113\n",
      "train loss:0.1603322190077343\n",
      "train loss:0.21536447819869373\n",
      "train loss:0.26034598712544477\n",
      "train loss:0.154039802684397\n",
      "train loss:0.2757752112485507\n",
      "train loss:0.20744828914734292\n",
      "train loss:0.1570675902422386\n",
      "train loss:0.1574265590270983\n",
      "train loss:0.19777955692082913\n",
      "train loss:0.2279752680944264\n",
      "train loss:0.2871082726427768\n",
      "train loss:0.20463111887248583\n",
      "train loss:0.15889639513286205\n",
      "train loss:0.16722416934153297\n",
      "train loss:0.08819207359365677\n",
      "train loss:0.19374820586404579\n",
      "train loss:0.24282860579528281\n",
      "train loss:0.1295837600711213\n",
      "train loss:0.22849830568523732\n",
      "train loss:0.20067733629171172\n",
      "train loss:0.18826869255546635\n",
      "train loss:0.16416427913891637\n",
      "train loss:0.25949777220781167\n",
      "train loss:0.08008464092738951\n",
      "train loss:0.23319557446790753\n",
      "train loss:0.1552918801399011\n",
      "train loss:0.19155563547827179\n",
      "train loss:0.10856138814018179\n",
      "train loss:0.20598361223355888\n",
      "train loss:0.3118516170068412\n",
      "train loss:0.14024913554751162\n",
      "train loss:0.12286956885779465\n",
      "train loss:0.14194175645516238\n",
      "train loss:0.15281217027614116\n",
      "train loss:0.1816279407670822\n",
      "train loss:0.20907636826611511\n",
      "train loss:0.21802659827416407\n",
      "train loss:0.28613521974736233\n",
      "train loss:0.23543428239665373\n",
      "train loss:0.21974161748796753\n",
      "train loss:0.2914906398390992\n",
      "train loss:0.18974929893046266\n",
      "train loss:0.20916240508767264\n",
      "train loss:0.24222558537297112\n",
      "train loss:0.15307594737318758\n",
      "train loss:0.13660168802822756\n",
      "train loss:0.10997789749221785\n",
      "train loss:0.051877369796983805\n",
      "train loss:0.0895619674838267\n",
      "train loss:0.19860390320328428\n",
      "train loss:0.16031241908392022\n",
      "train loss:0.19215526372820768\n",
      "train loss:0.1865113224345307\n",
      "train loss:0.0989127824513203\n",
      "train loss:0.09276945036656867\n",
      "train loss:0.13784255741636264\n",
      "train loss:0.1034219385116306\n",
      "train loss:0.13832264558279792\n",
      "train loss:0.0861425818384244\n",
      "train loss:0.2535938414228289\n",
      "train loss:0.23205826515197864\n",
      "train loss:0.19569278743646418\n",
      "train loss:0.13400455450982032\n",
      "train loss:0.17348185228313898\n",
      "train loss:0.1844994370804468\n",
      "train loss:0.12096270444812841\n",
      "train loss:0.14613398300800928\n",
      "train loss:0.137089590739044\n",
      "train loss:0.07524019573755218\n",
      "train loss:0.15311506155819402\n",
      "train loss:0.16071361963219816\n",
      "train loss:0.20696231399216355\n",
      "train loss:0.15072023390436107\n",
      "train loss:0.06979657969987056\n",
      "train loss:0.1571195100850905\n",
      "train loss:0.12874601278785297\n",
      "train loss:0.1564465709287653\n",
      "train loss:0.18959786252544064\n",
      "train loss:0.1586694909046337\n",
      "train loss:0.2624216350104338\n",
      "train loss:0.18401879511079472\n",
      "train loss:0.10757395272909978\n",
      "train loss:0.24104228965467286\n",
      "train loss:0.16535194890122223\n",
      "train loss:0.2629291761412954\n",
      "train loss:0.238561645897803\n",
      "train loss:0.1902628557701133\n",
      "train loss:0.2702040558187002\n",
      "train loss:0.16940458739955372\n",
      "train loss:0.19436284700026396\n",
      "train loss:0.14941038079725513\n",
      "train loss:0.2768911326055274\n",
      "train loss:0.1730522236566732\n",
      "train loss:0.21640031501849427\n",
      "train loss:0.18085460573163703\n",
      "train loss:0.2580174136147214\n",
      "train loss:0.1063022813825793\n",
      "train loss:0.09677337130398808\n",
      "train loss:0.0842833538578257\n",
      "train loss:0.23029168073828984\n",
      "train loss:0.2362147930058972\n",
      "train loss:0.12755797200803767\n",
      "train loss:0.05896987927069244\n",
      "train loss:0.1340877483309828\n",
      "train loss:0.2055829739221204\n",
      "train loss:0.07527849686860746\n",
      "train loss:0.18860793754772803\n",
      "train loss:0.21617157876731782\n",
      "train loss:0.09937073872590392\n",
      "train loss:0.13977703196887645\n",
      "train loss:0.1472304188064399\n",
      "train loss:0.09765743509619362\n",
      "train loss:0.16986654625087355\n",
      "train loss:0.12560884635878022\n",
      "train loss:0.1262304335937693\n",
      "train loss:0.07977876869648162\n",
      "train loss:0.19375950517242946\n",
      "train loss:0.12599482216545785\n",
      "train loss:0.09454790141812268\n",
      "train loss:0.08151358616638817\n",
      "train loss:0.1435537836507313\n",
      "train loss:0.1240707675279579\n",
      "train loss:0.21871557778750134\n",
      "train loss:0.07082379015342276\n",
      "train loss:0.2116495629858946\n",
      "train loss:0.2811276499189391\n",
      "train loss:0.1017777126502548\n",
      "train loss:0.25852547001779685\n",
      "train loss:0.15239600609947834\n",
      "train loss:0.21798436107997865\n",
      "train loss:0.10593934413602728\n",
      "train loss:0.10655921656549543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.04620780570223425\n",
      "train loss:0.18013138714112442\n",
      "train loss:0.1116460658863217\n",
      "train loss:0.11849371215153263\n",
      "train loss:0.08663039999467902\n",
      "train loss:0.05106796080445099\n",
      "train loss:0.2994382367797389\n",
      "train loss:0.16431702418766417\n",
      "train loss:0.06370640425506097\n",
      "train loss:0.08565143436419236\n",
      "train loss:0.05161129656967937\n",
      "train loss:0.12524172886451773\n",
      "train loss:0.19387018405141823\n",
      "train loss:0.13104989619592897\n",
      "train loss:0.1520410866941322\n",
      "train loss:0.13405827144466087\n",
      "train loss:0.21622784255097297\n",
      "train loss:0.18452933291381232\n",
      "train loss:0.11819069052710303\n",
      "train loss:0.11944825733076576\n",
      "train loss:0.10265275626538994\n",
      "train loss:0.14112141467783995\n",
      "train loss:0.108753633260154\n",
      "train loss:0.1750287002798219\n",
      "train loss:0.04233501598462985\n",
      "train loss:0.1106643299488183\n",
      "train loss:0.07723764107784589\n",
      "train loss:0.16547021020734134\n",
      "train loss:0.14826587530665344\n",
      "train loss:0.09500258364831916\n",
      "train loss:0.1765263111567124\n",
      "train loss:0.1316961852551027\n",
      "train loss:0.1905821496704891\n",
      "train loss:0.1343888749084397\n",
      "train loss:0.07944700784929695\n",
      "train loss:0.07430263624229233\n",
      "train loss:0.11971183215984717\n",
      "train loss:0.11374190837510156\n",
      "train loss:0.15028752220620767\n",
      "train loss:0.13328552314713893\n",
      "train loss:0.19951425723949115\n",
      "train loss:0.1080616255807691\n",
      "train loss:0.10711783965413664\n",
      "train loss:0.28495286637272793\n",
      "train loss:0.05028058215534235\n",
      "train loss:0.05191542134144171\n",
      "train loss:0.06652100512951664\n",
      "train loss:0.14904554192557692\n",
      "train loss:0.06352646714978508\n",
      "train loss:0.07303836559898907\n",
      "train loss:0.08496942779307709\n",
      "train loss:0.18353888930171552\n",
      "train loss:0.06374262480805468\n",
      "train loss:0.06753040402528161\n",
      "train loss:0.12656374308157697\n",
      "train loss:0.25445197630567\n",
      "train loss:0.13548398354610933\n",
      "train loss:0.13760260679408795\n",
      "train loss:0.23340964205192832\n",
      "train loss:0.17141943985105257\n",
      "train loss:0.06537952501551693\n",
      "train loss:0.1937740418709607\n",
      "train loss:0.14665989176375205\n",
      "=== epoch:2, train acc:0.962, test acc:0.953 ===\n",
      "train loss:0.18643108689909116\n",
      "train loss:0.06444420408621199\n",
      "train loss:0.08960737397394941\n",
      "train loss:0.08306563607015051\n",
      "train loss:0.09463218640697443\n",
      "train loss:0.05989141211568774\n",
      "train loss:0.08374946391130575\n",
      "train loss:0.12771002150840827\n",
      "train loss:0.089736834403489\n",
      "train loss:0.04386079641731138\n",
      "train loss:0.14071068803558628\n",
      "train loss:0.15450591378570672\n",
      "train loss:0.1794326290873298\n",
      "train loss:0.11090203521435738\n",
      "train loss:0.23776598295169982\n",
      "train loss:0.07528826917047882\n",
      "train loss:0.15489436878962817\n",
      "train loss:0.2022516353030127\n",
      "train loss:0.1647042644927238\n",
      "train loss:0.12205964197925462\n",
      "train loss:0.1631094979505641\n",
      "train loss:0.1649734062924021\n",
      "train loss:0.09401934140868905\n",
      "train loss:0.10920093304168338\n",
      "train loss:0.17250297506005016\n",
      "train loss:0.10865124385627585\n",
      "train loss:0.1312440014054287\n",
      "train loss:0.10995887649445893\n",
      "train loss:0.08663107018542622\n",
      "train loss:0.09197470068776675\n",
      "train loss:0.11506420898580912\n",
      "train loss:0.10966099925994383\n",
      "train loss:0.06217409191219612\n",
      "train loss:0.15747617119810398\n",
      "train loss:0.14590531486728694\n",
      "train loss:0.18222513738242338\n",
      "train loss:0.0653165024422284\n",
      "train loss:0.1252385305904524\n",
      "train loss:0.0841858005008781\n",
      "train loss:0.09282696759399282\n",
      "train loss:0.06776437175467574\n",
      "train loss:0.16697693560423943\n",
      "train loss:0.11511918868121124\n",
      "train loss:0.08139247671609703\n",
      "train loss:0.12070108342684252\n",
      "train loss:0.13477743313894025\n",
      "train loss:0.12503567750378794\n",
      "train loss:0.07772445418403398\n",
      "train loss:0.17406215744054335\n",
      "train loss:0.17421166818660327\n",
      "train loss:0.10208967368978929\n",
      "train loss:0.04489411768128206\n",
      "train loss:0.09427834271057703\n",
      "train loss:0.08480524131743047\n",
      "train loss:0.11624865151923514\n",
      "train loss:0.06822832856490776\n",
      "train loss:0.24975065457300477\n",
      "train loss:0.13708571449287138\n",
      "train loss:0.14294551629028523\n",
      "train loss:0.05687220954439177\n",
      "train loss:0.15248793601710536\n",
      "train loss:0.1367945266828689\n",
      "train loss:0.2194672337668917\n",
      "train loss:0.1361311818039729\n",
      "train loss:0.14595479866075375\n",
      "train loss:0.08305842786918032\n",
      "train loss:0.19240720832565958\n",
      "train loss:0.11788916448075354\n",
      "train loss:0.054157741268926515\n",
      "train loss:0.25274137879997655\n",
      "train loss:0.07149262228706756\n",
      "train loss:0.18071708875436956\n",
      "train loss:0.09589341804471851\n",
      "train loss:0.16138700682628618\n",
      "train loss:0.13859359607685418\n",
      "train loss:0.1933927988822587\n",
      "train loss:0.20036917830491785\n",
      "train loss:0.1213279226897798\n",
      "train loss:0.11478880426406224\n",
      "train loss:0.0878459552043649\n",
      "train loss:0.07681591099982368\n",
      "train loss:0.08425887319343911\n",
      "train loss:0.07963171036144939\n",
      "train loss:0.05462393254617685\n",
      "train loss:0.1261652140853578\n",
      "train loss:0.07655939899273399\n",
      "train loss:0.09987711944768694\n",
      "train loss:0.20081354063771759\n",
      "train loss:0.09047508528727068\n",
      "train loss:0.0934781042437821\n",
      "train loss:0.14623726066603693\n",
      "train loss:0.166923000670401\n",
      "train loss:0.14055871161613542\n",
      "train loss:0.07654643598132554\n",
      "train loss:0.10057002059439388\n",
      "train loss:0.14227792526768168\n",
      "train loss:0.1806724892648421\n",
      "train loss:0.13273720930393737\n",
      "train loss:0.12460888901760118\n",
      "train loss:0.09361452937579096\n",
      "train loss:0.06671182108286614\n",
      "train loss:0.259732299143027\n",
      "train loss:0.1521691314440957\n",
      "train loss:0.05524056724152056\n",
      "train loss:0.05927932050623526\n",
      "train loss:0.21440843406927132\n",
      "train loss:0.10512271946880503\n",
      "train loss:0.11202422880371937\n",
      "train loss:0.055988116258714866\n",
      "train loss:0.1398721410401323\n",
      "train loss:0.18570841937611393\n",
      "train loss:0.1487781688772951\n",
      "train loss:0.10256359807189808\n",
      "train loss:0.20074539369740493\n",
      "train loss:0.3221167662197783\n",
      "train loss:0.07383957217192752\n",
      "train loss:0.1463983270404315\n",
      "train loss:0.07766547069073276\n",
      "train loss:0.17579417475805809\n",
      "train loss:0.18536571556957324\n",
      "train loss:0.21796332977547783\n",
      "train loss:0.06862553109142687\n",
      "train loss:0.09303309275903293\n",
      "train loss:0.131820413834491\n",
      "train loss:0.12841463122184207\n",
      "train loss:0.07638854916813871\n",
      "train loss:0.07584716921730743\n",
      "train loss:0.07505241235902413\n",
      "train loss:0.08700853607332538\n",
      "train loss:0.12602213999692402\n",
      "train loss:0.07899815240512466\n",
      "train loss:0.1126529046982448\n",
      "train loss:0.11749455423705374\n",
      "train loss:0.1480421990628283\n",
      "train loss:0.05584058056085488\n",
      "train loss:0.052387255436630295\n",
      "train loss:0.08977205618804157\n",
      "train loss:0.08672322796020858\n",
      "train loss:0.09413261023647862\n",
      "train loss:0.052696507462491035\n",
      "train loss:0.11580784287535524\n",
      "train loss:0.10933818041393525\n",
      "train loss:0.20129119206307194\n",
      "train loss:0.12074558502088935\n",
      "train loss:0.05733625098391335\n",
      "train loss:0.10735362708433169\n",
      "train loss:0.08034647590256697\n",
      "train loss:0.16227695326298963\n",
      "train loss:0.18388402860888703\n",
      "train loss:0.17642199631536304\n",
      "train loss:0.14026107325359083\n",
      "train loss:0.07513130274428746\n",
      "train loss:0.0807046451705056\n",
      "train loss:0.15400519147719782\n",
      "train loss:0.06890354098480847\n",
      "train loss:0.0709804240097492\n",
      "train loss:0.09253637977856606\n",
      "train loss:0.06782833084562621\n",
      "train loss:0.03758254197842525\n",
      "train loss:0.0655036901247176\n",
      "train loss:0.15745453703512016\n",
      "train loss:0.07079611589810537\n",
      "train loss:0.07408121248013239\n",
      "train loss:0.13599804833841186\n",
      "train loss:0.042159962772879034\n",
      "train loss:0.07524728876447492\n",
      "train loss:0.058483328604467706\n",
      "train loss:0.06241854625992027\n",
      "train loss:0.06808791466352337\n",
      "train loss:0.12961851582295103\n",
      "train loss:0.06515217583298419\n",
      "train loss:0.1011315912027812\n",
      "train loss:0.0982473076097489\n",
      "train loss:0.09024080953287825\n",
      "train loss:0.132975802681502\n",
      "train loss:0.1035971366509342\n",
      "train loss:0.0607684548304535\n",
      "train loss:0.13374595364839137\n",
      "train loss:0.06999555085891584\n",
      "train loss:0.08416252129979135\n",
      "train loss:0.04820113584521134\n",
      "train loss:0.03859287878994986\n",
      "train loss:0.0828290030329824\n",
      "train loss:0.09828705485639073\n",
      "train loss:0.20455060803658953\n",
      "train loss:0.12529741411222747\n",
      "train loss:0.09991968170283894\n",
      "train loss:0.08958359444351659\n",
      "train loss:0.09357665546928302\n",
      "train loss:0.08601803481997852\n",
      "train loss:0.07632675719165785\n",
      "train loss:0.08111494093916001\n",
      "train loss:0.09962796541085854\n",
      "train loss:0.09014531596088224\n",
      "train loss:0.14612798444795758\n",
      "train loss:0.04756233401737507\n",
      "train loss:0.055209149324910854\n",
      "train loss:0.09624302750599792\n",
      "train loss:0.03815294675556162\n",
      "train loss:0.0757941091127449\n",
      "train loss:0.04174182904049349\n",
      "train loss:0.13462302824622094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.05971480891887203\n",
      "train loss:0.06879812888172773\n",
      "train loss:0.03577763753801233\n",
      "train loss:0.07017204553113016\n",
      "train loss:0.034746401859179904\n",
      "train loss:0.1070529453315895\n",
      "train loss:0.21739396203214106\n",
      "train loss:0.11332469183244123\n",
      "train loss:0.24982534083947797\n",
      "train loss:0.08625691254274363\n",
      "train loss:0.11649252353296785\n",
      "train loss:0.04385257988176\n",
      "train loss:0.1410132136865435\n",
      "train loss:0.09724094452823494\n",
      "train loss:0.15185048741567755\n",
      "train loss:0.08468877055634222\n",
      "train loss:0.04901167487056279\n",
      "train loss:0.07570029585794998\n",
      "train loss:0.10168435998819604\n",
      "train loss:0.11115244238049189\n",
      "train loss:0.1352073063648814\n",
      "train loss:0.05263000241317543\n",
      "train loss:0.02432599734919253\n",
      "train loss:0.11526400268944734\n",
      "train loss:0.07707215655446882\n",
      "train loss:0.1727821156306371\n",
      "train loss:0.09747978841273097\n",
      "train loss:0.1464289399229712\n",
      "train loss:0.0943272495661758\n",
      "train loss:0.10176053188128814\n",
      "train loss:0.11861036495790155\n",
      "train loss:0.12932879567569144\n",
      "train loss:0.24406243143490067\n",
      "train loss:0.1087320330384608\n",
      "train loss:0.06214720323691204\n",
      "train loss:0.06740046093613342\n",
      "train loss:0.07967724084925729\n",
      "train loss:0.07317395399928867\n",
      "train loss:0.06588281486617957\n",
      "train loss:0.09595446467150699\n",
      "train loss:0.105355661850666\n",
      "train loss:0.05412705354182105\n",
      "train loss:0.07578159740902791\n",
      "train loss:0.06578333973023623\n",
      "train loss:0.09300021101642239\n",
      "train loss:0.04357610925028232\n",
      "train loss:0.08943517457376263\n",
      "train loss:0.03291102603416857\n",
      "train loss:0.1581724245482853\n",
      "train loss:0.12368987530855341\n",
      "train loss:0.08240262400269\n",
      "train loss:0.08546172424718407\n",
      "train loss:0.07407440945354635\n",
      "train loss:0.05288011658957356\n",
      "train loss:0.051513010288285394\n",
      "train loss:0.0739614421031472\n",
      "train loss:0.10008569686030305\n",
      "train loss:0.16484578101307842\n",
      "train loss:0.08426048345980436\n",
      "train loss:0.10916575544208568\n",
      "train loss:0.07501959179645191\n",
      "train loss:0.06709068708719723\n",
      "train loss:0.05522241672188559\n",
      "train loss:0.03682694706851632\n",
      "train loss:0.08636075003424615\n",
      "train loss:0.12779740956255992\n",
      "train loss:0.14391942381230843\n",
      "train loss:0.08749969064726346\n",
      "train loss:0.08616218611356675\n",
      "train loss:0.06212642281095105\n",
      "train loss:0.05002525554895818\n",
      "train loss:0.043553087826793686\n",
      "train loss:0.126941259951684\n",
      "train loss:0.14236513703066156\n",
      "train loss:0.07090229013956145\n",
      "train loss:0.18746467615319573\n",
      "train loss:0.08428524414744927\n",
      "train loss:0.11006237592322556\n",
      "train loss:0.0416864800726305\n",
      "train loss:0.05077950342573935\n",
      "train loss:0.11433065500736478\n",
      "train loss:0.056171829176623646\n",
      "train loss:0.11081962228475302\n",
      "train loss:0.12317672835880882\n",
      "train loss:0.12572914995237267\n",
      "train loss:0.06615242089281846\n",
      "train loss:0.18717116799498112\n",
      "train loss:0.044136540728051905\n",
      "train loss:0.05138101641462666\n",
      "train loss:0.06969372786475066\n",
      "train loss:0.13883927238557775\n",
      "train loss:0.03868809868417692\n",
      "train loss:0.07781460484563017\n",
      "train loss:0.21058149436148038\n",
      "train loss:0.1175733339067328\n",
      "train loss:0.03310138783390492\n",
      "train loss:0.09446033127453081\n",
      "train loss:0.24319516254966103\n",
      "train loss:0.09914565592252828\n",
      "train loss:0.09401768904585042\n",
      "train loss:0.18536436916935523\n",
      "train loss:0.05820158981936305\n",
      "train loss:0.03408206416822413\n",
      "train loss:0.09287351735941779\n",
      "train loss:0.08450032719766354\n",
      "train loss:0.09990127078463677\n",
      "train loss:0.16153570272532294\n",
      "train loss:0.06718409019169702\n",
      "train loss:0.05744069430487779\n",
      "train loss:0.06245137762876226\n",
      "train loss:0.08914603073960117\n",
      "train loss:0.04724120930420716\n",
      "train loss:0.07589408700129611\n",
      "train loss:0.21881611633073575\n",
      "train loss:0.08447150739261575\n",
      "train loss:0.08868865588108094\n",
      "train loss:0.13522930498988017\n",
      "train loss:0.048220698883644254\n",
      "train loss:0.07464993337842438\n",
      "train loss:0.06160933605084352\n",
      "train loss:0.0880795082135607\n",
      "train loss:0.0731386240314431\n",
      "train loss:0.14837423758218404\n",
      "train loss:0.031963615521897054\n",
      "train loss:0.04958434388385769\n",
      "train loss:0.07565053458429588\n",
      "train loss:0.09792572260845774\n",
      "train loss:0.10604896712509472\n",
      "train loss:0.08212786253510956\n",
      "train loss:0.0299953080726759\n",
      "train loss:0.029658973925624624\n",
      "train loss:0.06752717520879732\n",
      "train loss:0.07404908320040493\n",
      "train loss:0.051087363297648195\n",
      "train loss:0.15293456293883115\n",
      "train loss:0.04855796348859186\n",
      "train loss:0.04865670785016719\n",
      "train loss:0.08001635034054068\n",
      "train loss:0.1912142378365706\n",
      "train loss:0.08862390178547336\n",
      "train loss:0.11131686069428821\n",
      "train loss:0.05477891242009039\n",
      "train loss:0.13433274613988866\n",
      "train loss:0.08904259282442407\n",
      "train loss:0.09956995860763516\n",
      "train loss:0.09586068230761775\n",
      "train loss:0.13574395392380165\n",
      "train loss:0.09234445230036725\n",
      "train loss:0.03406220374283032\n",
      "train loss:0.06076560058881741\n",
      "train loss:0.06194913249304643\n",
      "train loss:0.13289547158303205\n",
      "train loss:0.19299341283912075\n",
      "train loss:0.0804583946949927\n",
      "train loss:0.03659883407506618\n",
      "train loss:0.19670082922973642\n",
      "train loss:0.056265632154672486\n",
      "train loss:0.037071783838113444\n",
      "train loss:0.143520005753617\n",
      "train loss:0.06509595517578722\n",
      "train loss:0.19614386803650372\n",
      "train loss:0.0634444329168161\n",
      "train loss:0.06324484121419797\n",
      "train loss:0.06138410056223138\n",
      "train loss:0.06031195838760164\n",
      "train loss:0.1466655061818487\n",
      "train loss:0.07434058384829657\n",
      "train loss:0.11414885317799885\n",
      "train loss:0.05212058075117093\n",
      "train loss:0.04825076100039124\n",
      "train loss:0.0886506659910099\n",
      "train loss:0.07248464934049044\n",
      "train loss:0.054137343801660125\n",
      "train loss:0.05341636456039911\n",
      "train loss:0.14036155430441877\n",
      "train loss:0.046046928689569826\n",
      "train loss:0.07255566020166454\n",
      "train loss:0.11432209439008595\n",
      "train loss:0.06313544538911785\n",
      "train loss:0.058224925785063865\n",
      "train loss:0.055962700483593045\n",
      "train loss:0.08244618529357883\n",
      "train loss:0.13588234176185165\n",
      "train loss:0.12684393641502495\n",
      "train loss:0.10818120457298878\n",
      "train loss:0.022709078996053737\n",
      "train loss:0.06747593034032441\n",
      "train loss:0.051733978508163796\n",
      "train loss:0.11749773468649223\n",
      "train loss:0.10018168558406997\n",
      "train loss:0.05660592408906634\n",
      "train loss:0.07694177061104716\n",
      "train loss:0.06029335709915627\n",
      "train loss:0.07868778632536022\n",
      "train loss:0.09047017246474308\n",
      "train loss:0.040634475026966745\n",
      "train loss:0.08714720784608615\n",
      "train loss:0.0449673063858538\n",
      "train loss:0.08994394633648733\n",
      "train loss:0.10307980554613115\n",
      "train loss:0.05784263850528944\n",
      "train loss:0.03721205948476245\n",
      "train loss:0.09413712057374106\n",
      "train loss:0.07107246728497155\n",
      "train loss:0.1000700489253591\n",
      "train loss:0.03163626167608225\n",
      "train loss:0.17137130772012668\n",
      "train loss:0.16127695270427192\n",
      "train loss:0.04977533808695382\n",
      "train loss:0.026304656945632533\n",
      "train loss:0.053273515092729\n",
      "train loss:0.09086394568446517\n",
      "train loss:0.06537341156016799\n",
      "train loss:0.02790347711132644\n",
      "train loss:0.06459507612003987\n",
      "train loss:0.0778202716334979\n",
      "train loss:0.08917778776951138\n",
      "train loss:0.09323812284166756\n",
      "train loss:0.07000923985290973\n",
      "train loss:0.059427666271156435\n",
      "train loss:0.1405629388397169\n",
      "train loss:0.03871606294953136\n",
      "train loss:0.052427316456382045\n",
      "train loss:0.06229858316087287\n",
      "train loss:0.020647633415191772\n",
      "train loss:0.06910028586155552\n",
      "train loss:0.0656608031314694\n",
      "train loss:0.12591172482561513\n",
      "train loss:0.046164965631761756\n",
      "train loss:0.08911801584325874\n",
      "train loss:0.11109825739942486\n",
      "train loss:0.026900222679897362\n",
      "train loss:0.04907353353386451\n",
      "train loss:0.06181578555790664\n",
      "train loss:0.06984798437480778\n",
      "train loss:0.1530843916348877\n",
      "train loss:0.08755726572817422\n",
      "train loss:0.05840756828137495\n",
      "train loss:0.026405740860252772\n",
      "train loss:0.03618403684281221\n",
      "train loss:0.19874355147843262\n",
      "train loss:0.06962974931100255\n",
      "train loss:0.11325822328997452\n",
      "train loss:0.026049577433913472\n",
      "train loss:0.11371832646370844\n",
      "train loss:0.05867461888320471\n",
      "train loss:0.07118857151539784\n",
      "train loss:0.04492748367035059\n",
      "train loss:0.10881489806119685\n",
      "train loss:0.08314214014321333\n",
      "train loss:0.03230626679956185\n",
      "train loss:0.04858821733692524\n",
      "train loss:0.11957427106047888\n",
      "train loss:0.05187260570745608\n",
      "train loss:0.12307854911398619\n",
      "train loss:0.037524794391657644\n",
      "train loss:0.039660267135014964\n",
      "train loss:0.151921084349184\n",
      "train loss:0.06394903746283946\n",
      "train loss:0.1398725194584083\n",
      "train loss:0.043477808319508426\n",
      "train loss:0.10662542651909883\n",
      "train loss:0.10244568017678932\n",
      "train loss:0.044975505254274496\n",
      "train loss:0.056332478862868844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.05358023700614168\n",
      "train loss:0.08073361296531345\n",
      "train loss:0.13978978586576457\n",
      "train loss:0.12481495830300965\n",
      "train loss:0.045870334178270085\n",
      "train loss:0.06721751419571141\n",
      "train loss:0.0960072185933571\n",
      "train loss:0.07896411424612966\n",
      "train loss:0.0489681274132314\n",
      "train loss:0.0359873488667342\n",
      "train loss:0.04767411487498592\n",
      "train loss:0.07204757246864008\n",
      "train loss:0.14178612683247158\n",
      "train loss:0.03489845036291455\n",
      "train loss:0.024631983187221484\n",
      "train loss:0.07172887078029327\n",
      "train loss:0.04396177721670722\n",
      "train loss:0.06491133724526006\n",
      "train loss:0.08538998989316708\n",
      "train loss:0.05037681601015507\n",
      "train loss:0.06625485748283794\n",
      "train loss:0.1451434174101261\n",
      "train loss:0.030899403285454513\n",
      "train loss:0.05126409816516054\n",
      "train loss:0.02938789098026107\n",
      "train loss:0.024902718513665503\n",
      "train loss:0.08188706562942126\n",
      "train loss:0.05133330888455118\n",
      "train loss:0.02823777630033404\n",
      "train loss:0.054307381499639845\n",
      "train loss:0.09543911333291322\n",
      "train loss:0.030187585430445224\n",
      "train loss:0.07804485934224925\n",
      "train loss:0.0295985500263316\n",
      "train loss:0.06879093365019295\n",
      "train loss:0.11310050022241995\n",
      "train loss:0.12160439291340301\n",
      "train loss:0.06133126872348825\n",
      "train loss:0.0693384004421094\n",
      "train loss:0.02140459945031161\n",
      "train loss:0.030381683020413414\n",
      "train loss:0.052448615346210196\n",
      "train loss:0.08437713228144657\n",
      "train loss:0.051358913119546844\n",
      "train loss:0.08521496945810446\n",
      "train loss:0.09890040523160971\n",
      "train loss:0.03777141926242848\n",
      "train loss:0.09931009739392566\n",
      "train loss:0.050830399269978725\n",
      "train loss:0.0906668184970853\n",
      "train loss:0.05986764977851682\n",
      "train loss:0.06852329618360073\n",
      "train loss:0.08378221265065502\n",
      "train loss:0.04784929498946834\n",
      "train loss:0.08950578783107252\n",
      "train loss:0.054399347901718055\n",
      "train loss:0.08524609714103232\n",
      "train loss:0.01810300771147274\n",
      "train loss:0.06272773511792559\n",
      "train loss:0.07080674060955615\n",
      "train loss:0.06440444122906303\n",
      "train loss:0.04580588921752069\n",
      "train loss:0.08000728547973956\n",
      "train loss:0.05584335973422608\n",
      "train loss:0.06799399403167049\n",
      "train loss:0.06539699348272468\n",
      "train loss:0.03520928855793885\n",
      "train loss:0.0365960999284045\n",
      "train loss:0.05221859391706165\n",
      "train loss:0.04747286008817819\n",
      "train loss:0.21910562321441723\n",
      "train loss:0.05375648796733768\n",
      "train loss:0.058378519983293804\n",
      "train loss:0.11595487048578047\n",
      "train loss:0.06705337740561584\n",
      "train loss:0.049667286026857986\n",
      "train loss:0.03815675643742798\n",
      "train loss:0.018420768439969062\n",
      "train loss:0.03946691399231252\n",
      "train loss:0.07161609859534983\n",
      "train loss:0.029538765111221\n",
      "train loss:0.1073674667865433\n",
      "train loss:0.016954727878775305\n",
      "train loss:0.12816727770692618\n",
      "train loss:0.05701417368382831\n",
      "train loss:0.10690831264511853\n",
      "train loss:0.08029769553873804\n",
      "train loss:0.10329260671764745\n",
      "train loss:0.04407385459990945\n",
      "train loss:0.08632550538697124\n",
      "train loss:0.02694613419924587\n",
      "train loss:0.09634703856504072\n",
      "train loss:0.0651935143841416\n",
      "train loss:0.05906294136867331\n",
      "train loss:0.10704265528377649\n",
      "train loss:0.0906901676169582\n",
      "train loss:0.10328647804762808\n",
      "train loss:0.04361501965629848\n",
      "train loss:0.11586972685505728\n",
      "train loss:0.06424181213680566\n",
      "train loss:0.14984959272296164\n",
      "train loss:0.03897001953368399\n",
      "train loss:0.11246200373215956\n",
      "train loss:0.02493199387258271\n",
      "train loss:0.02803561814951455\n",
      "train loss:0.04430580326179955\n",
      "train loss:0.0879992308374945\n",
      "train loss:0.07044973713984562\n",
      "train loss:0.043652963897218316\n",
      "train loss:0.04619432305757206\n",
      "train loss:0.11971703642136992\n",
      "train loss:0.045111013738434395\n",
      "train loss:0.02260642656900579\n",
      "train loss:0.10060771178257419\n",
      "train loss:0.12088168137911938\n",
      "train loss:0.04501834857711132\n",
      "train loss:0.07446966434094687\n",
      "train loss:0.06637550448466512\n",
      "train loss:0.07541380399955619\n",
      "train loss:0.06898970232175185\n",
      "train loss:0.06294984477034976\n",
      "train loss:0.0678463819453141\n",
      "train loss:0.04525085278923708\n",
      "train loss:0.06920444341734416\n",
      "train loss:0.053671882523007405\n",
      "train loss:0.09482484714583682\n",
      "train loss:0.06901939289970815\n",
      "train loss:0.04352102580537284\n",
      "train loss:0.07213375542058165\n",
      "train loss:0.160034239402767\n",
      "train loss:0.06721341525055603\n",
      "train loss:0.0986743774582385\n",
      "train loss:0.05742003278108251\n",
      "=== epoch:3, train acc:0.975, test acc:0.976 ===\n",
      "train loss:0.02854825409340289\n",
      "train loss:0.11525114172512035\n",
      "train loss:0.043710900345260935\n",
      "train loss:0.06567341967754907\n",
      "train loss:0.10336741464242281\n",
      "train loss:0.06929282814694301\n",
      "train loss:0.06177902818694576\n",
      "train loss:0.018824687004632377\n",
      "train loss:0.05317234473459634\n",
      "train loss:0.025126510176844735\n",
      "train loss:0.06755016925560771\n",
      "train loss:0.07478562100142366\n",
      "train loss:0.059495601881518034\n",
      "train loss:0.028852369706728574\n",
      "train loss:0.011835081445264042\n",
      "train loss:0.03688561201358691\n",
      "train loss:0.025785444274035448\n",
      "train loss:0.05554258994081301\n",
      "train loss:0.051076947441182276\n",
      "train loss:0.06039357208579322\n",
      "train loss:0.04496376853159287\n",
      "train loss:0.047623094622848375\n",
      "train loss:0.03188625783290437\n",
      "train loss:0.054799337909375544\n",
      "train loss:0.09778486478819703\n",
      "train loss:0.08442265219497708\n",
      "train loss:0.026931924259497548\n",
      "train loss:0.0371562984540772\n",
      "train loss:0.0886056207822845\n",
      "train loss:0.06379575618117075\n",
      "train loss:0.08095217398699552\n",
      "train loss:0.04508594892752851\n",
      "train loss:0.03347844826981019\n",
      "train loss:0.178740957177038\n",
      "train loss:0.04056238452836094\n",
      "train loss:0.025487692484523157\n",
      "train loss:0.11980157154734637\n",
      "train loss:0.020211144031789415\n",
      "train loss:0.0698587156880341\n",
      "train loss:0.12181066705082123\n",
      "train loss:0.07785804837882056\n",
      "train loss:0.1014676730033338\n",
      "train loss:0.03744336475950365\n",
      "train loss:0.0431022451632603\n",
      "train loss:0.0441260242161108\n",
      "train loss:0.03609150514206609\n",
      "train loss:0.10670112181834814\n",
      "train loss:0.05274184942572131\n",
      "train loss:0.06139919116112622\n",
      "train loss:0.07468384428253252\n",
      "train loss:0.11497039651354694\n",
      "train loss:0.08945007587274131\n",
      "train loss:0.051494341145597325\n",
      "train loss:0.056168327798091146\n",
      "train loss:0.07427276497897721\n",
      "train loss:0.07176604763991197\n",
      "train loss:0.09749643465269633\n",
      "train loss:0.12481771814828178\n",
      "train loss:0.09883737498266917\n",
      "train loss:0.17179406084338564\n",
      "train loss:0.045156579034278374\n",
      "train loss:0.04085502680871276\n",
      "train loss:0.05638925960851031\n",
      "train loss:0.040506079105624766\n",
      "train loss:0.1322467277213099\n",
      "train loss:0.0169289654089675\n",
      "train loss:0.041709165126381904\n",
      "train loss:0.056426456907134534\n",
      "train loss:0.06452034427533562\n",
      "train loss:0.05827030899708255\n",
      "train loss:0.09444871728919106\n",
      "train loss:0.1069147881650735\n",
      "train loss:0.09890985544702467\n",
      "train loss:0.07695522434395509\n",
      "train loss:0.06477957670904766\n",
      "train loss:0.031828096460278676\n",
      "train loss:0.07300740809266273\n",
      "train loss:0.09627655746420245\n",
      "train loss:0.12665062143440997\n",
      "train loss:0.03313579098402587\n",
      "train loss:0.052544356570048294\n",
      "train loss:0.10904943453919388\n",
      "train loss:0.019859859624490512\n",
      "train loss:0.04292894630884603\n",
      "train loss:0.0726379500653483\n",
      "train loss:0.07384000110240609\n",
      "train loss:0.041537248844087805\n",
      "train loss:0.0319191553300898\n",
      "train loss:0.10590238309433646\n",
      "train loss:0.053058126376219254\n",
      "train loss:0.05511004851588293\n",
      "train loss:0.05323846457198047\n",
      "train loss:0.07192559337515317\n",
      "train loss:0.051821179279913504\n",
      "train loss:0.07631439314419335\n",
      "train loss:0.12483688712522115\n",
      "train loss:0.04273658691718005\n",
      "train loss:0.03907048188042192\n",
      "train loss:0.11583593034426266\n",
      "train loss:0.037401512093219534\n",
      "train loss:0.11115289225790956\n",
      "train loss:0.11285422849481719\n",
      "train loss:0.05920609512096048\n",
      "train loss:0.048196475329196076\n",
      "train loss:0.09029536214672636\n",
      "train loss:0.09547792608988663\n",
      "train loss:0.05758608822524422\n",
      "train loss:0.03637014393776327\n",
      "train loss:0.027908388268107993\n",
      "train loss:0.05260815273381475\n",
      "train loss:0.04941104793235837\n",
      "train loss:0.0158979499538208\n",
      "train loss:0.1411767115052927\n",
      "train loss:0.22320873713912578\n",
      "train loss:0.0658867062959817\n",
      "train loss:0.08103616892014605\n",
      "train loss:0.0505664739900686\n",
      "train loss:0.032170014753533704\n",
      "train loss:0.06172331303615776\n",
      "train loss:0.028292033507390152\n",
      "train loss:0.07628183140100826\n",
      "train loss:0.03490486642967274\n",
      "train loss:0.03705779247087588\n",
      "train loss:0.023370941901033438\n",
      "train loss:0.08745686885799982\n",
      "train loss:0.038408098350775376\n",
      "train loss:0.025190662597846514\n",
      "train loss:0.045773080600155544\n",
      "train loss:0.11377652354647548\n",
      "train loss:0.06137627193403365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.021627093484577427\n",
      "train loss:0.0763729320347195\n",
      "train loss:0.25678278752774547\n",
      "train loss:0.07755118477702559\n",
      "train loss:0.07670607400114149\n",
      "train loss:0.05523410062317475\n",
      "train loss:0.01940317941917601\n",
      "train loss:0.056695819881879946\n",
      "train loss:0.11690800915976274\n",
      "train loss:0.12904818142863783\n",
      "train loss:0.025220211541554814\n",
      "train loss:0.019142920033383748\n",
      "train loss:0.08047561756406928\n",
      "train loss:0.07980116149669829\n",
      "train loss:0.08477018158066654\n",
      "train loss:0.040581393519294344\n",
      "train loss:0.043984300975983895\n",
      "train loss:0.08164694439090749\n",
      "train loss:0.05246062025923383\n",
      "train loss:0.10055851719892422\n",
      "train loss:0.013531332948071611\n",
      "train loss:0.049750042883319995\n",
      "train loss:0.0140530162766028\n",
      "train loss:0.07075802201361146\n",
      "train loss:0.09752497169588482\n",
      "train loss:0.06713122209638872\n",
      "train loss:0.11104677157139725\n",
      "train loss:0.05166158926221264\n",
      "train loss:0.09881390912151346\n",
      "train loss:0.0929177816998117\n",
      "train loss:0.09189705659790258\n",
      "train loss:0.042546254776141705\n",
      "train loss:0.06848798535640988\n",
      "train loss:0.0562396865524789\n",
      "train loss:0.05590821828600137\n",
      "train loss:0.034248536789174874\n",
      "train loss:0.049804720904990496\n",
      "train loss:0.08020550917305494\n",
      "train loss:0.038919333167541106\n",
      "train loss:0.08562222488191057\n",
      "train loss:0.03436095634061762\n",
      "train loss:0.048534628416901746\n",
      "train loss:0.0656826177121299\n",
      "train loss:0.031669913872703216\n",
      "train loss:0.06138994144106708\n",
      "train loss:0.02232626607354991\n",
      "train loss:0.06389835087518696\n",
      "train loss:0.10029413298267759\n",
      "train loss:0.1104095186799048\n",
      "train loss:0.06012801524069975\n",
      "train loss:0.04008871609780756\n",
      "train loss:0.09481094637596406\n",
      "train loss:0.031437175102858074\n",
      "train loss:0.017756164258444895\n",
      "train loss:0.02875061304872666\n",
      "train loss:0.02687380508198686\n",
      "train loss:0.040707235587023834\n",
      "train loss:0.12965660963555492\n",
      "train loss:0.08709196577049601\n",
      "train loss:0.07510038097024249\n",
      "train loss:0.04538528472932143\n",
      "train loss:0.0259396049068894\n",
      "train loss:0.12489984605924798\n",
      "train loss:0.07235551398670476\n",
      "train loss:0.036245645361024356\n",
      "train loss:0.013343669242015022\n",
      "train loss:0.05025943247995602\n",
      "train loss:0.05697460734734126\n",
      "train loss:0.06697885523082225\n",
      "train loss:0.05794030899787422\n",
      "train loss:0.03375285770624065\n",
      "train loss:0.021231598965984103\n",
      "train loss:0.08393740429387353\n",
      "train loss:0.06995833204961702\n",
      "train loss:0.09020673136302115\n",
      "train loss:0.02873555623999302\n",
      "train loss:0.023212947364375937\n",
      "train loss:0.08193623553405255\n",
      "train loss:0.08637870937055801\n",
      "train loss:0.07559091319712752\n",
      "train loss:0.034858611128496045\n",
      "train loss:0.12964985767692774\n",
      "train loss:0.025212722042060497\n",
      "train loss:0.06935630341263117\n",
      "train loss:0.06155722758187033\n",
      "train loss:0.07556243060698742\n",
      "train loss:0.09298262005674278\n",
      "train loss:0.050439682508072826\n",
      "train loss:0.07705551162043126\n",
      "train loss:0.07570888000681436\n",
      "train loss:0.05963194185155157\n",
      "train loss:0.06311534673151438\n",
      "train loss:0.14823488450491407\n",
      "train loss:0.02758733153883443\n",
      "train loss:0.11345694797203189\n",
      "train loss:0.026004648797086256\n",
      "train loss:0.05365294615021471\n",
      "train loss:0.08052258918284647\n",
      "train loss:0.017218607846371966\n",
      "train loss:0.021470866677944483\n",
      "train loss:0.08639901994433473\n",
      "train loss:0.16175816029337015\n",
      "train loss:0.07257401746022735\n",
      "train loss:0.04044255664835338\n",
      "train loss:0.05177361878287436\n",
      "train loss:0.059671339934881586\n",
      "train loss:0.04866175609346958\n",
      "train loss:0.021098628412035178\n",
      "train loss:0.05483989723327686\n",
      "train loss:0.08413179005553056\n",
      "train loss:0.014617855586226271\n",
      "train loss:0.058259907202812815\n",
      "train loss:0.02785604261839917\n",
      "train loss:0.036715655519230776\n",
      "train loss:0.10468231606098471\n",
      "train loss:0.08999090234776791\n",
      "train loss:0.049276215393564325\n",
      "train loss:0.0885774540171087\n",
      "train loss:0.07965244505295838\n",
      "train loss:0.09298750046568399\n",
      "train loss:0.014098966118956491\n",
      "train loss:0.19936993784960289\n",
      "train loss:0.06905312258219927\n",
      "train loss:0.11613651048373555\n",
      "train loss:0.056699696198316794\n",
      "train loss:0.033312190869437895\n",
      "train loss:0.028094187929146374\n",
      "train loss:0.08512125678730376\n",
      "train loss:0.023690989129558578\n",
      "train loss:0.0703510781533438\n",
      "train loss:0.08034933720214558\n",
      "train loss:0.038781527743681876\n",
      "train loss:0.0556609948937669\n",
      "train loss:0.03913877203578636\n",
      "train loss:0.04395811308703018\n",
      "train loss:0.043450854144958174\n",
      "train loss:0.05208177125560685\n",
      "train loss:0.05611536057094609\n",
      "train loss:0.04279242573562067\n",
      "train loss:0.04669052710333385\n",
      "train loss:0.048560987941750275\n",
      "train loss:0.06107757795771072\n",
      "train loss:0.05597522037797211\n",
      "train loss:0.061047648598969516\n",
      "train loss:0.02006424836053019\n",
      "train loss:0.015347765073308489\n",
      "train loss:0.0170311462994322\n",
      "train loss:0.03247489377096342\n",
      "train loss:0.057041438224975975\n",
      "train loss:0.1206896559702267\n",
      "train loss:0.036175837061923705\n",
      "train loss:0.07356222694417362\n",
      "train loss:0.041718547678599144\n",
      "train loss:0.047122932966346696\n",
      "train loss:0.03331863901585997\n",
      "train loss:0.050432407777844725\n",
      "train loss:0.03839940160796607\n",
      "train loss:0.07201584069068097\n",
      "train loss:0.034533278580072074\n",
      "train loss:0.06906583959768203\n",
      "train loss:0.07651069224889112\n",
      "train loss:0.02215262205274053\n",
      "train loss:0.15327835471931775\n",
      "train loss:0.016973196333501098\n",
      "train loss:0.015745659232289873\n",
      "train loss:0.016994804183872624\n",
      "train loss:0.031303605992924276\n",
      "train loss:0.08948507951812341\n",
      "train loss:0.08373296350381525\n",
      "train loss:0.01582710353589477\n",
      "train loss:0.04621558035766089\n",
      "train loss:0.023367603393876425\n",
      "train loss:0.12146216747087855\n",
      "train loss:0.05194277293555755\n",
      "train loss:0.02418627967209291\n",
      "train loss:0.029703138777786405\n",
      "train loss:0.09906337569029768\n",
      "train loss:0.07397129100519069\n",
      "train loss:0.014670611335564599\n",
      "train loss:0.011994897984838871\n",
      "train loss:0.05263463522083352\n",
      "train loss:0.1501936569765337\n",
      "train loss:0.05829894466279224\n",
      "train loss:0.02422547424635397\n",
      "train loss:0.09062409319478515\n",
      "train loss:0.05539619646886768\n",
      "train loss:0.019798068475351524\n",
      "train loss:0.07713561450889793\n",
      "train loss:0.04458568741107971\n",
      "train loss:0.12282233449519486\n",
      "train loss:0.04735454641790171\n",
      "train loss:0.07623595793775019\n",
      "train loss:0.1053097254013072\n",
      "train loss:0.03699006350290177\n",
      "train loss:0.14496972902331787\n",
      "train loss:0.04308784350698376\n",
      "train loss:0.03304083805248203\n",
      "train loss:0.08942703448923464\n",
      "train loss:0.03335347099153982\n",
      "train loss:0.04106729357479929\n",
      "train loss:0.014330414845993986\n",
      "train loss:0.07342863746433811\n",
      "train loss:0.034207082972760636\n",
      "train loss:0.0367130253006999\n",
      "train loss:0.016374181972905338\n",
      "train loss:0.039203757330165664\n",
      "train loss:0.07454674550733917\n",
      "train loss:0.07361854030493915\n",
      "train loss:0.05685588325495818\n",
      "train loss:0.049392568239871676\n",
      "train loss:0.04634263758686091\n",
      "train loss:0.07803366964071187\n",
      "train loss:0.03675114862299697\n",
      "train loss:0.046288085142667655\n",
      "train loss:0.06738751433241986\n",
      "train loss:0.023033798905540265\n",
      "train loss:0.012498656384340737\n",
      "train loss:0.04443484030105345\n",
      "train loss:0.024466862648493293\n",
      "train loss:0.06796234499727397\n",
      "train loss:0.1155836764772069\n",
      "train loss:0.0199344776532618\n",
      "train loss:0.03549759682460714\n",
      "train loss:0.017813408026499618\n",
      "train loss:0.02304010149949165\n",
      "train loss:0.05799491196601094\n",
      "train loss:0.023012118739818958\n",
      "train loss:0.07465312838814374\n",
      "train loss:0.042758567405021014\n",
      "train loss:0.013124007305439188\n",
      "train loss:0.10141079796675466\n",
      "train loss:0.03286175674920586\n",
      "train loss:0.05030748666484744\n",
      "train loss:0.09750904597029729\n",
      "train loss:0.06499722458492502\n",
      "train loss:0.020460497108479428\n",
      "train loss:0.02714430525822302\n",
      "train loss:0.09634011422554822\n",
      "train loss:0.08878523195006145\n",
      "train loss:0.09905000917476522\n",
      "train loss:0.06533953302700683\n",
      "train loss:0.01360948413202033\n",
      "train loss:0.0785155481894142\n",
      "train loss:0.06269981149022398\n",
      "train loss:0.030291863009561344\n",
      "train loss:0.06496116666706044\n",
      "train loss:0.07016281196464273\n",
      "train loss:0.02034947769513032\n",
      "train loss:0.03916185517404894\n",
      "train loss:0.02351172450736372\n",
      "train loss:0.03100844504884453\n",
      "train loss:0.029890941699490116\n",
      "train loss:0.07565794862583032\n",
      "train loss:0.053818634990897535\n",
      "train loss:0.03838277184595036\n",
      "train loss:0.038227903148208016\n",
      "train loss:0.13112494162485386\n",
      "train loss:0.08790957622136601\n",
      "train loss:0.0515307831132296\n",
      "train loss:0.06900080764582989\n",
      "train loss:0.04363162095489472\n",
      "train loss:0.06812814436706346\n",
      "train loss:0.12884990520480505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.040279908213797046\n",
      "train loss:0.08411227759368999\n",
      "train loss:0.0851587797870244\n",
      "train loss:0.024529358278280552\n",
      "train loss:0.01644241849065227\n",
      "train loss:0.019601955066539282\n",
      "train loss:0.02562757534717432\n",
      "train loss:0.03211916894404767\n",
      "train loss:0.05952799249162383\n",
      "train loss:0.0954058124439487\n",
      "train loss:0.026314578067532048\n",
      "train loss:0.053369659251722365\n",
      "train loss:0.01488875307202306\n",
      "train loss:0.06295256883050564\n",
      "train loss:0.140117599565879\n",
      "train loss:0.05598807045948804\n",
      "train loss:0.037398408018893166\n",
      "train loss:0.029089693464907862\n",
      "train loss:0.09029257104211029\n",
      "train loss:0.02940831688243857\n",
      "train loss:0.037900570543679575\n",
      "train loss:0.07465369327603964\n",
      "train loss:0.02417132228243462\n",
      "train loss:0.02440780563229269\n",
      "train loss:0.03545533863229909\n",
      "train loss:0.07942298301379762\n",
      "train loss:0.0180605713473462\n",
      "train loss:0.18804946785568075\n",
      "train loss:0.08055967495364857\n",
      "train loss:0.039345803635124556\n",
      "train loss:0.014974552460698514\n",
      "train loss:0.027328535107528164\n",
      "train loss:0.04000326499295573\n",
      "train loss:0.05730628581783078\n",
      "train loss:0.0411157627677263\n",
      "train loss:0.0075747718572499265\n",
      "train loss:0.01704916761069722\n",
      "train loss:0.02683247768135393\n",
      "train loss:0.026034124672058293\n",
      "train loss:0.09076794295576769\n",
      "train loss:0.04151691621449713\n",
      "train loss:0.02603725495374528\n",
      "train loss:0.008673404167811403\n",
      "train loss:0.027397939002509367\n",
      "train loss:0.020376509899961856\n",
      "train loss:0.02014825055742704\n",
      "train loss:0.05840746493208603\n",
      "train loss:0.04264450278859464\n",
      "train loss:0.025641826796818246\n",
      "train loss:0.07917924229911563\n",
      "train loss:0.062302709183393416\n",
      "train loss:0.04014285472417428\n",
      "train loss:0.018491987000349833\n",
      "train loss:0.04445538893427622\n",
      "train loss:0.0368290257935426\n",
      "train loss:0.10248049672181198\n",
      "train loss:0.10992538493309625\n",
      "train loss:0.03708418780971343\n",
      "train loss:0.07906624383369346\n",
      "train loss:0.04556711088680403\n",
      "train loss:0.07054265170068826\n",
      "train loss:0.031241809652817424\n",
      "train loss:0.013223380146699786\n",
      "train loss:0.0266387379223079\n",
      "train loss:0.0171626814032324\n",
      "train loss:0.069399830138534\n",
      "train loss:0.03135811731125843\n",
      "train loss:0.021021501952279146\n",
      "train loss:0.030644893021011876\n",
      "train loss:0.0818999905647897\n",
      "train loss:0.07305494782068923\n",
      "train loss:0.18199182903129293\n",
      "train loss:0.04049239631263408\n",
      "train loss:0.04809405140504542\n",
      "train loss:0.027698276642026544\n",
      "train loss:0.03796794512136102\n",
      "train loss:0.0516492439184191\n",
      "train loss:0.04713094143549947\n",
      "train loss:0.0454732524556947\n",
      "train loss:0.07577908758722711\n",
      "train loss:0.08097190986192296\n",
      "train loss:0.024910827403449853\n",
      "train loss:0.08924778361856296\n",
      "train loss:0.07349775083418597\n",
      "train loss:0.09544929760247058\n",
      "train loss:0.06398413539674774\n",
      "train loss:0.02519933030918775\n",
      "train loss:0.0329145042479177\n",
      "train loss:0.12511536308273732\n",
      "train loss:0.008000916788118153\n",
      "train loss:0.013820879628134483\n",
      "train loss:0.08127166780048144\n",
      "train loss:0.04663573950175276\n",
      "train loss:0.06206874457641134\n",
      "train loss:0.041882312467673925\n",
      "train loss:0.06312954874390803\n",
      "train loss:0.030938198332498938\n",
      "train loss:0.08405879624193954\n",
      "train loss:0.010884304561199204\n",
      "train loss:0.025310379364317875\n",
      "train loss:0.06654315938671164\n",
      "train loss:0.06251601928492515\n",
      "train loss:0.06394044263323359\n",
      "train loss:0.07192248742893508\n",
      "train loss:0.01721783304880357\n",
      "train loss:0.031878728500915186\n",
      "train loss:0.005504288677060641\n",
      "train loss:0.03531591887805237\n",
      "train loss:0.045053236846111275\n",
      "train loss:0.08321478103852092\n",
      "train loss:0.018468558667247115\n",
      "train loss:0.05450070070410676\n",
      "train loss:0.08849499917452013\n",
      "train loss:0.017542770204455372\n",
      "train loss:0.05825843973464167\n",
      "train loss:0.06329081287468014\n",
      "train loss:0.05217948933770922\n",
      "train loss:0.05377734361848086\n",
      "train loss:0.07794244365160961\n",
      "train loss:0.09743257263797878\n",
      "train loss:0.04200867657861811\n",
      "train loss:0.05250615227299502\n",
      "train loss:0.06880988087114326\n",
      "train loss:0.07523466875484364\n",
      "train loss:0.07037618745811262\n",
      "train loss:0.0727390039269589\n",
      "train loss:0.028340908841559643\n",
      "train loss:0.055179775006792144\n",
      "train loss:0.033819011305691725\n",
      "train loss:0.05537502178194423\n",
      "train loss:0.03965299038909809\n",
      "train loss:0.17687428687324355\n",
      "train loss:0.03857772408121425\n",
      "train loss:0.07181547856707571\n",
      "train loss:0.09120257856719684\n",
      "train loss:0.01989611696053881\n",
      "train loss:0.06974893429664292\n",
      "train loss:0.012790604407657462\n",
      "train loss:0.05685084101838015\n",
      "train loss:0.029493182323529567\n",
      "train loss:0.044328693201161146\n",
      "train loss:0.03412365796572225\n",
      "train loss:0.06302862744066323\n",
      "train loss:0.048043515800715635\n",
      "train loss:0.057320556221437856\n",
      "train loss:0.026380327016279796\n",
      "train loss:0.010937021415168129\n",
      "train loss:0.08167053664648531\n",
      "train loss:0.06137265059492055\n",
      "train loss:0.04111785966288187\n",
      "train loss:0.020006593592091667\n",
      "train loss:0.03962036679257481\n",
      "train loss:0.049750524181190005\n",
      "train loss:0.10321430490945888\n",
      "train loss:0.034002450852896215\n",
      "train loss:0.07056995412705526\n",
      "train loss:0.053848603894624585\n",
      "train loss:0.011682634413828734\n",
      "train loss:0.04451788669455291\n",
      "train loss:0.02530208032626838\n",
      "train loss:0.029938694067252337\n",
      "train loss:0.0737828993643822\n",
      "train loss:0.03420684843001355\n",
      "train loss:0.08356661689130371\n",
      "train loss:0.03711650228172799\n",
      "train loss:0.04968608294844172\n",
      "train loss:0.033567258085804366\n",
      "train loss:0.08560999236497753\n",
      "train loss:0.046585386893079776\n",
      "train loss:0.038464669288588646\n",
      "train loss:0.03754677292689945\n",
      "train loss:0.06980163076108828\n",
      "train loss:0.030892045997600145\n",
      "train loss:0.14596367422489098\n",
      "train loss:0.07252596051289167\n",
      "train loss:0.05935599794378885\n",
      "train loss:0.04234477478281894\n",
      "train loss:0.03327320658376826\n",
      "train loss:0.04029868178790517\n",
      "train loss:0.09504685270791413\n",
      "train loss:0.03218986807909145\n",
      "train loss:0.031171439650679877\n",
      "train loss:0.059310995791462796\n",
      "train loss:0.06137854062159554\n",
      "train loss:0.05239294016825787\n",
      "train loss:0.019710056227264447\n",
      "train loss:0.015696827200187204\n",
      "train loss:0.02257733767817882\n",
      "train loss:0.03978543425553425\n",
      "train loss:0.027277585726441303\n",
      "train loss:0.030915567447496163\n",
      "train loss:0.04987574396257422\n",
      "train loss:0.11281205888281316\n",
      "train loss:0.012993317476793033\n",
      "train loss:0.05755822297596086\n",
      "train loss:0.022417839041195924\n",
      "train loss:0.05143304453680847\n",
      "train loss:0.006958863551334112\n",
      "train loss:0.1351789691448062\n",
      "train loss:0.01202655672207723\n",
      "train loss:0.028382283014209864\n",
      "train loss:0.007427208160697879\n",
      "train loss:0.025722996406419302\n",
      "train loss:0.044133661874546724\n",
      "train loss:0.06458524847223733\n",
      "train loss:0.047082763790338496\n",
      "train loss:0.005304931065761581\n",
      "=== epoch:4, train acc:0.983, test acc:0.982 ===\n",
      "train loss:0.0299690692137968\n",
      "train loss:0.04165766560048779\n",
      "train loss:0.06415792560639792\n",
      "train loss:0.04719038647576752\n",
      "train loss:0.023408420536994986\n",
      "train loss:0.0375903305482225\n",
      "train loss:0.008562423831503687\n",
      "train loss:0.08147454720676764\n",
      "train loss:0.024153713484775925\n",
      "train loss:0.02269040805319122\n",
      "train loss:0.07469200460271218\n",
      "train loss:0.05726327747389368\n",
      "train loss:0.06636960360829273\n",
      "train loss:0.05431147273228243\n",
      "train loss:0.016163421040631964\n",
      "train loss:0.05611008761553978\n",
      "train loss:0.05069199931417557\n",
      "train loss:0.026195470010828083\n",
      "train loss:0.08304208904813554\n",
      "train loss:0.06313510572238329\n",
      "train loss:0.07227767121869987\n",
      "train loss:0.026625516391877792\n",
      "train loss:0.03224469613159824\n",
      "train loss:0.02578647610325272\n",
      "train loss:0.05663075942686393\n",
      "train loss:0.041284422427496574\n",
      "train loss:0.04308535958572022\n",
      "train loss:0.05817225008262029\n",
      "train loss:0.02406943762881262\n",
      "train loss:0.06559988552389968\n",
      "train loss:0.01701472310346216\n",
      "train loss:0.012658901705021645\n",
      "train loss:0.023587911663465303\n",
      "train loss:0.015177297921346032\n",
      "train loss:0.0691719776996231\n",
      "train loss:0.01784660623585762\n",
      "train loss:0.10082288958419448\n",
      "train loss:0.05963361667820976\n",
      "train loss:0.05010072653783992\n",
      "train loss:0.013810184793511699\n",
      "train loss:0.0306388294815329\n",
      "train loss:0.05056380705038462\n",
      "train loss:0.07575742363714649\n",
      "train loss:0.08553039167679277\n",
      "train loss:0.02403185484662327\n",
      "train loss:0.05511580889491248\n",
      "train loss:0.030990246194167716\n",
      "train loss:0.0350513133152701\n",
      "train loss:0.025395575551093442\n",
      "train loss:0.06764681155561868\n",
      "train loss:0.024045480188288254\n",
      "train loss:0.03249029200035951\n",
      "train loss:0.0703200496786317\n",
      "train loss:0.04775083005564135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.026853114830988484\n",
      "train loss:0.021630520747119516\n",
      "train loss:0.01980415126944677\n",
      "train loss:0.02438544125151064\n",
      "train loss:0.22042967515697215\n",
      "train loss:0.019939590353358363\n",
      "train loss:0.04380062755315563\n",
      "train loss:0.049684259434810404\n",
      "train loss:0.040952987566609415\n",
      "train loss:0.0173282267232803\n",
      "train loss:0.0801203129935973\n",
      "train loss:0.05483728895003314\n",
      "train loss:0.10744487052630966\n",
      "train loss:0.0223329900216292\n",
      "train loss:0.01304197678495699\n",
      "train loss:0.05457916109603854\n",
      "train loss:0.044980021659038014\n",
      "train loss:0.08718686855078728\n",
      "train loss:0.027600621841221504\n",
      "train loss:0.04278124221653308\n",
      "train loss:0.012296999534573003\n",
      "train loss:0.1667929359422273\n",
      "train loss:0.062095427076720756\n",
      "train loss:0.040613388093930426\n",
      "train loss:0.03492528651273534\n",
      "train loss:0.013300217463245558\n",
      "train loss:0.1073212911008934\n",
      "train loss:0.014777341572854277\n",
      "train loss:0.020878814969886826\n",
      "train loss:0.03241628723389124\n",
      "train loss:0.08071019228059122\n",
      "train loss:0.014238791693107882\n",
      "train loss:0.07814424953359811\n",
      "train loss:0.02906327001729143\n",
      "train loss:0.05084978082256494\n",
      "train loss:0.09291062437866086\n",
      "train loss:0.01662464551079423\n",
      "train loss:0.008165287797515785\n",
      "train loss:0.09939871076906755\n",
      "train loss:0.03941536721323552\n",
      "train loss:0.02264506831050544\n",
      "train loss:0.03468388170697014\n",
      "train loss:0.07399544813145542\n",
      "train loss:0.028393519353660607\n",
      "train loss:0.024913011936508793\n",
      "train loss:0.03719906271753439\n",
      "train loss:0.07415615764222194\n",
      "train loss:0.020654270034653113\n",
      "train loss:0.11059559685998155\n",
      "train loss:0.04597105132849658\n",
      "train loss:0.022206030553747372\n",
      "train loss:0.06924302024712492\n",
      "train loss:0.02506880325230668\n",
      "train loss:0.04960465960032936\n",
      "train loss:0.019417616373402335\n",
      "train loss:0.03286474792195056\n",
      "train loss:0.016146638787501926\n",
      "train loss:0.05845147982884138\n",
      "train loss:0.041081669157711234\n",
      "train loss:0.016140296417995737\n",
      "train loss:0.018130111701506666\n",
      "train loss:0.02322745429198238\n",
      "train loss:0.03831551936629684\n",
      "train loss:0.030431529506176367\n",
      "train loss:0.019010087823233858\n",
      "train loss:0.05530453472674175\n",
      "train loss:0.02122186784254041\n",
      "train loss:0.02060262483257601\n",
      "train loss:0.019492589147266107\n",
      "train loss:0.0341351703858281\n",
      "train loss:0.06645442788770234\n",
      "train loss:0.02914279697647796\n",
      "train loss:0.02848414659308738\n",
      "train loss:0.010974119671331016\n",
      "train loss:0.061200508575030385\n",
      "train loss:0.09509238035480705\n",
      "train loss:0.022010582101968598\n",
      "train loss:0.03474949288527057\n",
      "train loss:0.00928012703619105\n",
      "train loss:0.025927914499192784\n",
      "train loss:0.07437864539977822\n",
      "train loss:0.04195453822868609\n",
      "train loss:0.027543378697404895\n",
      "train loss:0.04703769644240675\n",
      "train loss:0.020086842048030875\n",
      "train loss:0.09994333974123093\n",
      "train loss:0.07200027032641047\n",
      "train loss:0.03083914785876948\n",
      "train loss:0.07012656249245347\n",
      "train loss:0.03460025469685494\n",
      "train loss:0.044577975547833146\n",
      "train loss:0.05125336780050591\n",
      "train loss:0.05246654005353675\n",
      "train loss:0.05336795526726209\n",
      "train loss:0.04025708719363518\n",
      "train loss:0.08536300518861502\n",
      "train loss:0.05494467452974794\n",
      "train loss:0.006983932201761836\n",
      "train loss:0.06601024898385303\n",
      "train loss:0.052841963780771904\n",
      "train loss:0.021420910159092796\n",
      "train loss:0.03701813139285379\n",
      "train loss:0.04334657212177968\n",
      "train loss:0.06081363559940671\n",
      "train loss:0.06303987102019713\n",
      "train loss:0.06385880856327564\n",
      "train loss:0.0704427335400129\n",
      "train loss:0.07122975751526402\n",
      "train loss:0.12604188116253578\n",
      "train loss:0.04549613999103465\n",
      "train loss:0.09557018222628959\n",
      "train loss:0.0639958377067402\n",
      "train loss:0.028636477404792228\n",
      "train loss:0.08526417252532424\n",
      "train loss:0.02012100512983851\n",
      "train loss:0.050133774876620275\n",
      "train loss:0.051929050158742766\n",
      "train loss:0.049835892646932896\n",
      "train loss:0.060712888965390566\n",
      "train loss:0.06199673021478425\n",
      "train loss:0.10474362926392727\n",
      "train loss:0.0377996088182017\n",
      "train loss:0.033924945762062675\n",
      "train loss:0.046771495027783994\n",
      "train loss:0.0392325440870767\n",
      "train loss:0.012676150533357577\n",
      "train loss:0.023493098624779312\n",
      "train loss:0.08562899579113205\n",
      "train loss:0.1369879295475223\n",
      "train loss:0.04610436906201277\n",
      "train loss:0.06519179831568804\n",
      "train loss:0.0507684470263371\n",
      "train loss:0.05113820807064507\n",
      "train loss:0.024762303465584883\n",
      "train loss:0.031505918083488335\n",
      "train loss:0.10810100067318296\n",
      "train loss:0.05759417506195908\n",
      "train loss:0.010246048216380315\n",
      "train loss:0.02643524062715614\n",
      "train loss:0.03200220922435198\n",
      "train loss:0.056102011664205725\n",
      "train loss:0.016293314892031455\n",
      "train loss:0.050253613037498625\n",
      "train loss:0.017855466964521872\n",
      "train loss:0.039066766721737166\n",
      "train loss:0.031020321189316503\n",
      "train loss:0.062240338623925424\n",
      "train loss:0.031161825491293524\n",
      "train loss:0.02635499939379319\n",
      "train loss:0.017908251164626462\n",
      "train loss:0.026202643652515165\n",
      "train loss:0.021571049800475105\n",
      "train loss:0.05135116521421268\n",
      "train loss:0.011315220911356762\n",
      "train loss:0.008932186221734887\n",
      "train loss:0.04009402725535607\n",
      "train loss:0.08138116842169904\n",
      "train loss:0.051319182875901134\n",
      "train loss:0.028210362290058945\n",
      "train loss:0.05121544660227607\n",
      "train loss:0.01763289123823772\n",
      "train loss:0.03078762255799221\n",
      "train loss:0.018011537267167605\n",
      "train loss:0.13612722533703686\n",
      "train loss:0.020338720782215932\n",
      "train loss:0.032022137729770465\n",
      "train loss:0.050591457705699686\n",
      "train loss:0.06120071201801578\n",
      "train loss:0.01813723034082619\n",
      "train loss:0.04025958631684655\n",
      "train loss:0.03500555793970556\n",
      "train loss:0.03524754904841154\n",
      "train loss:0.017415631107579606\n",
      "train loss:0.006432775688222969\n",
      "train loss:0.01412435530117077\n",
      "train loss:0.04165182357159997\n",
      "train loss:0.02137283043356849\n",
      "train loss:0.0411613857604552\n",
      "train loss:0.053537357707634674\n",
      "train loss:0.02626399163823807\n",
      "train loss:0.02732185275265179\n",
      "train loss:0.007749630863298171\n",
      "train loss:0.17104028715183414\n",
      "train loss:0.02358914416764878\n",
      "train loss:0.024109965532569534\n",
      "train loss:0.008914187164082554\n",
      "train loss:0.051640986402275095\n",
      "train loss:0.019950166648407045\n",
      "train loss:0.02580688855181744\n",
      "train loss:0.042307912527118095\n",
      "train loss:0.012747920122154022\n",
      "train loss:0.013669859854568351\n",
      "train loss:0.013609499427571328\n",
      "train loss:0.037721977442114925\n",
      "train loss:0.03514176149020612\n",
      "train loss:0.06151044952480932\n",
      "train loss:0.08512189686736338\n",
      "train loss:0.025045628218762977\n",
      "train loss:0.03187012359188778\n",
      "train loss:0.021397892786493997\n",
      "train loss:0.03381210942370617\n",
      "train loss:0.021022100278588703\n",
      "train loss:0.052089017016274865\n",
      "train loss:0.038981048974433656\n",
      "train loss:0.021498534698250204\n",
      "train loss:0.028136325103236062\n",
      "train loss:0.010560462705117422\n",
      "train loss:0.01443947647478509\n",
      "train loss:0.03635275894313998\n",
      "train loss:0.0379155439063359\n",
      "train loss:0.04459470136407528\n",
      "train loss:0.03394489636401928\n",
      "train loss:0.010913286415525072\n",
      "train loss:0.10410174329760567\n",
      "train loss:0.024944397781099976\n",
      "train loss:0.0424874849532453\n",
      "train loss:0.06337990926160908\n",
      "train loss:0.017611801381228153\n",
      "train loss:0.03678486901015995\n",
      "train loss:0.04038963026995594\n",
      "train loss:0.018005007260124082\n",
      "train loss:0.02837931719740469\n",
      "train loss:0.05100171620441468\n",
      "train loss:0.027767772230623308\n",
      "train loss:0.041590786911397976\n",
      "train loss:0.06250498297566191\n",
      "train loss:0.07295393912865333\n",
      "train loss:0.016334319110134415\n",
      "train loss:0.023517792849277873\n",
      "train loss:0.019677384820478892\n",
      "train loss:0.05950983035041364\n",
      "train loss:0.034036007311714724\n",
      "train loss:0.021117005455074177\n",
      "train loss:0.020626037412702195\n",
      "train loss:0.12435481330782394\n",
      "train loss:0.017710653098024096\n",
      "train loss:0.11570037734596887\n",
      "train loss:0.007970963922564599\n",
      "train loss:0.011842607897783543\n",
      "train loss:0.11267325032271298\n",
      "train loss:0.039314678483254914\n",
      "train loss:0.014351257062251455\n",
      "train loss:0.09614588260255558\n",
      "train loss:0.033605108554933774\n",
      "train loss:0.05453039764602959\n",
      "train loss:0.010889296678554723\n",
      "train loss:0.023395788682683577\n",
      "train loss:0.06827527757566162\n",
      "train loss:0.02234774342945424\n",
      "train loss:0.04877335365000317\n",
      "train loss:0.035809856570593504\n",
      "train loss:0.04642566269504297\n",
      "train loss:0.024937085563631774\n",
      "train loss:0.018251839964291725\n",
      "train loss:0.03179761445897079\n",
      "train loss:0.053809651097558975\n",
      "train loss:0.03052383141045964\n",
      "train loss:0.03529877666673018\n",
      "train loss:0.04465504362533813\n",
      "train loss:0.041148898299065824\n",
      "train loss:0.04786374075827671\n",
      "train loss:0.07440410085782348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0705470847141988\n",
      "train loss:0.020891880435309568\n",
      "train loss:0.030852079669888503\n",
      "train loss:0.10353388218991308\n",
      "train loss:0.009208661956676011\n",
      "train loss:0.07240642377697987\n",
      "train loss:0.03157928764221724\n",
      "train loss:0.028058693764311235\n",
      "train loss:0.05789203129740143\n",
      "train loss:0.011680005021719602\n",
      "train loss:0.11001087204335941\n",
      "train loss:0.011270792655626208\n",
      "train loss:0.04117004596657074\n",
      "train loss:0.006335093277564311\n",
      "train loss:0.027194095326850277\n",
      "train loss:0.02905082448095716\n",
      "train loss:0.03714727286215164\n",
      "train loss:0.08019290768686789\n",
      "train loss:0.016531867031711146\n",
      "train loss:0.043298264821820066\n",
      "train loss:0.02478689614408918\n",
      "train loss:0.029455094496081257\n",
      "train loss:0.012175407569047409\n",
      "train loss:0.035278015134618666\n",
      "train loss:0.01464991223082585\n",
      "train loss:0.025997292081891114\n",
      "train loss:0.009763842381802825\n",
      "train loss:0.0058461667158709275\n",
      "train loss:0.021162778138814845\n",
      "train loss:0.020113294918000665\n",
      "train loss:0.08682276227438701\n",
      "train loss:0.028162384049725934\n",
      "train loss:0.02084584204585398\n",
      "train loss:0.04614342493536106\n",
      "train loss:0.10316931627692122\n",
      "train loss:0.026369097575070978\n",
      "train loss:0.055300596863374754\n",
      "train loss:0.060237730344825345\n",
      "train loss:0.05134901080351795\n",
      "train loss:0.010276294736767756\n",
      "train loss:0.11837651549632179\n",
      "train loss:0.10264460722520324\n",
      "train loss:0.049522776239126196\n",
      "train loss:0.0370877113260731\n",
      "train loss:0.07468575783987434\n",
      "train loss:0.054679065107672044\n",
      "train loss:0.04778731206541711\n",
      "train loss:0.015460166529029122\n",
      "train loss:0.049603001907872396\n",
      "train loss:0.019447576885100834\n",
      "train loss:0.011500868306423346\n",
      "train loss:0.07458797326810077\n",
      "train loss:0.10147078774307573\n",
      "train loss:0.07452750039742209\n",
      "train loss:0.009578613474634397\n",
      "train loss:0.09340855215990496\n",
      "train loss:0.01472223359293302\n",
      "train loss:0.010336795531545007\n",
      "train loss:0.0784526731829833\n",
      "train loss:0.07245733880041035\n",
      "train loss:0.07927181492450833\n",
      "train loss:0.029707116258301615\n",
      "train loss:0.014068310589593817\n",
      "train loss:0.056979467111343204\n",
      "train loss:0.008098800377867197\n",
      "train loss:0.009129260948325264\n",
      "train loss:0.034190023385682354\n",
      "train loss:0.06285344851510707\n",
      "train loss:0.031218521992994398\n",
      "train loss:0.0652463598075432\n",
      "train loss:0.012381192581982434\n",
      "train loss:0.05440676709939675\n",
      "train loss:0.028272205322640787\n",
      "train loss:0.021029413537178524\n",
      "train loss:0.031858371804348855\n",
      "train loss:0.04845756965274168\n",
      "train loss:0.02435330032731085\n",
      "train loss:0.010203383038450049\n",
      "train loss:0.03510447447334298\n",
      "train loss:0.01680429895633001\n",
      "train loss:0.05595133667052124\n",
      "train loss:0.04136766270640864\n",
      "train loss:0.035247356737174884\n",
      "train loss:0.02240387178034772\n",
      "train loss:0.07054610933517433\n",
      "train loss:0.047452735480127524\n",
      "train loss:0.038027234177062656\n",
      "train loss:0.0075605841959190505\n",
      "train loss:0.012871567555840997\n",
      "train loss:0.007561573301839844\n",
      "train loss:0.04579515204035233\n",
      "train loss:0.0075603372307267\n",
      "train loss:0.024010502738515512\n",
      "train loss:0.07250813029650073\n",
      "train loss:0.005664440875897456\n",
      "train loss:0.022459081189954287\n",
      "train loss:0.11947353491326901\n",
      "train loss:0.06880439969573064\n",
      "train loss:0.11733280922124234\n",
      "train loss:0.012628274514290896\n",
      "train loss:0.016857402235674557\n",
      "train loss:0.05560566128370244\n",
      "train loss:0.030802830724189257\n",
      "train loss:0.008705435999686727\n",
      "train loss:0.034523246883794156\n",
      "train loss:0.08094712530406496\n",
      "train loss:0.09831456675770771\n",
      "train loss:0.0561667119083499\n",
      "train loss:0.009250591991032273\n",
      "train loss:0.03543651573713982\n",
      "train loss:0.03532399843184698\n",
      "train loss:0.029142276926588318\n",
      "train loss:0.009374781611798774\n",
      "train loss:0.019086162215644013\n",
      "train loss:0.026533004397352497\n",
      "train loss:0.05970709154984369\n",
      "train loss:0.08791187333834605\n",
      "train loss:0.0369693031907964\n",
      "train loss:0.05844270251381802\n",
      "train loss:0.007915892354231261\n",
      "train loss:0.030663494645207255\n",
      "train loss:0.03629731674699786\n",
      "train loss:0.016173930839263016\n",
      "train loss:0.0204689461859014\n",
      "train loss:0.12280570130263366\n",
      "train loss:0.062253981793072774\n",
      "train loss:0.02225467890355983\n",
      "train loss:0.023062770199905328\n",
      "train loss:0.025009670232903822\n",
      "train loss:0.051544880695008184\n",
      "train loss:0.05642115458004218\n",
      "train loss:0.04119752916677693\n",
      "train loss:0.012599427810837765\n",
      "train loss:0.07593710879799562\n",
      "train loss:0.0605169212295388\n",
      "train loss:0.019009205366698586\n",
      "train loss:0.047245406052670684\n",
      "train loss:0.05545831829308143\n",
      "train loss:0.013032174883489346\n",
      "train loss:0.10476249787645896\n",
      "train loss:0.050891087359043616\n",
      "train loss:0.013472125439211217\n",
      "train loss:0.039048297108483905\n",
      "train loss:0.048333751182820246\n",
      "train loss:0.017526993419297417\n",
      "train loss:0.025716377711866842\n",
      "train loss:0.03705362073865676\n",
      "train loss:0.07667737930262666\n",
      "train loss:0.03869766934327931\n",
      "train loss:0.01724103443521527\n",
      "train loss:0.016455861021819788\n",
      "train loss:0.05954058302156864\n",
      "train loss:0.026024514631380637\n",
      "train loss:0.032912191495307795\n",
      "train loss:0.014576280258776789\n",
      "train loss:0.0320414707624264\n",
      "train loss:0.02786364968075716\n",
      "train loss:0.047708136123286275\n",
      "train loss:0.07808552018839361\n",
      "train loss:0.1704223894120487\n",
      "train loss:0.011942451481184063\n",
      "train loss:0.035099798537734275\n",
      "train loss:0.03227472805354272\n",
      "train loss:0.04537000422605983\n",
      "train loss:0.050706265576534675\n",
      "train loss:0.02635034020539934\n",
      "train loss:0.04322785869914782\n",
      "train loss:0.014032622629781192\n",
      "train loss:0.052563077121293336\n",
      "train loss:0.01715787918949849\n",
      "train loss:0.020252295268204556\n",
      "train loss:0.11067030279397574\n",
      "train loss:0.045896517408715566\n",
      "train loss:0.05092171852314924\n",
      "train loss:0.0213698327182725\n",
      "train loss:0.0063500863465576485\n",
      "train loss:0.018053214559816008\n",
      "train loss:0.05832962590257971\n",
      "train loss:0.07795249142496402\n",
      "train loss:0.030429911071966912\n",
      "train loss:0.032693830549307475\n",
      "train loss:0.0629062606680053\n",
      "train loss:0.01513296062745476\n",
      "train loss:0.009568344019956841\n",
      "train loss:0.021897356933335513\n",
      "train loss:0.012302925080166359\n",
      "train loss:0.022877649563376137\n",
      "train loss:0.020907216913755043\n",
      "train loss:0.03170092846265835\n",
      "train loss:0.024582067067911297\n",
      "train loss:0.00885464911757884\n",
      "train loss:0.01551375920957461\n",
      "train loss:0.015273562380782237\n",
      "train loss:0.07273050122430551\n",
      "train loss:0.010779209678449775\n",
      "train loss:0.028458994552388574\n",
      "train loss:0.01792010662061707\n",
      "train loss:0.06600124530514438\n",
      "train loss:0.010360441191592152\n",
      "train loss:0.030957492432321557\n",
      "train loss:0.04166464559409792\n",
      "train loss:0.04255708865949786\n",
      "train loss:0.04946258219211803\n",
      "train loss:0.023351567909516133\n",
      "train loss:0.010656757349736366\n",
      "train loss:0.011238664360951016\n",
      "train loss:0.04993804936659535\n",
      "train loss:0.016969124911926745\n",
      "train loss:0.006509222517839312\n",
      "train loss:0.059938050329541886\n",
      "train loss:0.0038874766975070685\n",
      "train loss:0.07993763662472382\n",
      "train loss:0.020859899260800514\n",
      "train loss:0.013824231355495676\n",
      "train loss:0.03346612100093515\n",
      "train loss:0.0664871371117595\n",
      "train loss:0.0177988614264624\n",
      "train loss:0.009894197837911787\n",
      "train loss:0.05208207325237461\n",
      "train loss:0.013018562289776244\n",
      "train loss:0.06611205070450506\n",
      "train loss:0.01887554621210745\n",
      "train loss:0.01377386240776174\n",
      "train loss:0.010389484952955249\n",
      "train loss:0.06121869045633374\n",
      "train loss:0.019090074649911318\n",
      "train loss:0.015651109087000025\n",
      "train loss:0.02294503978547578\n",
      "train loss:0.05584147850087259\n",
      "train loss:0.028975674523329928\n",
      "train loss:0.0110568830095158\n",
      "train loss:0.0184457372549674\n",
      "train loss:0.021824756162603594\n",
      "train loss:0.013398794329878519\n",
      "train loss:0.02106727037746274\n",
      "train loss:0.007597250025676603\n",
      "train loss:0.021939955471514182\n",
      "train loss:0.013453577530736737\n",
      "train loss:0.028195513521277093\n",
      "train loss:0.030180105042436532\n",
      "train loss:0.007755723153636341\n",
      "train loss:0.019834460096725046\n",
      "train loss:0.0340640937652503\n",
      "train loss:0.07720415437911259\n",
      "train loss:0.03764617992838649\n",
      "train loss:0.014639897419651875\n",
      "train loss:0.0041939451326879675\n",
      "train loss:0.029969456232561847\n",
      "train loss:0.019591441870950414\n",
      "train loss:0.014195703654862574\n",
      "train loss:0.03557339194301339\n",
      "train loss:0.029029911605484723\n",
      "train loss:0.06213787971665678\n",
      "train loss:0.005526562116591395\n",
      "train loss:0.004025891265361006\n",
      "train loss:0.03216126064770927\n",
      "train loss:0.027119471742826393\n",
      "train loss:0.05858543590716426\n",
      "train loss:0.013466576104706453\n",
      "train loss:0.06132160448764224\n",
      "train loss:0.03808731302338799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.024283838227165493\n",
      "train loss:0.01859160212989573\n",
      "train loss:0.009305695601301745\n",
      "train loss:0.03734957758806478\n",
      "train loss:0.011112052095666021\n",
      "train loss:0.04392169373017171\n",
      "train loss:0.010536059738353499\n",
      "train loss:0.07238976581574136\n",
      "train loss:0.03447747879241078\n",
      "train loss:0.028221695804835224\n",
      "train loss:0.0448568850865893\n",
      "train loss:0.01867342012756635\n",
      "train loss:0.04582653030845197\n",
      "train loss:0.01151318106811626\n",
      "train loss:0.02206715188330353\n",
      "train loss:0.014340428392945373\n",
      "train loss:0.017670484217782292\n",
      "train loss:0.09372870689343703\n",
      "train loss:0.010095497520397735\n",
      "train loss:0.07132949221419606\n",
      "train loss:0.03460635748998951\n",
      "train loss:0.012258005695753275\n",
      "train loss:0.009483632429628606\n",
      "=== epoch:5, train acc:0.986, test acc:0.978 ===\n",
      "train loss:0.05898088922094165\n",
      "train loss:0.01954184310096828\n",
      "train loss:0.03075801834248861\n",
      "train loss:0.01827455773202079\n",
      "train loss:0.03231621731346253\n",
      "train loss:0.03402454137011303\n",
      "train loss:0.010331288183108444\n",
      "train loss:0.029702667087854143\n",
      "train loss:0.016485428462705842\n",
      "train loss:0.02130451625251127\n",
      "train loss:0.008975396748331534\n",
      "train loss:0.013238280039701756\n",
      "train loss:0.01189231575107795\n",
      "train loss:0.007053148426539827\n",
      "train loss:0.053360503916237534\n",
      "train loss:0.026421887938455468\n",
      "train loss:0.013531262687350366\n",
      "train loss:0.008507512821593354\n",
      "train loss:0.010951118209378987\n",
      "train loss:0.039931728358104907\n",
      "train loss:0.030053490112145934\n",
      "train loss:0.0542456941663136\n",
      "train loss:0.05327427383515153\n",
      "train loss:0.01800301801735554\n",
      "train loss:0.031361032269567636\n",
      "train loss:0.021855734022040413\n",
      "train loss:0.029036559725248597\n",
      "train loss:0.05115398368782494\n",
      "train loss:0.03040156838442308\n",
      "train loss:0.07264954618043222\n",
      "train loss:0.02060330577139776\n",
      "train loss:0.019048250741941036\n",
      "train loss:0.04533975297275013\n",
      "train loss:0.009792781055838778\n",
      "train loss:0.04385778756822934\n",
      "train loss:0.0053131400985180375\n",
      "train loss:0.04361236980800471\n",
      "train loss:0.013900806097295135\n",
      "train loss:0.026103384753001477\n",
      "train loss:0.02693861504418126\n",
      "train loss:0.0611970425719233\n",
      "train loss:0.035846386009462924\n",
      "train loss:0.0319325817259968\n",
      "train loss:0.008099449758147971\n",
      "train loss:0.031950156705564565\n",
      "train loss:0.03404834957076715\n",
      "train loss:0.02799366549590525\n",
      "train loss:0.005217767528234327\n",
      "train loss:0.09869118814274744\n",
      "train loss:0.04167978734054511\n",
      "train loss:0.07174212904814266\n",
      "train loss:0.02909917290838831\n",
      "train loss:0.041502005137052295\n",
      "train loss:0.019276705125739865\n",
      "train loss:0.05011989144818904\n",
      "train loss:0.020706116396044964\n",
      "train loss:0.002366092307360595\n",
      "train loss:0.026702833699654826\n",
      "train loss:0.018946692169658195\n",
      "train loss:0.012998002067536651\n",
      "train loss:0.02421931035611845\n",
      "train loss:0.011807848510893917\n",
      "train loss:0.03882616597993999\n",
      "train loss:0.003290301029811791\n",
      "train loss:0.019339512393961627\n",
      "train loss:0.022070425607663483\n",
      "train loss:0.003853968625716411\n",
      "train loss:0.06548998058262914\n",
      "train loss:0.00857624091807592\n",
      "train loss:0.027719288974018902\n",
      "train loss:0.042748435939565385\n",
      "train loss:0.005207946273996983\n",
      "train loss:0.010858903455601074\n",
      "train loss:0.03347705723834334\n",
      "train loss:0.05184967586115814\n",
      "train loss:0.051515329549921614\n",
      "train loss:0.007003111680343874\n",
      "train loss:0.013361906639772388\n",
      "train loss:0.02612525848559785\n",
      "train loss:0.04387114675499091\n",
      "train loss:0.05711483319775865\n",
      "train loss:0.0700288841889384\n",
      "train loss:0.015840654742371948\n",
      "train loss:0.013027762237933883\n",
      "train loss:0.00782230862511234\n",
      "train loss:0.10142325814690324\n",
      "train loss:0.01643347376075914\n",
      "train loss:0.008478730098202252\n",
      "train loss:0.026728106833389824\n",
      "train loss:0.010357475262726732\n",
      "train loss:0.013158633751838497\n",
      "train loss:0.03131399083670231\n",
      "train loss:0.03929316592753306\n",
      "train loss:0.029550059771501234\n",
      "train loss:0.011143433052618126\n",
      "train loss:0.013289678357050227\n",
      "train loss:0.029738257452374524\n",
      "train loss:0.019833684430430314\n",
      "train loss:0.022541440071109173\n",
      "train loss:0.08652317858228255\n",
      "train loss:0.012014752946221998\n",
      "train loss:0.0073660659416774155\n",
      "train loss:0.06017388571110006\n",
      "train loss:0.005569084727745561\n",
      "train loss:0.02239179798592621\n",
      "train loss:0.011795156500325928\n",
      "train loss:0.028787065007794897\n",
      "train loss:0.00679941869492303\n",
      "train loss:0.03817417865402538\n",
      "train loss:0.05594661564724545\n",
      "train loss:0.011231316677548153\n",
      "train loss:0.05742770385834585\n",
      "train loss:0.020838911758325834\n",
      "train loss:0.018374623917389806\n",
      "train loss:0.03956288446947749\n",
      "train loss:0.05931019105205865\n",
      "train loss:0.0384077800122337\n",
      "train loss:0.014790858226366055\n",
      "train loss:0.015099735171581714\n",
      "train loss:0.021069486687860725\n",
      "train loss:0.019356593217795478\n",
      "train loss:0.014027690297845806\n",
      "train loss:0.006544647592940407\n",
      "train loss:0.052068034162716756\n",
      "train loss:0.03300744848772274\n",
      "train loss:0.02671692849707002\n",
      "train loss:0.019844800767232804\n",
      "train loss:0.027636033003536474\n",
      "train loss:0.057243790081235674\n",
      "train loss:0.036082990966746414\n",
      "train loss:0.0368599226463862\n",
      "train loss:0.005141709799950644\n",
      "train loss:0.02649634222244544\n",
      "train loss:0.09820697351371475\n",
      "train loss:0.014060777756414528\n",
      "train loss:0.02545306847745124\n",
      "train loss:0.018042446664908725\n",
      "train loss:0.013085492988577951\n",
      "train loss:0.017357580927824728\n",
      "train loss:0.034412835959896214\n",
      "train loss:0.014506701779879833\n",
      "train loss:0.024153999711717875\n",
      "train loss:0.028021465626430347\n",
      "train loss:0.052314587982793676\n",
      "train loss:0.011120023918248243\n",
      "train loss:0.027822198595589903\n",
      "train loss:0.0060161346229898735\n",
      "train loss:0.014802135213153522\n",
      "train loss:0.02705664855017604\n",
      "train loss:0.05576170717126239\n",
      "train loss:0.04902190252338498\n",
      "train loss:0.01736944854646887\n",
      "train loss:0.025502247504698376\n",
      "train loss:0.02840673165305022\n",
      "train loss:0.012677459132876713\n",
      "train loss:0.030350439500085747\n",
      "train loss:0.029851460838288\n",
      "train loss:0.029059654210609007\n",
      "train loss:0.006510862485698292\n",
      "train loss:0.02202694241310684\n",
      "train loss:0.02855239693182216\n",
      "train loss:0.016995978292008367\n",
      "train loss:0.05314661804960096\n",
      "train loss:0.014725200646002577\n",
      "train loss:0.03904761367977408\n",
      "train loss:0.004063716869789192\n",
      "train loss:0.0132049007065668\n",
      "train loss:0.01793039497508548\n",
      "train loss:0.03225581682748889\n",
      "train loss:0.06224192821404988\n",
      "train loss:0.0700649553252767\n",
      "train loss:0.03214828726050671\n",
      "train loss:0.030157183065277433\n",
      "train loss:0.11467329002796242\n",
      "train loss:0.0396753686415535\n",
      "train loss:0.0026133427649500563\n",
      "train loss:0.0317207178691567\n",
      "train loss:0.02460313434971479\n",
      "train loss:0.040512865102426646\n",
      "train loss:0.025761210567788302\n",
      "train loss:0.02184378908672411\n",
      "train loss:0.015568898958185586\n",
      "train loss:0.03857064579298652\n",
      "train loss:0.0439368131235859\n",
      "train loss:0.010298670346312664\n",
      "train loss:0.008143934371973784\n",
      "train loss:0.06361646614685265\n",
      "train loss:0.02972848959917032\n",
      "train loss:0.057879450159515816\n",
      "train loss:0.048179434846967274\n",
      "train loss:0.05863678690636808\n",
      "train loss:0.010377303670850203\n",
      "train loss:0.02153918190099296\n",
      "train loss:0.032341913724971416\n",
      "train loss:0.030992913247494282\n",
      "train loss:0.027367715367259602\n",
      "train loss:0.019382122755950068\n",
      "train loss:0.02240088278663475\n",
      "train loss:0.01709179536074435\n",
      "train loss:0.03732362857747125\n",
      "train loss:0.09654859373267419\n",
      "train loss:0.024858054060971625\n",
      "train loss:0.016124764569006845\n",
      "train loss:0.024381461624986875\n",
      "train loss:0.0260324003394905\n",
      "train loss:0.021804969325752745\n",
      "train loss:0.009044763245742602\n",
      "train loss:0.015606599219746293\n",
      "train loss:0.07597281980517423\n",
      "train loss:0.04815377704385087\n",
      "train loss:0.017894542028930385\n",
      "train loss:0.04089836006890011\n",
      "train loss:0.016435180695849694\n",
      "train loss:0.04132470170027751\n",
      "train loss:0.030020839126568003\n",
      "train loss:0.016906384647305584\n",
      "train loss:0.041824680669655306\n",
      "train loss:0.022086271028520198\n",
      "train loss:0.014131839569174638\n",
      "train loss:0.03779642947944946\n",
      "train loss:0.02693482650879317\n",
      "train loss:0.008200327211006863\n",
      "train loss:0.04507802208619335\n",
      "train loss:0.00827877348852331\n",
      "train loss:0.017989451234677368\n",
      "train loss:0.005182317273909295\n",
      "train loss:0.005153046739875274\n",
      "train loss:0.0422534497101978\n",
      "train loss:0.011152161121402038\n",
      "train loss:0.01590623080530341\n",
      "train loss:0.017671831513524684\n",
      "train loss:0.02806334926446129\n",
      "train loss:0.050282606109317174\n",
      "train loss:0.047579695188587096\n",
      "train loss:0.031272327571985926\n",
      "train loss:0.01554062144769313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.015413299545141115\n",
      "train loss:0.00325733121470866\n",
      "train loss:0.0271565783721925\n",
      "train loss:0.03460242795800351\n",
      "train loss:0.04498134870020985\n",
      "train loss:0.07037928969150473\n",
      "train loss:0.01259807651150623\n",
      "train loss:0.05083100661319751\n",
      "train loss:0.02841010893973458\n",
      "train loss:0.02417009192600098\n",
      "train loss:0.010821846103503235\n",
      "train loss:0.07935628406617595\n",
      "train loss:0.007162502749510955\n",
      "train loss:0.003083140921223228\n",
      "train loss:0.031138777900480138\n",
      "train loss:0.021165124395620856\n",
      "train loss:0.02160989221080761\n",
      "train loss:0.02441319925714939\n",
      "train loss:0.07393888500671547\n",
      "train loss:0.004142536586025347\n",
      "train loss:0.018222038743278556\n",
      "train loss:0.020197003877818694\n",
      "train loss:0.012695795948726473\n",
      "train loss:0.006757118001291231\n",
      "train loss:0.018439366985899625\n",
      "train loss:0.006375489193981985\n",
      "train loss:0.12230298198662602\n",
      "train loss:0.019012659284481894\n",
      "train loss:0.02637113966933221\n",
      "train loss:0.042920522822429905\n",
      "train loss:0.021461912579565173\n",
      "train loss:0.017140731480917954\n",
      "train loss:0.012880433853883403\n",
      "train loss:0.013666675396549912\n",
      "train loss:0.02075758845933918\n",
      "train loss:0.0675074370960136\n",
      "train loss:0.06414866115049453\n",
      "train loss:0.05430897125508014\n",
      "train loss:0.004499772374098074\n",
      "train loss:0.009878728509998137\n",
      "train loss:0.017705615311354287\n",
      "train loss:0.014420584660864004\n",
      "train loss:0.022520344487775717\n",
      "train loss:0.06130429978910556\n",
      "train loss:0.04229521130692729\n",
      "train loss:0.026575649895597166\n",
      "train loss:0.02106696691394635\n",
      "train loss:0.042735664874436294\n",
      "train loss:0.08598492767072294\n",
      "train loss:0.02258239819695562\n",
      "train loss:0.009311167261031867\n",
      "train loss:0.08624721143516123\n",
      "train loss:0.0059865388365560115\n",
      "train loss:0.010564638773312113\n",
      "train loss:0.01663337415617824\n",
      "train loss:0.08535086691193788\n",
      "train loss:0.03371601530511563\n",
      "train loss:0.07290942264360215\n",
      "train loss:0.010054430362978681\n",
      "train loss:0.02603359652589867\n",
      "train loss:0.021969062065137206\n",
      "train loss:0.051862840510077446\n",
      "train loss:0.11799814867311217\n",
      "train loss:0.036253869507237774\n",
      "train loss:0.015371951500319878\n",
      "train loss:0.046276210210985165\n",
      "train loss:0.010378541970362712\n",
      "train loss:0.049964171330767665\n",
      "train loss:0.03374322808149808\n",
      "train loss:0.03151058004714932\n",
      "train loss:0.042937752488804444\n",
      "train loss:0.061122269938339836\n",
      "train loss:0.04302210189881013\n",
      "train loss:0.024253171462631142\n",
      "train loss:0.05704718986082625\n",
      "train loss:0.01673873660080877\n",
      "train loss:0.01713706568961933\n",
      "train loss:0.004585999272725369\n",
      "train loss:0.037090317522610994\n",
      "train loss:0.03059413646593436\n",
      "train loss:0.13677087909056124\n",
      "train loss:0.008569713061835398\n",
      "train loss:0.009053149271632296\n",
      "train loss:0.021142655364137425\n",
      "train loss:0.004565205319827501\n",
      "train loss:0.06563222727970672\n",
      "train loss:0.06155305592438991\n",
      "train loss:0.015544989604304196\n",
      "train loss:0.008497530813766113\n",
      "train loss:0.0177729589848898\n",
      "train loss:0.015438658098024312\n",
      "train loss:0.03401433228265942\n",
      "train loss:0.06680302490752936\n",
      "train loss:0.014389234487381244\n",
      "train loss:0.004236138500149648\n",
      "train loss:0.0036228746776038067\n",
      "train loss:0.07747177005470189\n",
      "train loss:0.018319519149186544\n",
      "train loss:0.017325141396524843\n",
      "train loss:0.01778234148354074\n",
      "train loss:0.008833718413595914\n",
      "train loss:0.022381221231661738\n",
      "train loss:0.012141395129424574\n",
      "train loss:0.03323334222574203\n",
      "train loss:0.008727519929089182\n",
      "train loss:0.016068770936442156\n",
      "train loss:0.012436620326423162\n",
      "train loss:0.007037663274066955\n",
      "train loss:0.1694156525005925\n",
      "train loss:0.050491955622491765\n",
      "train loss:0.011053578416478825\n",
      "train loss:0.05007548314170673\n",
      "train loss:0.02125208875910798\n",
      "train loss:0.04942072523578114\n",
      "train loss:0.01911449511130922\n",
      "train loss:0.016285609525838938\n",
      "train loss:0.02071315010882744\n",
      "train loss:0.02071594890847701\n",
      "train loss:0.020980669322093543\n",
      "train loss:0.06150763656088179\n",
      "train loss:0.06449602231860684\n",
      "train loss:0.02670448815868711\n",
      "train loss:0.015370941998541561\n",
      "train loss:0.06009173856241936\n",
      "train loss:0.014244115698952448\n",
      "train loss:0.05368648033528097\n",
      "train loss:0.01288964852769599\n",
      "train loss:0.03488637991551193\n",
      "train loss:0.008994318227645199\n",
      "train loss:0.004781637770049082\n",
      "train loss:0.03419459130386553\n",
      "train loss:0.02917936438521954\n",
      "train loss:0.016573378978022902\n",
      "train loss:0.011066041330816172\n",
      "train loss:0.03684664498251118\n",
      "train loss:0.026236096617804742\n",
      "train loss:0.007080676801914732\n",
      "train loss:0.03681475281383407\n",
      "train loss:0.019036010672804738\n",
      "train loss:0.00864769739709036\n",
      "train loss:0.04691590943651411\n",
      "train loss:0.022186000549898676\n",
      "train loss:0.011605372955951465\n",
      "train loss:0.0677817449244483\n",
      "train loss:0.026930974031258298\n",
      "train loss:0.027764780752309006\n",
      "train loss:0.041523325477672915\n",
      "train loss:0.015238944591266831\n",
      "train loss:0.014899511520435192\n",
      "train loss:0.01117698345384404\n",
      "train loss:0.031076741049584175\n",
      "train loss:0.07683228557283354\n",
      "train loss:0.017273951957665266\n",
      "train loss:0.006451440973324364\n",
      "train loss:0.017805948503361455\n",
      "train loss:0.02753925008308201\n",
      "train loss:0.01199539097434802\n",
      "train loss:0.025398535628980767\n",
      "train loss:0.03545167061119675\n",
      "train loss:0.05333377587414993\n",
      "train loss:0.05170170357782694\n",
      "train loss:0.03819551148393255\n",
      "train loss:0.014716654632724924\n",
      "train loss:0.007726432002059482\n",
      "train loss:0.005350107903495933\n",
      "train loss:0.02561044010020222\n",
      "train loss:0.033089728640006894\n",
      "train loss:0.00915664747861801\n",
      "train loss:0.041855815270631626\n",
      "train loss:0.03473745669143095\n",
      "train loss:0.014411603123777745\n",
      "train loss:0.03936281559173187\n",
      "train loss:0.017934885108097442\n",
      "train loss:0.013121795205739022\n",
      "train loss:0.0311236334267494\n",
      "train loss:0.04607242854142302\n",
      "train loss:0.03262879081598132\n",
      "train loss:0.012604322053819181\n",
      "train loss:0.013944289501296525\n",
      "train loss:0.020852183431696942\n",
      "train loss:0.017430207897832097\n",
      "train loss:0.015266999466952607\n",
      "train loss:0.08141193144871707\n",
      "train loss:0.028620471177164236\n",
      "train loss:0.03895585880889521\n",
      "train loss:0.0232607806178343\n",
      "train loss:0.0731493085163654\n",
      "train loss:0.00940231720037919\n",
      "train loss:0.02090291548226678\n",
      "train loss:0.012893542021701052\n",
      "train loss:0.014907960358586034\n",
      "train loss:0.054727352264316034\n",
      "train loss:0.013203934346002404\n",
      "train loss:0.025468753287839395\n",
      "train loss:0.01508774835712853\n",
      "train loss:0.03265143934283249\n",
      "train loss:0.016881207116230357\n",
      "train loss:0.0150936568849107\n",
      "train loss:0.004894001374711212\n",
      "train loss:0.01289664747196246\n",
      "train loss:0.041931913838350744\n",
      "train loss:0.024888829728947494\n",
      "train loss:0.037074059280018126\n",
      "train loss:0.028644977792246333\n",
      "train loss:0.017225795563301328\n",
      "train loss:0.041262781551319475\n",
      "train loss:0.028591411792577022\n",
      "train loss:0.03675027128447601\n",
      "train loss:0.01571698126274964\n",
      "train loss:0.01788969926556587\n",
      "train loss:0.007033594077963695\n",
      "train loss:0.019793443976349526\n",
      "train loss:0.014580624537653237\n",
      "train loss:0.024871737087370435\n",
      "train loss:0.0089789347816969\n",
      "train loss:0.011512601172415957\n",
      "train loss:0.007365472029105009\n",
      "train loss:0.04743902120432785\n",
      "train loss:0.0445903661581441\n",
      "train loss:0.004222886836858201\n",
      "train loss:0.017621148733593956\n",
      "train loss:0.0019473873631593811\n",
      "train loss:0.004731510304326439\n",
      "train loss:0.013544045025549005\n",
      "train loss:0.00964501684636394\n",
      "train loss:0.012182630535532826\n",
      "train loss:0.012729223133794952\n",
      "train loss:0.04054451974386269\n",
      "train loss:0.03936447805157087\n",
      "train loss:0.0017169261765992163\n",
      "train loss:0.012706415662205428\n",
      "train loss:0.02393112056854149\n",
      "train loss:0.0024992051210992842\n",
      "train loss:0.009867626791599738\n",
      "train loss:0.057347741923386604\n",
      "train loss:0.0623487911237117\n",
      "train loss:0.013478010007529106\n",
      "train loss:0.017953757056067644\n",
      "train loss:0.038769570638004056\n",
      "train loss:0.041058566323739415\n",
      "train loss:0.011784870888214737\n",
      "train loss:0.046833926352173795\n",
      "train loss:0.0033935654403665348\n",
      "train loss:0.017424392148340743\n",
      "train loss:0.012273534229121901\n",
      "train loss:0.03016066213717223\n",
      "train loss:0.02247670486665694\n",
      "train loss:0.00593975321748914\n",
      "train loss:0.03806436269570477\n",
      "train loss:0.007846159707729537\n",
      "train loss:0.011884433813610616\n",
      "train loss:0.09226186626350408\n",
      "train loss:0.03036406692362792\n",
      "train loss:0.043398715381977884\n",
      "train loss:0.041635366799359703\n",
      "train loss:0.06103788790726252\n",
      "train loss:0.07071563012789266\n",
      "train loss:0.016670902926022482\n",
      "train loss:0.029523405456617823\n",
      "train loss:0.07248935022580107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.010978338872451579\n",
      "train loss:0.10455249657073827\n",
      "train loss:0.08729839511106893\n",
      "train loss:0.02959302305719027\n",
      "train loss:0.028774315472248038\n",
      "train loss:0.004826958545624241\n",
      "train loss:0.01315445923265855\n",
      "train loss:0.03239265397554114\n",
      "train loss:0.024404128122545395\n",
      "train loss:0.016321167596487288\n",
      "train loss:0.0032019560881644286\n",
      "train loss:0.023046809090758666\n",
      "train loss:0.016120372620830263\n",
      "train loss:0.023729325341989\n",
      "train loss:0.07586247861948989\n",
      "train loss:0.032877019650742585\n",
      "train loss:0.037391088497647725\n",
      "train loss:0.025831377058361235\n",
      "train loss:0.07827559029060563\n",
      "train loss:0.015766216087269105\n",
      "train loss:0.02692420195661793\n",
      "train loss:0.014230857374569212\n",
      "train loss:0.020362755249281585\n",
      "train loss:0.012480446730085552\n",
      "train loss:0.07435375983659548\n",
      "train loss:0.03355354573100745\n",
      "train loss:0.010213732480832786\n",
      "train loss:0.015287154350417958\n",
      "train loss:0.008138508092260055\n",
      "train loss:0.020968680560928047\n",
      "train loss:0.01602136555925442\n",
      "train loss:0.012355063140959657\n",
      "train loss:0.057146030899218034\n",
      "train loss:0.005503895130132437\n",
      "train loss:0.0071087512155535845\n",
      "train loss:0.014416539461251054\n",
      "train loss:0.006865145565029549\n",
      "train loss:0.020120400693236996\n",
      "train loss:0.01260822158135383\n",
      "train loss:0.0525444673480051\n",
      "train loss:0.00583104627072207\n",
      "train loss:0.004812686892272214\n",
      "train loss:0.013553750542966163\n",
      "train loss:0.013159555364659417\n",
      "train loss:0.015688439325432044\n",
      "train loss:0.005960393887252157\n",
      "train loss:0.031145587370518882\n",
      "train loss:0.021458693750169875\n",
      "train loss:0.030666899786661327\n",
      "train loss:0.019556338761834925\n",
      "train loss:0.01600661289212399\n",
      "train loss:0.02767323361661852\n",
      "train loss:0.009366658033119339\n",
      "train loss:0.03626881548294735\n",
      "train loss:0.0030107653648605557\n",
      "train loss:0.016328791405117983\n",
      "train loss:0.009300509125207756\n",
      "train loss:0.004264979708823056\n",
      "train loss:0.013116569237557234\n",
      "train loss:0.023569809234933903\n",
      "train loss:0.01112988246087258\n",
      "train loss:0.015770076336765512\n",
      "train loss:0.04051129010666565\n",
      "train loss:0.024186202577841636\n",
      "train loss:0.020758560369480837\n",
      "train loss:0.01719923621148147\n",
      "train loss:0.012592697082220208\n",
      "train loss:0.006243303771377432\n",
      "train loss:0.039372982563456976\n",
      "train loss:0.005782511592504604\n",
      "train loss:0.05039603426686976\n",
      "train loss:0.026384102093892286\n",
      "train loss:0.051337122969554345\n",
      "train loss:0.1012136781727318\n",
      "train loss:0.0244462182667451\n",
      "train loss:0.01881357276729182\n",
      "train loss:0.0076943027515617365\n",
      "train loss:0.010731241007077764\n",
      "train loss:0.03883422143442955\n",
      "train loss:0.048970397442157115\n",
      "train loss:0.03999522696540328\n",
      "train loss:0.00479369016942361\n",
      "train loss:0.014793366931503129\n",
      "train loss:0.016335040555359743\n",
      "train loss:0.015566822909136507\n",
      "train loss:0.024714465800236507\n",
      "train loss:0.055075737284642975\n",
      "train loss:0.0054511597350655186\n",
      "train loss:0.015831992183512295\n",
      "train loss:0.027719989690293625\n",
      "train loss:0.030398018474001115\n",
      "train loss:0.0940577872122166\n",
      "train loss:0.020971653643856364\n",
      "train loss:0.021990991685571205\n",
      "train loss:0.03119050532465901\n",
      "train loss:0.008416703300980271\n",
      "train loss:0.04237643902482526\n",
      "train loss:0.03657115239671305\n",
      "train loss:0.05500728908867603\n",
      "train loss:0.01524698556106762\n",
      "train loss:0.023549005601443778\n",
      "train loss:0.039033729138088676\n",
      "train loss:0.013949948100517839\n",
      "train loss:0.006512728222224135\n",
      "=== epoch:6, train acc:0.988, test acc:0.975 ===\n",
      "train loss:0.041414494547750536\n",
      "train loss:0.014161624528219641\n",
      "train loss:0.005084080887763798\n",
      "train loss:0.024513626072667966\n",
      "train loss:0.02755041443394567\n",
      "train loss:0.04538306927849005\n",
      "train loss:0.0669732163649859\n",
      "train loss:0.024243755196105034\n",
      "train loss:0.03609150308024269\n",
      "train loss:0.014266886232413461\n",
      "train loss:0.018105499964566216\n",
      "train loss:0.05733790515723808\n",
      "train loss:0.006313177374583957\n",
      "train loss:0.01199766627215083\n",
      "train loss:0.005665227703621397\n",
      "train loss:0.03193438665664771\n",
      "train loss:0.020597916827216633\n",
      "train loss:0.03562712317514151\n",
      "train loss:0.007835552428229359\n",
      "train loss:0.006244027486964092\n",
      "train loss:0.023413964968446978\n",
      "train loss:0.003233704060492279\n",
      "train loss:0.013120843243385565\n",
      "train loss:0.02062610220125207\n",
      "train loss:0.007686214381320468\n",
      "train loss:0.012916269772684352\n",
      "train loss:0.02729255719202088\n",
      "train loss:0.004067963702263146\n",
      "train loss:0.032972703227567804\n",
      "train loss:0.013549717513309903\n",
      "train loss:0.013399160882119909\n",
      "train loss:0.016313823373938798\n",
      "train loss:0.012930427794977946\n",
      "train loss:0.008906117303125483\n",
      "train loss:0.05073433360428853\n",
      "train loss:0.011215375616883114\n",
      "train loss:0.029295678166869378\n",
      "train loss:0.017627180781092\n",
      "train loss:0.020701304583778276\n",
      "train loss:0.004215874935638343\n",
      "train loss:0.00829239649910096\n",
      "train loss:0.006875411501709889\n",
      "train loss:0.03395699519558212\n",
      "train loss:0.03355763820452645\n",
      "train loss:0.010034142721353475\n",
      "train loss:0.011240990566838329\n",
      "train loss:0.006827366124688352\n",
      "train loss:0.009797400432056274\n",
      "train loss:0.028010722852452714\n",
      "train loss:0.037937585260183454\n",
      "train loss:0.04776185154778059\n",
      "train loss:0.011398274315729408\n",
      "train loss:0.0016677026750876627\n",
      "train loss:0.006043927315164255\n",
      "train loss:0.004879126620715369\n",
      "train loss:0.036357477578419624\n",
      "train loss:0.02141354555586829\n",
      "train loss:0.014450772678890958\n",
      "train loss:0.007837112307996434\n",
      "train loss:0.01781219307387092\n",
      "train loss:0.014813569692343239\n",
      "train loss:0.016902292192422914\n",
      "train loss:0.09070656822595727\n",
      "train loss:0.019930349101951093\n",
      "train loss:0.0249875905952779\n",
      "train loss:0.015670102202425314\n",
      "train loss:0.05720867052455597\n",
      "train loss:0.008231639839368476\n",
      "train loss:0.025452418047937755\n",
      "train loss:0.006659988670490111\n",
      "train loss:0.031416172655931544\n",
      "train loss:0.013957653122016345\n",
      "train loss:0.038942444528652406\n",
      "train loss:0.01213641505797894\n",
      "train loss:0.01069059417141549\n",
      "train loss:0.0095221932181603\n",
      "train loss:0.01803603127170061\n",
      "train loss:0.009822248419753859\n",
      "train loss:0.019724487975183273\n",
      "train loss:0.03474558901915846\n",
      "train loss:0.004411193531439429\n",
      "train loss:0.004594754197998802\n",
      "train loss:0.017161794261747552\n",
      "train loss:0.02949063746852889\n",
      "train loss:0.006242050695266636\n",
      "train loss:0.005541100167290965\n",
      "train loss:0.007642728628002743\n",
      "train loss:0.010042202947036933\n",
      "train loss:0.009862427722174485\n",
      "train loss:0.009794333093433855\n",
      "train loss:0.02550241292114132\n",
      "train loss:0.022177310993091292\n",
      "train loss:0.020666383676077964\n",
      "train loss:0.02855996927909232\n",
      "train loss:0.023092235785003665\n",
      "train loss:0.008744495542892894\n",
      "train loss:0.020830641006843682\n",
      "train loss:0.00846917028173657\n",
      "train loss:0.009156080592343007\n",
      "train loss:0.004174636672203465\n",
      "train loss:0.0069916770838482165\n",
      "train loss:0.006694880697299832\n",
      "train loss:0.06346963074499669\n",
      "train loss:0.18365784028944543\n",
      "train loss:0.00932528447793904\n",
      "train loss:0.01780911257820333\n",
      "train loss:0.004836518513419961\n",
      "train loss:0.05264457249544474\n",
      "train loss:0.02198616041664182\n",
      "train loss:0.04734757617732065\n",
      "train loss:0.025211967035243785\n",
      "train loss:0.0033263744674903763\n",
      "train loss:0.023270280608602284\n",
      "train loss:0.008410431450370572\n",
      "train loss:0.010790064686163557\n",
      "train loss:0.011487070226280873\n",
      "train loss:0.0030833420134853263\n",
      "train loss:0.006763027656905241\n",
      "train loss:0.06243415260273848\n",
      "train loss:0.01278926364209763\n",
      "train loss:0.05453379379631691\n",
      "train loss:0.00563396148205678\n",
      "train loss:0.03671188572034973\n",
      "train loss:0.03126115295993273\n",
      "train loss:0.009013180182418808\n",
      "train loss:0.03372417831917206\n",
      "train loss:0.030070708885890408\n",
      "train loss:0.011964167099305914\n",
      "train loss:0.003352273804177852\n",
      "train loss:0.01808015797676148\n",
      "train loss:0.04683151405874037\n",
      "train loss:0.014467340164249842\n",
      "train loss:0.0039218257316844165\n",
      "train loss:0.034967558938517135\n",
      "train loss:0.028508119881146966\n",
      "train loss:0.012302401122301555\n",
      "train loss:0.00527361613997751\n",
      "train loss:0.012702725997792354\n",
      "train loss:0.08957920610250042\n",
      "train loss:0.022322136468207417\n",
      "train loss:0.011330715251543375\n",
      "train loss:0.004387351128516099\n",
      "train loss:0.010733258764105103\n",
      "train loss:0.030442536288043002\n",
      "train loss:0.020310349556185756\n",
      "train loss:0.007922992975445346\n",
      "train loss:0.029043531133762852\n",
      "train loss:0.035147106112257104\n",
      "train loss:0.008127460244285893\n",
      "train loss:0.003911112540321099\n",
      "train loss:0.02315050043378337\n",
      "train loss:0.025700006261688845\n",
      "train loss:0.00975132961598392\n",
      "train loss:0.05072151139126764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.018548815390439077\n",
      "train loss:0.019762893683703733\n",
      "train loss:0.014011144336762643\n",
      "train loss:0.019073743355533728\n",
      "train loss:0.002440411289166089\n",
      "train loss:0.03756949240164666\n",
      "train loss:0.01574481242370249\n",
      "train loss:0.04511806697369486\n",
      "train loss:0.053333677248076305\n",
      "train loss:0.01365299117458013\n",
      "train loss:0.030099035313515498\n",
      "train loss:0.00412679883963161\n",
      "train loss:0.00518190703557353\n",
      "train loss:0.004477112927457239\n",
      "train loss:0.022182067332631145\n",
      "train loss:0.00615546441510066\n",
      "train loss:0.018926396548830084\n",
      "train loss:0.043777920099443667\n",
      "train loss:0.03578658763741592\n",
      "train loss:0.04201443772282218\n",
      "train loss:0.08390220687827657\n",
      "train loss:0.01213323115261771\n",
      "train loss:0.046734290157624765\n",
      "train loss:0.003581761242124932\n",
      "train loss:0.0439383650733265\n",
      "train loss:0.02980749316085179\n",
      "train loss:0.007645949038676913\n",
      "train loss:0.023672756701524262\n",
      "train loss:0.017690176119448568\n",
      "train loss:0.0068671692839787435\n",
      "train loss:0.04077656165214179\n",
      "train loss:0.012110887139873723\n",
      "train loss:0.027295414038430763\n",
      "train loss:0.01833997349806121\n",
      "train loss:0.00875997625290542\n",
      "train loss:0.03409004169613755\n",
      "train loss:0.009244484628814009\n",
      "train loss:0.010744892512152805\n",
      "train loss:0.020465268461714238\n",
      "train loss:0.016366049800237602\n",
      "train loss:0.014378753033911982\n",
      "train loss:0.03566113878402901\n",
      "train loss:0.011768054937010435\n",
      "train loss:0.015102269672689898\n",
      "train loss:0.036876125480402984\n",
      "train loss:0.0025374131923437465\n",
      "train loss:0.023952482160723338\n",
      "train loss:0.010297199473678962\n",
      "train loss:0.032202102396735814\n",
      "train loss:0.005138186024092113\n",
      "train loss:0.02565137259711152\n",
      "train loss:0.04415114104098773\n",
      "train loss:0.008500723913224085\n",
      "train loss:0.018890929850453195\n",
      "train loss:0.004218990369690259\n",
      "train loss:0.03776686231430864\n",
      "train loss:0.05105506266891815\n",
      "train loss:0.025978472288097257\n",
      "train loss:0.007180110241569516\n",
      "train loss:0.07484859593049022\n",
      "train loss:0.018805909783261097\n",
      "train loss:0.05172667915697996\n",
      "train loss:0.046750345663387406\n",
      "train loss:0.01496674674011455\n",
      "train loss:0.009162293979599799\n",
      "train loss:0.020226148946606175\n",
      "train loss:0.08401550920357685\n",
      "train loss:0.004298513416186121\n",
      "train loss:0.005873436992285586\n",
      "train loss:0.02651882486651802\n",
      "train loss:0.04114448580034928\n",
      "train loss:0.010851848928419566\n",
      "train loss:0.016496974497418423\n",
      "train loss:0.026791019877131353\n",
      "train loss:0.01968356284964794\n",
      "train loss:0.006471661940539044\n",
      "train loss:0.008317035982458339\n",
      "train loss:0.03173771775472974\n",
      "train loss:0.010287769095477151\n",
      "train loss:0.009887551713980734\n",
      "train loss:0.0032810399363677367\n",
      "train loss:0.02266937433643184\n",
      "train loss:0.07135202520752518\n",
      "train loss:0.010137867673335648\n",
      "train loss:0.013170932247401228\n",
      "train loss:0.09685796085518003\n",
      "train loss:0.01572397294976358\n",
      "train loss:0.006307570886026139\n",
      "train loss:0.028412099845518554\n",
      "train loss:0.019822501225056702\n",
      "train loss:0.01712318693809281\n",
      "train loss:0.015673792596792694\n",
      "train loss:0.017928992790207456\n",
      "train loss:0.019245908902393943\n",
      "train loss:0.019404489440065936\n",
      "train loss:0.015923904280809722\n",
      "train loss:0.03207806634687795\n",
      "train loss:0.01683308718582499\n",
      "train loss:0.05653558966592634\n",
      "train loss:0.016074190615312713\n",
      "train loss:0.008926074356466479\n",
      "train loss:0.008490450654927859\n",
      "train loss:0.014077324948858385\n",
      "train loss:0.0177617365820789\n",
      "train loss:0.008457218446119269\n",
      "train loss:0.010687361960156499\n",
      "train loss:0.05170886533963351\n",
      "train loss:0.11285170011207782\n",
      "train loss:0.024225174247542204\n",
      "train loss:0.027200522268654034\n",
      "train loss:0.006813660140531381\n",
      "train loss:0.01358982376616785\n",
      "train loss:0.009558181273670223\n",
      "train loss:0.007361727447553612\n",
      "train loss:0.027833134558082877\n",
      "train loss:0.013973109927191753\n",
      "train loss:0.0077921158283847484\n",
      "train loss:0.016370735651677\n",
      "train loss:0.0071008935767064825\n",
      "train loss:0.005712336041409304\n",
      "train loss:0.031393471036853575\n",
      "train loss:0.0357356356068976\n",
      "train loss:0.04929428273664494\n",
      "train loss:0.014796816569365085\n",
      "train loss:0.013577521693991887\n",
      "train loss:0.014262438429997836\n",
      "train loss:0.009813153747136396\n",
      "train loss:0.023978016240392065\n",
      "train loss:0.013943012898036653\n",
      "train loss:0.009309302984048947\n",
      "train loss:0.004019192896749494\n",
      "train loss:0.005639535569726288\n",
      "train loss:0.007766606154580523\n",
      "train loss:0.026980307099034026\n",
      "train loss:0.013292323478796341\n",
      "train loss:0.010435297419117917\n",
      "train loss:0.022599439970466394\n",
      "train loss:0.02384462579955446\n",
      "train loss:0.003893203907515978\n",
      "train loss:0.08428869812215797\n",
      "train loss:0.010167087480038466\n",
      "train loss:0.031461120473389025\n",
      "train loss:0.024531153810646685\n",
      "train loss:0.007357136564650798\n",
      "train loss:0.015465285654829708\n",
      "train loss:0.01879307673390032\n",
      "train loss:0.032850712477524656\n",
      "train loss:0.011881858135904613\n",
      "train loss:0.015344871612140472\n",
      "train loss:0.011117213077735033\n",
      "train loss:0.08009035610675676\n",
      "train loss:0.01773282589649298\n",
      "train loss:0.011489830585258688\n",
      "train loss:0.032333867919766425\n",
      "train loss:0.04059661628713725\n",
      "train loss:0.00774476109002194\n",
      "train loss:0.053888938691317084\n",
      "train loss:0.019990015553012816\n",
      "train loss:0.005921406410653359\n",
      "train loss:0.007624534255429166\n",
      "train loss:0.013177647660032408\n",
      "train loss:0.01801294007639863\n",
      "train loss:0.019003448078261678\n",
      "train loss:0.009498770340505358\n",
      "train loss:0.010974708573958712\n",
      "train loss:0.01151141824698665\n",
      "train loss:0.0036025161870427386\n",
      "train loss:0.011793280091133453\n",
      "train loss:0.0051096918708345455\n",
      "train loss:0.03554575024547032\n",
      "train loss:0.012764094148987904\n",
      "train loss:0.011774045072629675\n",
      "train loss:0.01684995137272378\n",
      "train loss:0.011364991222089907\n",
      "train loss:0.013667962392204637\n",
      "train loss:0.011557764395397716\n",
      "train loss:0.005303928065407943\n",
      "train loss:0.003183285674314154\n",
      "train loss:0.02431955430014605\n",
      "train loss:0.0056345705354349076\n",
      "train loss:0.010974934927135385\n",
      "train loss:0.03147197987239971\n",
      "train loss:0.018362253407278234\n",
      "train loss:0.002640257377192798\n",
      "train loss:0.009369307279003833\n",
      "train loss:0.019081027971812627\n",
      "train loss:0.02131979962564826\n",
      "train loss:0.00409380146269613\n",
      "train loss:0.018936985482922095\n",
      "train loss:0.009400971681097272\n",
      "train loss:0.018565289551888905\n",
      "train loss:0.0194068237186974\n",
      "train loss:0.013458534448907216\n",
      "train loss:0.012642098465521705\n",
      "train loss:0.003444165348659065\n",
      "train loss:0.05328551373696589\n",
      "train loss:0.01805828690140174\n",
      "train loss:0.025421381131393413\n",
      "train loss:0.012135459415385874\n",
      "train loss:0.00622441357562904\n",
      "train loss:0.008024793903121935\n",
      "train loss:0.03904040694252661\n",
      "train loss:0.0042494551977474366\n",
      "train loss:0.02175649332788088\n",
      "train loss:0.005902432874114\n",
      "train loss:0.10965848984723055\n",
      "train loss:0.007182911591888095\n",
      "train loss:0.0086622774433696\n",
      "train loss:0.0036385063280757494\n",
      "train loss:0.020767019605623507\n",
      "train loss:0.012588701242584573\n",
      "train loss:0.028467518460983478\n",
      "train loss:0.006395617537127236\n",
      "train loss:0.0037532206905489265\n",
      "train loss:0.014916244028495854\n",
      "train loss:0.010733236446986694\n",
      "train loss:0.011576890702193664\n",
      "train loss:0.01854693961204525\n",
      "train loss:0.053820087913121484\n",
      "train loss:0.007013958755951352\n",
      "train loss:0.003622571325959295\n",
      "train loss:0.009485451582187504\n",
      "train loss:0.027210511121362316\n",
      "train loss:0.011311998663370858\n",
      "train loss:0.006342292724227396\n",
      "train loss:0.036999483904626554\n",
      "train loss:0.07297225435919208\n",
      "train loss:0.004200715912495655\n",
      "train loss:0.06329521670579798\n",
      "train loss:0.03435779488071419\n",
      "train loss:0.04618148504497691\n",
      "train loss:0.01812980280832714\n",
      "train loss:0.05938557745301068\n",
      "train loss:0.0038870570592587704\n",
      "train loss:0.04435865705947099\n",
      "train loss:0.043254326764790935\n",
      "train loss:0.0291320953397363\n",
      "train loss:0.029027889885896732\n",
      "train loss:0.0045090371021877925\n",
      "train loss:0.030804160914373747\n",
      "train loss:0.02071482820194492\n",
      "train loss:0.008108205683357789\n",
      "train loss:0.016414696210168136\n",
      "train loss:0.028170540084711045\n",
      "train loss:0.008930436677657923\n",
      "train loss:0.008245291720052908\n",
      "train loss:0.011028634244538267\n",
      "train loss:0.0270922708483787\n",
      "train loss:0.05231674542920478\n",
      "train loss:0.020647649111594085\n",
      "train loss:0.009617968572898703\n",
      "train loss:0.01958087362031733\n",
      "train loss:0.03076177234219667\n",
      "train loss:0.005717629733014951\n",
      "train loss:0.03231303714563635\n",
      "train loss:0.012797739246185252\n",
      "train loss:0.004573257019620135\n",
      "train loss:0.019523281386056912\n",
      "train loss:0.008367988943280636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.02348881519694232\n",
      "train loss:0.03145966030588645\n",
      "train loss:0.046361586411522514\n",
      "train loss:0.007308888922856568\n",
      "train loss:0.043333524113771525\n",
      "train loss:0.012740666671499791\n",
      "train loss:0.005115124329858569\n",
      "train loss:0.011167517538825078\n",
      "train loss:0.016370822875383894\n",
      "train loss:0.008506751191776499\n",
      "train loss:0.01945229121142451\n",
      "train loss:0.0036483459198118724\n",
      "train loss:0.00617837007955355\n",
      "train loss:0.01997082049596001\n",
      "train loss:0.004951298642076846\n",
      "train loss:0.00842594241792407\n",
      "train loss:0.009160717003545127\n",
      "train loss:0.002480665491292326\n",
      "train loss:0.0617784936146173\n",
      "train loss:0.053248987332785186\n",
      "train loss:0.007845535198180355\n",
      "train loss:0.002636290031331611\n",
      "train loss:0.02421766482687511\n",
      "train loss:0.019310598059384197\n",
      "train loss:0.010254166173751203\n",
      "train loss:0.013060274447230583\n",
      "train loss:0.030631253215961215\n",
      "train loss:0.02304781133151558\n",
      "train loss:0.015387368037222314\n",
      "train loss:0.01789689378267845\n",
      "train loss:0.011916501956703065\n",
      "train loss:0.012160503262828325\n",
      "train loss:0.012530788322333208\n",
      "train loss:0.003521849817198579\n",
      "train loss:0.030059805763792483\n",
      "train loss:0.043664968679687215\n",
      "train loss:0.02814354521924026\n",
      "train loss:0.02408403117808468\n",
      "train loss:0.008362889194931434\n",
      "train loss:0.032127867110074246\n",
      "train loss:0.007051025656623669\n",
      "train loss:0.028399606168759316\n",
      "train loss:0.007733992090011862\n",
      "train loss:0.03341063447546922\n",
      "train loss:0.0061452242478263345\n",
      "train loss:0.01048769331695818\n",
      "train loss:0.015735303477138706\n",
      "train loss:0.026042253163083857\n",
      "train loss:0.009405105284954909\n",
      "train loss:0.034485993414608535\n",
      "train loss:0.068663207222545\n",
      "train loss:0.005474460837936163\n",
      "train loss:0.056356841191287456\n",
      "train loss:0.0314673197362634\n",
      "train loss:0.015939922770853546\n",
      "train loss:0.008404067659700315\n",
      "train loss:0.023351576411232533\n",
      "train loss:0.01494726326982167\n",
      "train loss:0.00910082868427859\n",
      "train loss:0.01926238803662969\n",
      "train loss:0.007668466779705053\n",
      "train loss:0.013333279920327314\n",
      "train loss:0.02920506267970629\n",
      "train loss:0.024883898756435766\n",
      "train loss:0.005678054994093665\n",
      "train loss:0.012106025092136789\n",
      "train loss:0.020491349445088458\n",
      "train loss:0.009568906346310068\n",
      "train loss:0.05503456624235658\n",
      "train loss:0.019310845872204177\n",
      "train loss:0.01379108102042579\n",
      "train loss:0.019043561287686087\n",
      "train loss:0.008388730185422702\n",
      "train loss:0.018281282405703102\n",
      "train loss:0.021799257962456978\n",
      "train loss:0.005766274546771644\n",
      "train loss:0.01480943779671175\n",
      "train loss:0.021185089677758263\n",
      "train loss:0.010765385838387473\n",
      "train loss:0.01951149570280913\n",
      "train loss:0.011131533702104431\n",
      "train loss:0.01860583990037089\n",
      "train loss:0.01691371426081122\n",
      "train loss:0.004287326514007158\n",
      "train loss:0.04267311618086476\n",
      "train loss:0.05922255906104354\n",
      "train loss:0.04112050146540687\n",
      "train loss:0.023883422331859746\n",
      "train loss:0.008503948808180051\n",
      "train loss:0.010748725194635801\n",
      "train loss:0.03023097249614631\n",
      "train loss:0.01083262877270532\n",
      "train loss:0.004182807950809447\n",
      "train loss:0.021627992963774906\n",
      "train loss:0.007280279382935409\n",
      "train loss:0.04197601428671969\n",
      "train loss:0.002150713120588684\n",
      "train loss:0.048432096793165534\n",
      "train loss:0.0070115990346078716\n",
      "train loss:0.009347371649798519\n",
      "train loss:0.012813248309247054\n",
      "train loss:0.012149435106348118\n",
      "train loss:0.006099895661502187\n",
      "train loss:0.003047385750522703\n",
      "train loss:0.009528538054388871\n",
      "train loss:0.009434232075568238\n",
      "train loss:0.005573579036949201\n",
      "train loss:0.014090032716534995\n",
      "train loss:0.0203866360233006\n",
      "train loss:0.014679539954102216\n",
      "train loss:0.013676053044294239\n",
      "train loss:0.0034306360757746794\n",
      "train loss:0.004094123277206903\n",
      "train loss:0.0057040761451427014\n",
      "train loss:0.008158944958297972\n",
      "train loss:0.016213209502512177\n",
      "train loss:0.014773436153000525\n",
      "train loss:0.010727902455029345\n",
      "train loss:0.046283721120997656\n",
      "train loss:0.008352674245919527\n",
      "train loss:0.04173907218127181\n",
      "train loss:0.008057106659144546\n",
      "train loss:0.022676516869034227\n",
      "train loss:0.00532814901635743\n",
      "train loss:0.020521106817526075\n",
      "train loss:0.016865281209120682\n",
      "train loss:0.004949287423181802\n",
      "train loss:0.002705734195558638\n",
      "train loss:0.0013320637022537086\n",
      "train loss:0.037375690960556686\n",
      "train loss:0.03240914515318917\n",
      "train loss:0.008876995573363656\n",
      "train loss:0.01337766211551255\n",
      "train loss:0.017157978690047763\n",
      "train loss:0.018185625635328266\n",
      "train loss:0.012008949745720657\n",
      "train loss:0.006453816858412645\n",
      "train loss:0.026397220471865598\n",
      "train loss:0.004560754383774381\n",
      "train loss:0.07389419246217774\n",
      "train loss:0.007096169339887248\n",
      "train loss:0.04978382230026745\n",
      "train loss:0.03370942693026515\n",
      "train loss:0.0015753573015801709\n",
      "train loss:0.01636468806953475\n",
      "train loss:0.06752253014416358\n",
      "train loss:0.09742186271693183\n",
      "train loss:0.009914590531998842\n",
      "train loss:0.014245554064218924\n",
      "train loss:0.023081597882887436\n",
      "train loss:0.010671495746727124\n",
      "train loss:0.01745464887432207\n",
      "train loss:0.07433883888833659\n",
      "train loss:0.02224221221791798\n",
      "train loss:0.03070940216877994\n",
      "train loss:0.0065849083112812104\n",
      "train loss:0.02109763166468765\n",
      "train loss:0.02159836034310311\n",
      "train loss:0.01983686500968288\n",
      "train loss:0.010280940983801728\n",
      "train loss:0.0378990146706735\n",
      "train loss:0.01308992718748344\n",
      "train loss:0.01872292199599992\n",
      "train loss:0.013696322640943958\n",
      "train loss:0.007975625029239125\n",
      "train loss:0.054317971347352216\n",
      "train loss:0.021539881066784606\n",
      "train loss:0.013876040487405287\n",
      "train loss:0.021097606164354042\n",
      "train loss:0.03703014295076821\n",
      "train loss:0.008520577793181524\n",
      "train loss:0.023844337857427168\n",
      "train loss:0.022062767509240553\n",
      "train loss:0.004793481381553513\n",
      "train loss:0.029186416371680915\n",
      "train loss:0.0138448666667243\n",
      "train loss:0.016559004534007188\n",
      "train loss:0.013923648738113295\n",
      "train loss:0.016471996999250508\n",
      "train loss:0.008122335709715496\n",
      "train loss:0.007926969539372884\n",
      "train loss:0.01727933918704355\n",
      "train loss:0.019902436037250327\n",
      "train loss:0.01777042165083406\n",
      "train loss:0.011703230177408461\n",
      "train loss:0.0030395708819687655\n",
      "train loss:0.021080093350117672\n",
      "=== epoch:7, train acc:0.989, test acc:0.982 ===\n",
      "train loss:0.024538841875329228\n",
      "train loss:0.1757054882247053\n",
      "train loss:0.012506488368012022\n",
      "train loss:0.005019575256648906\n",
      "train loss:0.011791132078433256\n",
      "train loss:0.17810763149876174\n",
      "train loss:0.00452474371313839\n",
      "train loss:0.015127388956909396\n",
      "train loss:0.004316095819608421\n",
      "train loss:0.01626551736953585\n",
      "train loss:0.03031254005836249\n",
      "train loss:0.019406356627090983\n",
      "train loss:0.004780028277594221\n",
      "train loss:0.006652003114805783\n",
      "train loss:0.01882104049486162\n",
      "train loss:0.033980612475091015\n",
      "train loss:0.030135208451582837\n",
      "train loss:0.04028250179079584\n",
      "train loss:0.01334731958238205\n",
      "train loss:0.053090720174092845\n",
      "train loss:0.01052338342013569\n",
      "train loss:0.012161154864741041\n",
      "train loss:0.025257201593983217\n",
      "train loss:0.004484241496152088\n",
      "train loss:0.009749383999465669\n",
      "train loss:0.009399096869294903\n",
      "train loss:0.011264312966972756\n",
      "train loss:0.019139341455682395\n",
      "train loss:0.0050824582420976585\n",
      "train loss:0.02765983385484001\n",
      "train loss:0.0064182814724016764\n",
      "train loss:0.016992225432966156\n",
      "train loss:0.1274439006393747\n",
      "train loss:0.015068231213328422\n",
      "train loss:0.022232629309491922\n",
      "train loss:0.02568290817407547\n",
      "train loss:0.05985466019263711\n",
      "train loss:0.03274764590996011\n",
      "train loss:0.006764850050526458\n",
      "train loss:0.03120516065862907\n",
      "train loss:0.01778047452559461\n",
      "train loss:0.007182318616910286\n",
      "train loss:0.04712217228925899\n",
      "train loss:0.0038286342004700004\n",
      "train loss:0.004611113384347037\n",
      "train loss:0.020922749401670614\n",
      "train loss:0.012681010026409286\n",
      "train loss:0.005625764718606766\n",
      "train loss:0.011732916766346056\n",
      "train loss:0.0057212872615927815\n",
      "train loss:0.045538407544607716\n",
      "train loss:0.027955255709177104\n",
      "train loss:0.0019823993954819165\n",
      "train loss:0.0020499984708679934\n",
      "train loss:0.012971298561810117\n",
      "train loss:0.02615569735678694\n",
      "train loss:0.0027542646571967733\n",
      "train loss:0.019479387471090445\n",
      "train loss:0.023811175349730575\n",
      "train loss:0.03035398123798955\n",
      "train loss:0.019934072174330752\n",
      "train loss:0.007338593685694725\n",
      "train loss:0.002818850131187296\n",
      "train loss:0.05809805649228755\n",
      "train loss:0.012866109343128375\n",
      "train loss:0.016605889951264392\n",
      "train loss:0.01727101147066127\n",
      "train loss:0.03884774770624808\n",
      "train loss:0.028120923537615746\n",
      "train loss:0.005260877620393532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.015915518136876524\n",
      "train loss:0.008172234385503671\n",
      "train loss:0.15123958417916475\n",
      "train loss:0.007546699703375973\n",
      "train loss:0.07241866521456589\n",
      "train loss:0.01427736256949012\n",
      "train loss:0.01558138466537109\n",
      "train loss:0.0044473876219199935\n",
      "train loss:0.006046582183945325\n",
      "train loss:0.03148876384109551\n",
      "train loss:0.03489646144454097\n",
      "train loss:0.00367372779145959\n",
      "train loss:0.012415743485293253\n",
      "train loss:0.016701499275622787\n",
      "train loss:0.024564163472666118\n",
      "train loss:0.05558520652392073\n",
      "train loss:0.013728189529862425\n",
      "train loss:0.0036708716289945886\n",
      "train loss:0.05009693499911301\n",
      "train loss:0.030255808972810633\n",
      "train loss:0.0073985354635428754\n",
      "train loss:0.007789835763184482\n",
      "train loss:0.00430725188962539\n",
      "train loss:0.0042153088532146995\n",
      "train loss:0.005724011662688027\n",
      "train loss:0.02298343427656253\n",
      "train loss:0.10153739064927292\n",
      "train loss:0.014497701724136468\n",
      "train loss:0.030584444446090035\n",
      "train loss:0.028901978709400214\n",
      "train loss:0.016874202257081652\n",
      "train loss:0.020133455514365593\n",
      "train loss:0.014362651520775545\n",
      "train loss:0.0050064379441226705\n",
      "train loss:0.029890327149703334\n",
      "train loss:0.027853721206228442\n",
      "train loss:0.04680152536058014\n",
      "train loss:0.042170389717587436\n",
      "train loss:0.046513570515962555\n",
      "train loss:0.01414530105317\n",
      "train loss:0.007490757930487616\n",
      "train loss:0.005871149040382328\n",
      "train loss:0.02560288649358728\n",
      "train loss:0.04483571750218482\n",
      "train loss:0.00576169038941407\n",
      "train loss:0.044176372351016034\n",
      "train loss:0.037343377559741014\n",
      "train loss:0.007163127820693644\n",
      "train loss:0.014326239909970017\n",
      "train loss:0.016514069342442934\n",
      "train loss:0.02377534406618079\n",
      "train loss:0.014176375804704261\n",
      "train loss:0.009943672163630046\n",
      "train loss:0.020457470094055043\n",
      "train loss:0.009955607181248936\n",
      "train loss:0.021771969567074213\n",
      "train loss:0.019224169408709524\n",
      "train loss:0.002872481358545302\n",
      "train loss:0.006974551534900485\n",
      "train loss:0.023502365880764514\n",
      "train loss:0.011053496812541322\n",
      "train loss:0.012470380924307141\n",
      "train loss:0.014132244591600366\n",
      "train loss:0.007716340858381084\n",
      "train loss:0.03346376624072092\n",
      "train loss:0.0227565452958207\n",
      "train loss:0.015922204814110264\n",
      "train loss:0.017431259258781626\n",
      "train loss:0.02859622492952969\n",
      "train loss:0.015704839923810374\n",
      "train loss:0.015467096592509763\n",
      "train loss:0.02731334777251284\n",
      "train loss:0.01204415403197928\n",
      "train loss:0.005498877221466997\n",
      "train loss:0.0031622127732214844\n",
      "train loss:0.010421395346934613\n",
      "train loss:0.010215543605821487\n",
      "train loss:0.009415544507863059\n",
      "train loss:0.034828179758952915\n",
      "train loss:0.015468341933669973\n",
      "train loss:0.019344948578427532\n",
      "train loss:0.0051963352941687725\n",
      "train loss:0.02009649390383788\n",
      "train loss:0.005541010062818168\n",
      "train loss:0.01478609564357309\n",
      "train loss:0.049026696370524245\n",
      "train loss:0.022204152923268283\n",
      "train loss:0.027950429209728546\n",
      "train loss:0.017172611239320016\n",
      "train loss:0.012917432302033034\n",
      "train loss:0.03187118992449422\n",
      "train loss:0.072944502755565\n",
      "train loss:0.017732409360249633\n",
      "train loss:0.008686392463599663\n",
      "train loss:0.006843864580506575\n",
      "train loss:0.010348532429989782\n",
      "train loss:0.020105485552133363\n",
      "train loss:0.035514798703517265\n",
      "train loss:0.018944876760243156\n",
      "train loss:0.0255287981402188\n",
      "train loss:0.029011558281283985\n",
      "train loss:0.0032750568507880695\n",
      "train loss:0.00628209419970949\n",
      "train loss:0.007063896492607258\n",
      "train loss:0.13466588926972006\n",
      "train loss:0.0026211483659456286\n",
      "train loss:0.008739138315647021\n",
      "train loss:0.008598816945950346\n",
      "train loss:0.01768075528390584\n",
      "train loss:0.003562700140237544\n",
      "train loss:0.0026015568800733164\n",
      "train loss:0.005755994194159175\n",
      "train loss:0.0021928131616912126\n",
      "train loss:0.05001985419445604\n",
      "train loss:0.01497852715198611\n",
      "train loss:0.006672635310384287\n",
      "train loss:0.009427467358776963\n",
      "train loss:0.0163127778737605\n",
      "train loss:0.00771143627942809\n",
      "train loss:0.017497024715883373\n",
      "train loss:0.010265295091156014\n",
      "train loss:0.014144865047942717\n",
      "train loss:0.0035883343408132373\n",
      "train loss:0.00921062780441115\n",
      "train loss:0.005016288114445515\n",
      "train loss:0.008349477136562377\n",
      "train loss:0.03333651813361017\n",
      "train loss:0.034115693089463786\n",
      "train loss:0.009443133819099598\n",
      "train loss:0.024991584000647667\n",
      "train loss:0.10227436312608865\n",
      "train loss:0.04722597891586553\n",
      "train loss:0.004929635131522083\n",
      "train loss:0.015372645326622345\n",
      "train loss:0.06547591358436496\n",
      "train loss:0.06906004210172474\n",
      "train loss:0.017318969221678707\n",
      "train loss:0.007032612225969538\n",
      "train loss:0.04617533365836723\n",
      "train loss:0.0131475636857758\n",
      "train loss:0.026843719002760884\n",
      "train loss:0.020640554068016254\n",
      "train loss:0.018641351055339456\n",
      "train loss:0.020352210561179064\n",
      "train loss:0.004096678473096509\n",
      "train loss:0.04027495826064463\n",
      "train loss:0.01820012319462221\n",
      "train loss:0.014018516036439516\n",
      "train loss:0.03542353792244873\n",
      "train loss:0.03878331702305262\n",
      "train loss:0.0023065401718340662\n",
      "train loss:0.03132848603612612\n",
      "train loss:0.030517855117516323\n",
      "train loss:0.02492803649755416\n",
      "train loss:0.009135894545835825\n",
      "train loss:0.02725961726484745\n",
      "train loss:0.010840784008303817\n",
      "train loss:0.0363531198153414\n",
      "train loss:0.037670164032380805\n",
      "train loss:0.012276595848687162\n",
      "train loss:0.020911031059348953\n",
      "train loss:0.07340503576007751\n",
      "train loss:0.004463677295062053\n",
      "train loss:0.008668135252119123\n",
      "train loss:0.0014447125854109761\n",
      "train loss:0.004390952597390267\n",
      "train loss:0.011484326585918461\n",
      "train loss:0.0035621809729382598\n",
      "train loss:0.005245749274618608\n",
      "train loss:0.015878738835069708\n",
      "train loss:0.02936102993151291\n",
      "train loss:0.0021756285779914166\n",
      "train loss:0.012570570343887017\n",
      "train loss:0.01425625231057503\n",
      "train loss:0.03650825261488927\n",
      "train loss:0.0015662046156740765\n",
      "train loss:0.004330996890769906\n",
      "train loss:0.0057807525476227225\n",
      "train loss:0.007696231486196169\n",
      "train loss:0.005029524148056511\n",
      "train loss:0.032812547417002576\n",
      "train loss:0.0097611267464563\n",
      "train loss:0.012673596447929269\n",
      "train loss:0.0047824158960260744\n",
      "train loss:0.04468419784564777\n",
      "train loss:0.003940702349238104\n",
      "train loss:0.004653627043322066\n",
      "train loss:0.029763128447264395\n",
      "train loss:0.022407586705785163\n",
      "train loss:0.010705764515681756\n",
      "train loss:0.012839203842006416\n",
      "train loss:0.01052198096282771\n",
      "train loss:0.02140244082755603\n",
      "train loss:0.021040419393744802\n",
      "train loss:0.006570186916413102\n",
      "train loss:0.0037561996959926598\n",
      "train loss:0.004676918129997842\n",
      "train loss:0.038246124850585074\n",
      "train loss:0.0082289165271375\n",
      "train loss:0.036299190773601435\n",
      "train loss:0.020127555546984713\n",
      "train loss:0.04655741053387618\n",
      "train loss:0.01658312666989963\n",
      "train loss:0.022447458404845907\n",
      "train loss:0.017469747068095263\n",
      "train loss:0.004700911842753717\n",
      "train loss:0.05073969291537838\n",
      "train loss:0.024982528993697958\n",
      "train loss:0.014906992384325668\n",
      "train loss:0.06753315171091005\n",
      "train loss:0.016551133651421458\n",
      "train loss:0.014904907802525211\n",
      "train loss:0.007437207280139912\n",
      "train loss:0.009683609029276057\n",
      "train loss:0.02276247619326034\n",
      "train loss:0.03596428669064562\n",
      "train loss:0.02233397753813655\n",
      "train loss:0.0015629662734937388\n",
      "train loss:0.015597153634436407\n",
      "train loss:0.03952266412991837\n",
      "train loss:0.11625067551550458\n",
      "train loss:0.03828152687696776\n",
      "train loss:0.019760552658228098\n",
      "train loss:0.0060161117892318025\n",
      "train loss:0.017754054243918196\n",
      "train loss:0.028781111457017325\n",
      "train loss:0.020482489831801974\n",
      "train loss:0.005165995006181348\n",
      "train loss:0.04554081284641613\n",
      "train loss:0.011897714021483199\n",
      "train loss:0.0024591773305924895\n",
      "train loss:0.023984621584416096\n",
      "train loss:0.023926840162262507\n",
      "train loss:0.03856371604105306\n",
      "train loss:0.005798593789241549\n",
      "train loss:0.010614317050378243\n",
      "train loss:0.006983348084471659\n",
      "train loss:0.002553897530063301\n",
      "train loss:0.0154357873786973\n",
      "train loss:0.006718924141340308\n",
      "train loss:0.029249282530490035\n",
      "train loss:0.012536211070286548\n",
      "train loss:0.01998170802938506\n",
      "train loss:0.004446260516116769\n",
      "train loss:0.016474591403331157\n",
      "train loss:0.03855933950096791\n",
      "train loss:0.006021939475227183\n",
      "train loss:0.015876099517722154\n",
      "train loss:0.01926141054396259\n",
      "train loss:0.0023242416466715283\n",
      "train loss:0.015680990310204104\n",
      "train loss:0.00688615008213197\n",
      "train loss:0.06862926833373377\n",
      "train loss:0.04572091997616774\n",
      "train loss:0.007023367366559613\n",
      "train loss:0.0016648680531352004\n",
      "train loss:0.023125248045853534\n",
      "train loss:0.0020886030411909028\n",
      "train loss:0.0019474101405294849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.055453628156528635\n",
      "train loss:0.014894543313873103\n",
      "train loss:0.022725671753401268\n",
      "train loss:0.0051546412331764345\n",
      "train loss:0.02781978184004545\n",
      "train loss:0.010709859286413445\n",
      "train loss:0.0034472004156620387\n",
      "train loss:0.003072467264193567\n",
      "train loss:0.024650292587355134\n",
      "train loss:0.009472750062839774\n",
      "train loss:0.006152950432458764\n",
      "train loss:0.011525325035891607\n",
      "train loss:0.041180293347758364\n",
      "train loss:0.009984463900225102\n",
      "train loss:0.01165405558593422\n",
      "train loss:0.004651146370460442\n",
      "train loss:0.029705358285504385\n",
      "train loss:0.02456420114252\n",
      "train loss:0.0098487810154167\n",
      "train loss:0.009143556161041655\n",
      "train loss:0.031360982050279415\n",
      "train loss:0.028024660752723012\n",
      "train loss:0.03746442748402985\n",
      "train loss:0.018484011751809047\n",
      "train loss:0.00844271733074989\n",
      "train loss:0.007528324829352912\n",
      "train loss:0.020091838239584037\n",
      "train loss:0.054414331633494094\n",
      "train loss:0.004679357500874968\n",
      "train loss:0.005837470416060824\n",
      "train loss:0.012317842820112543\n",
      "train loss:0.0034319390683958282\n",
      "train loss:0.01286015054604141\n",
      "train loss:0.008603159256966489\n",
      "train loss:0.028096958855800512\n",
      "train loss:0.03827074282150486\n",
      "train loss:0.06904057490087812\n",
      "train loss:0.009593339670796822\n",
      "train loss:0.010690070868439672\n",
      "train loss:0.00966451625164208\n",
      "train loss:0.011362455034741417\n",
      "train loss:0.0445111712281463\n",
      "train loss:0.012738708167550255\n",
      "train loss:0.021422001499271953\n",
      "train loss:0.027978682462382172\n",
      "train loss:0.013710780933150826\n",
      "train loss:0.004534937399305523\n",
      "train loss:0.011771604691380515\n",
      "train loss:0.0026256020725935235\n",
      "train loss:0.023190336125045844\n",
      "train loss:0.01366618526618618\n",
      "train loss:0.013597377980206297\n",
      "train loss:0.004817948653471854\n",
      "train loss:0.010782888474088875\n",
      "train loss:0.0007779535557078997\n",
      "train loss:0.00868769447589376\n",
      "train loss:0.009131662993587359\n",
      "train loss:0.014723786172222787\n",
      "train loss:0.0044435057603622935\n",
      "train loss:0.00740677612260714\n",
      "train loss:0.04451203596730531\n",
      "train loss:0.009728639225972072\n",
      "train loss:0.006201806036041645\n",
      "train loss:0.005083629982683259\n",
      "train loss:0.011397479032742498\n",
      "train loss:0.006461881861980962\n",
      "train loss:0.0072267226795564255\n",
      "train loss:0.0173943204933358\n",
      "train loss:0.10424451662439932\n",
      "train loss:0.006101602914145354\n",
      "train loss:0.0029203194834034442\n",
      "train loss:0.010108673808553802\n",
      "train loss:0.007460611263768899\n",
      "train loss:0.0019323960545859777\n",
      "train loss:0.013954341647339863\n",
      "train loss:0.011950255946709015\n",
      "train loss:0.003098434353142768\n",
      "train loss:0.006371058378800029\n",
      "train loss:0.027617579164822315\n",
      "train loss:0.009955408221012164\n",
      "train loss:0.014709469613818124\n",
      "train loss:0.0056864184907091265\n",
      "train loss:0.01160681830062902\n",
      "train loss:0.005847395817434358\n",
      "train loss:0.038751879934140615\n",
      "train loss:0.01629720037181848\n",
      "train loss:0.006816282063582545\n",
      "train loss:0.002736682459331472\n",
      "train loss:0.005971271919487423\n",
      "train loss:0.03831742878039666\n",
      "train loss:0.00303867361739816\n",
      "train loss:0.014149283948177221\n",
      "train loss:0.03721050162997301\n",
      "train loss:0.00810564593280753\n",
      "train loss:0.0009844945466733568\n",
      "train loss:0.0017394661653938276\n",
      "train loss:0.010351154757893919\n",
      "train loss:0.0020590593949867337\n",
      "train loss:0.10264572750369017\n",
      "train loss:0.0052257665382092425\n",
      "train loss:0.06685058719948471\n",
      "train loss:0.002591679575546307\n",
      "train loss:0.009746658163541614\n",
      "train loss:0.007621319409847099\n",
      "train loss:0.032653111612892104\n",
      "train loss:0.022341691656221793\n",
      "train loss:0.00678370680950938\n",
      "train loss:0.010912306499707057\n",
      "train loss:0.014295273881780346\n",
      "train loss:0.00545519546718503\n",
      "train loss:0.03974342436771173\n",
      "train loss:0.011026058094488247\n",
      "train loss:0.002609760543051334\n",
      "train loss:0.008718301754049309\n",
      "train loss:0.0204523931423678\n",
      "train loss:0.014239826268600621\n",
      "train loss:0.011343257734236245\n",
      "train loss:0.006343117480525981\n",
      "train loss:0.00849584512685358\n",
      "train loss:0.05405097764189115\n",
      "train loss:0.0391852197110126\n",
      "train loss:0.009146560564318233\n",
      "train loss:0.005585797982643162\n",
      "train loss:0.004233008919944629\n",
      "train loss:0.008703422018754741\n",
      "train loss:0.054906063869272374\n",
      "train loss:0.015366737575608436\n",
      "train loss:0.11116145386291627\n",
      "train loss:0.03726357623411381\n",
      "train loss:0.008967848838843405\n",
      "train loss:0.013014299702734622\n",
      "train loss:0.007222027472582251\n",
      "train loss:0.014914296385313006\n",
      "train loss:0.00872925749065718\n",
      "train loss:0.004659124772014671\n",
      "train loss:0.014930429197581703\n",
      "train loss:0.008537515625634635\n",
      "train loss:0.015816041793157605\n",
      "train loss:0.0395242682636191\n",
      "train loss:0.0417564030543433\n",
      "train loss:0.005193838635520388\n",
      "train loss:0.012973144875675106\n",
      "train loss:0.02230929256941031\n",
      "train loss:0.004805209352960853\n",
      "train loss:0.0196679291240073\n",
      "train loss:0.009824469355279973\n",
      "train loss:0.013784387609781252\n",
      "train loss:0.06252500220761671\n",
      "train loss:0.00628202432127111\n",
      "train loss:0.004589573776364026\n",
      "train loss:0.014601438889234947\n",
      "train loss:0.0043600476005977995\n",
      "train loss:0.0077269269893159125\n",
      "train loss:0.013226207863550476\n",
      "train loss:0.00875481679979371\n",
      "train loss:0.004076017909384517\n",
      "train loss:0.005952111486652982\n",
      "train loss:0.00944429841269263\n",
      "train loss:0.00936137137572818\n",
      "train loss:0.0073049974246074175\n",
      "train loss:0.0014719216704324435\n",
      "train loss:0.007786543027598094\n",
      "train loss:0.016959568821392424\n",
      "train loss:0.006244541671458983\n",
      "train loss:0.003127490482503706\n",
      "train loss:0.012223404314699794\n",
      "train loss:0.009459205233971556\n",
      "train loss:0.037539738689309\n",
      "train loss:0.005684309738238703\n",
      "train loss:0.010639750676003843\n",
      "train loss:0.0032870883108849663\n",
      "train loss:0.009853798592386886\n",
      "train loss:0.004031760861243605\n",
      "train loss:0.03606436110350447\n",
      "train loss:0.007702388103311048\n",
      "train loss:0.014058148393714076\n",
      "train loss:0.017749016571333095\n",
      "train loss:0.021984704673416847\n",
      "train loss:0.0016119607320397627\n",
      "train loss:0.01725828564109535\n",
      "train loss:0.012625154703210685\n",
      "train loss:0.014986279511887897\n",
      "train loss:0.01836275517103049\n",
      "train loss:0.0030344350053456465\n",
      "train loss:0.00260074615768121\n",
      "train loss:0.003225222703876175\n",
      "train loss:0.013828362067031417\n",
      "train loss:0.014516235127192086\n",
      "train loss:0.03227351816836206\n",
      "train loss:0.017850066805927788\n",
      "train loss:0.010639939003120458\n",
      "train loss:0.015370899794636447\n",
      "train loss:0.050890364731542646\n",
      "train loss:0.01850478118933256\n",
      "train loss:0.005159467520274499\n",
      "train loss:0.00439608266817338\n",
      "train loss:0.0381492432909412\n",
      "train loss:0.014615489679055984\n",
      "train loss:0.0013648547794764129\n",
      "train loss:0.007243358548442619\n",
      "train loss:0.0035077519828307256\n",
      "train loss:0.03632919206040333\n",
      "train loss:0.006070136013695608\n",
      "train loss:0.011976953486041856\n",
      "train loss:0.01159328122523955\n",
      "train loss:0.015168935818237332\n",
      "train loss:0.0033269732578439628\n",
      "train loss:0.042408760699605204\n",
      "train loss:0.00669187900376279\n",
      "train loss:0.02641626884595318\n",
      "train loss:0.01054341196776789\n",
      "train loss:0.0072833911952540995\n",
      "train loss:0.0037559524224155157\n",
      "train loss:0.056377283645895754\n",
      "train loss:0.0028721522173662194\n",
      "train loss:0.005698737646474173\n",
      "train loss:0.04209621132866996\n",
      "train loss:0.003124638691226057\n",
      "train loss:0.0019856047420316113\n",
      "train loss:0.02465473443390487\n",
      "train loss:0.014683875989241237\n",
      "train loss:0.013641745044020024\n",
      "train loss:0.030602467453547416\n",
      "train loss:0.005686354362890176\n",
      "train loss:0.05250911003515224\n",
      "train loss:0.0016104195930051446\n",
      "train loss:0.00883790072947866\n",
      "train loss:0.030653248572327093\n",
      "train loss:0.011927119425712507\n",
      "train loss:0.004714750977024444\n",
      "train loss:0.0065006273924581946\n",
      "train loss:0.00547348369711247\n",
      "train loss:0.003437839052330711\n",
      "train loss:0.04225428102233333\n",
      "train loss:0.005763077923503025\n",
      "train loss:0.005989765774176147\n",
      "train loss:0.002638980133917262\n",
      "train loss:0.001323158684310809\n",
      "train loss:0.0052869205468198555\n",
      "train loss:0.0028182642569554057\n",
      "train loss:0.00637787938007679\n",
      "train loss:0.006496710367147465\n",
      "train loss:0.04170941024714014\n",
      "train loss:0.004078153953284131\n",
      "train loss:0.010913770495058315\n",
      "train loss:0.002702714277518658\n",
      "train loss:0.03938623580528737\n",
      "train loss:0.003866063533963299\n",
      "train loss:0.006039718008444895\n",
      "train loss:0.010682654537203531\n",
      "train loss:0.008526836230827036\n",
      "train loss:0.0024835746099850977\n",
      "train loss:0.005937964432870887\n",
      "train loss:0.00656259117005638\n",
      "train loss:0.004382695109521161\n",
      "train loss:0.0038147001066166798\n",
      "train loss:0.054275337174156925\n",
      "train loss:0.018759096332407896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.05498025709140233\n",
      "train loss:0.01656306773539079\n",
      "train loss:0.006256220047527625\n",
      "train loss:0.005797147734051582\n",
      "train loss:0.008608667185438535\n",
      "train loss:0.03291698038861672\n",
      "train loss:0.0063765202136378705\n",
      "train loss:0.00856290392037449\n",
      "train loss:0.0032500054890964337\n",
      "train loss:0.003288617391402664\n",
      "train loss:0.0063740857856435665\n",
      "train loss:0.03221736352018073\n",
      "train loss:0.0019147729406309261\n",
      "=== epoch:8, train acc:0.988, test acc:0.981 ===\n",
      "train loss:0.007580180660192854\n",
      "train loss:0.009345539882603377\n",
      "train loss:0.0112073423266903\n",
      "train loss:0.00500776551782511\n",
      "train loss:0.01507639142210122\n",
      "train loss:0.003332524070071619\n",
      "train loss:0.0025495389405388734\n",
      "train loss:0.0012384311784933173\n",
      "train loss:0.008483631457013842\n",
      "train loss:0.02487834677200324\n",
      "train loss:0.00920712038243871\n",
      "train loss:0.008922579860502393\n",
      "train loss:0.027679339964340098\n",
      "train loss:0.0036973159547893995\n",
      "train loss:0.04450148823055456\n",
      "train loss:0.0033582207913474427\n",
      "train loss:0.015664135721677644\n",
      "train loss:0.008188468916713215\n",
      "train loss:0.006160891558708657\n",
      "train loss:0.00578972169699099\n",
      "train loss:0.018816523258434206\n",
      "train loss:0.00820599560426187\n",
      "train loss:0.0009346100703256019\n",
      "train loss:0.0035600298696435973\n",
      "train loss:0.006088710633810893\n",
      "train loss:0.0033477215833424543\n",
      "train loss:0.008013543259403167\n",
      "train loss:0.0027753740498980863\n",
      "train loss:0.007054068506375996\n",
      "train loss:0.0017778793431246188\n",
      "train loss:0.00404628848212089\n",
      "train loss:0.003971643270721172\n",
      "train loss:0.02736438772049504\n",
      "train loss:0.02511040738534412\n",
      "train loss:0.0075346765348728905\n",
      "train loss:0.007080487422975773\n",
      "train loss:0.01425973091504659\n",
      "train loss:0.012607181275912236\n",
      "train loss:0.0020836703355538964\n",
      "train loss:0.006729939136910061\n",
      "train loss:0.028195703747342996\n",
      "train loss:0.004685130627168641\n",
      "train loss:0.007019161406576362\n",
      "train loss:0.018127427706745705\n",
      "train loss:0.00635493019989468\n",
      "train loss:0.0117957740655273\n",
      "train loss:0.004426829451900287\n",
      "train loss:0.015222337202193239\n",
      "train loss:0.060679056658718734\n",
      "train loss:0.006056471475110621\n",
      "train loss:0.004234549550657867\n",
      "train loss:0.0055598408695714694\n",
      "train loss:0.009634380355102494\n",
      "train loss:0.002836528583534626\n",
      "train loss:0.12667131464230258\n",
      "train loss:0.019586751029969027\n",
      "train loss:0.0047363378406076115\n",
      "train loss:0.06568213729147293\n",
      "train loss:0.04873977759197599\n",
      "train loss:0.004873682957829539\n",
      "train loss:0.013830536720001854\n",
      "train loss:0.010116077363041648\n",
      "train loss:0.03025132614822629\n",
      "train loss:0.02724700588444509\n",
      "train loss:0.01537094682923489\n",
      "train loss:0.004433434940978032\n",
      "train loss:0.01392502604241178\n",
      "train loss:0.0031926343704560766\n",
      "train loss:0.002302337353822622\n",
      "train loss:0.03400279079785036\n",
      "train loss:0.0020430626369657558\n",
      "train loss:0.010037064059911867\n",
      "train loss:0.006051002343635824\n",
      "train loss:0.007820754045383283\n",
      "train loss:0.052929462451506114\n",
      "train loss:0.00759981508517578\n",
      "train loss:0.004739816179718172\n",
      "train loss:0.02207235850970485\n",
      "train loss:0.009811338662210213\n",
      "train loss:0.0037265140684206288\n",
      "train loss:0.010744460598951157\n",
      "train loss:0.006086906763243047\n",
      "train loss:0.0018479531725981346\n",
      "train loss:0.007337026224395669\n",
      "train loss:0.010861245620485065\n",
      "train loss:0.014638855915179954\n",
      "train loss:0.00788316846984649\n",
      "train loss:0.007451679313100476\n",
      "train loss:0.00896394524039807\n",
      "train loss:0.010196618842382339\n",
      "train loss:0.024153696003581405\n",
      "train loss:0.024820067426979096\n",
      "train loss:0.00910477422653022\n",
      "train loss:0.011186489950788471\n",
      "train loss:0.014233358898933735\n",
      "train loss:0.027621848877387056\n",
      "train loss:0.005781703069736973\n",
      "train loss:0.007327891860501943\n",
      "train loss:0.004486076826217687\n",
      "train loss:0.025952981430261722\n",
      "train loss:0.006219455770377299\n",
      "train loss:0.008671297584003921\n",
      "train loss:0.004780473763105254\n",
      "train loss:0.02179850131653317\n",
      "train loss:0.004071120764189974\n",
      "train loss:0.010152421149334647\n",
      "train loss:0.006237017903709195\n",
      "train loss:0.009028181544488471\n",
      "train loss:0.027191691087484253\n",
      "train loss:0.004652816541012474\n",
      "train loss:0.008891427394804596\n",
      "train loss:0.011137894614616126\n",
      "train loss:0.0192561201601986\n",
      "train loss:0.020630033378324114\n",
      "train loss:0.0193269731735579\n",
      "train loss:0.02010268564245802\n",
      "train loss:0.007070920476816927\n",
      "train loss:0.014166368637181426\n",
      "train loss:0.028445584268945136\n",
      "train loss:0.0315226696541626\n",
      "train loss:0.009196408623139127\n",
      "train loss:0.007398031441534995\n",
      "train loss:0.0017585958597735702\n",
      "train loss:0.0025446834959362164\n",
      "train loss:0.006312874560167143\n",
      "train loss:0.004379571415590817\n",
      "train loss:0.0022822212604678978\n",
      "train loss:0.005103095442204637\n",
      "train loss:0.020764467200459307\n",
      "train loss:0.01185126696280835\n",
      "train loss:0.012662346196225907\n",
      "train loss:0.030053033790529305\n",
      "train loss:0.0031377393004666495\n",
      "train loss:0.003672415994088117\n",
      "train loss:0.0035506287837850686\n",
      "train loss:0.006040558593374589\n",
      "train loss:0.020668201687484018\n",
      "train loss:0.014667654143299234\n",
      "train loss:0.005426502481042507\n",
      "train loss:0.011104796597804585\n",
      "train loss:0.02955302917784763\n",
      "train loss:0.041104234722434144\n",
      "train loss:0.010850839878884013\n",
      "train loss:0.015364305110104956\n",
      "train loss:0.005238072592591471\n",
      "train loss:0.017233920810535687\n",
      "train loss:0.052084146110091066\n",
      "train loss:0.0051826239768333025\n",
      "train loss:0.01742296068953986\n",
      "train loss:0.022717176152404386\n",
      "train loss:0.0009367256805297386\n",
      "train loss:0.01761452414493348\n",
      "train loss:0.007379656289029543\n",
      "train loss:0.047313533124120656\n",
      "train loss:0.008610661475011615\n",
      "train loss:0.005636815227676898\n",
      "train loss:0.006570218085435986\n",
      "train loss:0.015261623203999547\n",
      "train loss:0.0069358406223636315\n",
      "train loss:0.015574281017548515\n",
      "train loss:0.007339210758055361\n",
      "train loss:0.00431085518230689\n",
      "train loss:0.012134758867380569\n",
      "train loss:0.007474705165813603\n",
      "train loss:0.012666389686472995\n",
      "train loss:0.05025828055861023\n",
      "train loss:0.011379891815205743\n",
      "train loss:0.00841910993637312\n",
      "train loss:0.0032184162994694943\n",
      "train loss:0.0042026714462190164\n",
      "train loss:0.0024746281951835082\n",
      "train loss:0.04645723942516015\n",
      "train loss:0.0089341788131843\n",
      "train loss:0.006596059370061342\n",
      "train loss:0.007232795413515917\n",
      "train loss:0.016373448921169903\n",
      "train loss:0.044923739437179415\n",
      "train loss:0.0747261592618347\n",
      "train loss:0.00654713599008685\n",
      "train loss:0.003012873151445078\n",
      "train loss:0.0011554416905106726\n",
      "train loss:0.010071706295836019\n",
      "train loss:0.003074800348092209\n",
      "train loss:0.05801997694399147\n",
      "train loss:0.028458523312983444\n",
      "train loss:0.005921750887196792\n",
      "train loss:0.005585007695575668\n",
      "train loss:0.02699875164890282\n",
      "train loss:0.015966262227413156\n",
      "train loss:0.008217884620522392\n",
      "train loss:0.0055387606471114905\n",
      "train loss:0.0008498442038076956\n",
      "train loss:0.010989175732687215\n",
      "train loss:0.002542451671899879\n",
      "train loss:0.05308134313525979\n",
      "train loss:0.007283802747871239\n",
      "train loss:0.014634928142816417\n",
      "train loss:0.017230073516940496\n",
      "train loss:0.019820782588520314\n",
      "train loss:0.005113204049528872\n",
      "train loss:0.028029883995646765\n",
      "train loss:0.005031254838503604\n",
      "train loss:0.028303538369375363\n",
      "train loss:0.0421674670396375\n",
      "train loss:0.0025795758799390402\n",
      "train loss:0.0049761764797186265\n",
      "train loss:0.03438659412002128\n",
      "train loss:0.008840296552972176\n",
      "train loss:0.036464377352305004\n",
      "train loss:0.0022664899758526474\n",
      "train loss:0.017033134929567456\n",
      "train loss:0.028847676404652228\n",
      "train loss:0.010336231756290348\n",
      "train loss:0.015805977781546098\n",
      "train loss:0.03050500125627907\n",
      "train loss:0.03345163940299971\n",
      "train loss:0.1094092131118207\n",
      "train loss:0.004262166792979133\n",
      "train loss:0.004003106138615025\n",
      "train loss:0.0102914317541722\n",
      "train loss:0.008893317650604596\n",
      "train loss:0.005669739865425467\n",
      "train loss:0.012250570400880593\n",
      "train loss:0.014654274417129813\n",
      "train loss:0.008961397937291582\n",
      "train loss:0.017454241286174434\n",
      "train loss:0.008161568705478224\n",
      "train loss:0.006808886823209749\n",
      "train loss:0.0038721165464312003\n",
      "train loss:0.01488946397931279\n",
      "train loss:0.006027445446998061\n",
      "train loss:0.014304369496107631\n",
      "train loss:0.009325329886675435\n",
      "train loss:0.006792217540512597\n",
      "train loss:0.008890052826397401\n",
      "train loss:0.0016983483938660083\n",
      "train loss:0.012542426728326029\n",
      "train loss:0.00287362796083782\n",
      "train loss:0.012314991441650708\n",
      "train loss:0.0037834184553219626\n",
      "train loss:0.022445074420085243\n",
      "train loss:0.005724303441450565\n",
      "train loss:0.004768077010336131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.017903364471122313\n",
      "train loss:0.017954139930271493\n",
      "train loss:0.023360683272292654\n",
      "train loss:0.016343085366095713\n",
      "train loss:0.003444115598507816\n",
      "train loss:0.0065318436274143694\n",
      "train loss:0.008951590391540434\n",
      "train loss:0.02972376813959905\n",
      "train loss:0.0027966023945639458\n",
      "train loss:0.004283793839361836\n",
      "train loss:0.0032570060485558054\n",
      "train loss:0.004085109846404473\n",
      "train loss:0.0035718803634840718\n",
      "train loss:0.036956217925669874\n",
      "train loss:0.007328748499546714\n",
      "train loss:0.00905933824663345\n",
      "train loss:0.029845564250180624\n",
      "train loss:0.016925146050283293\n",
      "train loss:0.0022308163753459436\n",
      "train loss:0.001626079180458924\n",
      "train loss:0.004352195151902486\n",
      "train loss:0.017805794191388943\n",
      "train loss:0.012163322485820229\n",
      "train loss:0.011080426746263285\n",
      "train loss:0.0033453307470130518\n",
      "train loss:0.005611940076560196\n",
      "train loss:0.006426603083864457\n",
      "train loss:0.0056427991124156475\n",
      "train loss:0.004016699648532688\n",
      "train loss:0.03415494184873554\n",
      "train loss:0.00881981118168015\n",
      "train loss:0.02868871107483807\n",
      "train loss:0.0019872730810095015\n",
      "train loss:0.005978672559491793\n",
      "train loss:0.005041679123136644\n",
      "train loss:0.005292755721125558\n",
      "train loss:0.025887641753162202\n",
      "train loss:0.006805634332447683\n",
      "train loss:0.003435726074638361\n",
      "train loss:0.004929696860868028\n",
      "train loss:0.0072571458337787565\n",
      "train loss:0.0049378910719140665\n",
      "train loss:0.0008719652524160369\n",
      "train loss:0.003068134356483985\n",
      "train loss:0.005902816556124995\n",
      "train loss:0.0014659100395418248\n",
      "train loss:0.00392830026152309\n",
      "train loss:0.0046205786001525\n",
      "train loss:0.0037372191661392716\n",
      "train loss:0.005223107293105034\n",
      "train loss:0.04425630048898056\n",
      "train loss:0.019857253716875793\n",
      "train loss:0.011688953635379999\n",
      "train loss:0.001392582928871714\n",
      "train loss:0.0013539348205013704\n",
      "train loss:0.0038905333183489738\n",
      "train loss:0.007237275128783321\n",
      "train loss:0.007232662262498084\n",
      "train loss:0.03234459568330616\n",
      "train loss:0.024480626362931263\n",
      "train loss:0.0024318147518613974\n",
      "train loss:0.026495895852303254\n",
      "train loss:0.004204239365669181\n",
      "train loss:0.0028566407215935893\n",
      "train loss:0.0014249875114234307\n",
      "train loss:0.002904015318437309\n",
      "train loss:0.003092296540716044\n",
      "train loss:0.017252816885444788\n",
      "train loss:0.011647438022590686\n",
      "train loss:0.008149151225457597\n",
      "train loss:0.005056729342179048\n",
      "train loss:0.008564072064879462\n",
      "train loss:0.010485921333209622\n",
      "train loss:0.002634503699946363\n",
      "train loss:0.016813471634098763\n",
      "train loss:0.02595951615061117\n",
      "train loss:0.0013794011074223448\n",
      "train loss:0.0025947593530784158\n",
      "train loss:0.023626314606139683\n",
      "train loss:0.07338067475014133\n",
      "train loss:0.0029826044097298644\n",
      "train loss:0.010271081436339417\n",
      "train loss:0.007906526514857784\n",
      "train loss:0.00224319627797897\n",
      "train loss:0.0022080927281929548\n",
      "train loss:0.03920046969386027\n",
      "train loss:0.003910328820155364\n",
      "train loss:0.008560373803485313\n",
      "train loss:0.0025692312078928353\n",
      "train loss:0.0424698701146956\n",
      "train loss:0.009602358113841329\n",
      "train loss:0.029398817598632495\n",
      "train loss:0.007498048849448236\n",
      "train loss:0.004212404021776884\n",
      "train loss:0.009069634944785137\n",
      "train loss:0.011485943727352111\n",
      "train loss:0.004192256489570522\n",
      "train loss:0.003869800765794008\n",
      "train loss:0.017754759453464827\n",
      "train loss:0.026974773613678057\n",
      "train loss:0.008897186003505664\n",
      "train loss:0.009151237016034262\n",
      "train loss:0.017617073421084265\n",
      "train loss:0.020458285454224096\n",
      "train loss:0.004439361395344147\n",
      "train loss:0.006196625931749351\n",
      "train loss:0.007290478642508563\n",
      "train loss:0.023864487714336538\n",
      "train loss:0.003243311204768612\n",
      "train loss:0.0029852893573038886\n",
      "train loss:0.0062231008578806065\n",
      "train loss:0.03250109430383151\n",
      "train loss:0.03263452275686249\n",
      "train loss:0.005820086089964788\n",
      "train loss:0.013769524425204578\n",
      "train loss:0.02260930458659257\n",
      "train loss:0.005092264974729106\n",
      "train loss:0.005202150483064491\n",
      "train loss:0.0013192372189786378\n",
      "train loss:0.00416868746630747\n",
      "train loss:0.010316681791821032\n",
      "train loss:0.0032473304111558746\n",
      "train loss:0.0042612306174353645\n",
      "train loss:0.007138352305579854\n",
      "train loss:0.030923861757194495\n",
      "train loss:0.015340208799848926\n",
      "train loss:0.03497203468521415\n",
      "train loss:0.005720943105947871\n",
      "train loss:0.01795209856517283\n",
      "train loss:0.0031586376710576107\n",
      "train loss:0.004819242950197323\n",
      "train loss:0.025045677174739888\n",
      "train loss:0.004864366060674101\n",
      "train loss:0.04353513901989332\n",
      "train loss:0.03802308933640111\n",
      "train loss:0.07079031645691723\n",
      "train loss:0.02370163465814189\n",
      "train loss:0.0012085037193781515\n",
      "train loss:0.008350759170053488\n",
      "train loss:0.023687675032247207\n",
      "train loss:0.024405661745163735\n",
      "train loss:0.02006774521490771\n",
      "train loss:0.014759410107502846\n",
      "train loss:0.005015945928318883\n",
      "train loss:0.03571519720419788\n",
      "train loss:0.010840771272164795\n",
      "train loss:0.042373027024067096\n",
      "train loss:0.017446177829622173\n",
      "train loss:0.007764041313838932\n",
      "train loss:0.01861117464951008\n",
      "train loss:0.0008014121662723274\n",
      "train loss:0.014771880661098559\n",
      "train loss:0.030122214741794776\n",
      "train loss:0.006613601516863628\n",
      "train loss:0.016439548679806227\n",
      "train loss:0.004820012420904299\n",
      "train loss:0.0041040521050847815\n",
      "train loss:0.040303827111662686\n",
      "train loss:0.0028783270181069066\n",
      "train loss:0.008022265171376736\n",
      "train loss:0.016779779779253448\n",
      "train loss:0.0008982369443314516\n",
      "train loss:0.018726611606874586\n",
      "train loss:0.0195055738188473\n",
      "train loss:0.01334069654042771\n",
      "train loss:0.015058020407658626\n",
      "train loss:0.029353485854569084\n",
      "train loss:0.00407109213927696\n",
      "train loss:0.01617122238787828\n",
      "train loss:0.006840624303435301\n",
      "train loss:0.01073917614991329\n",
      "train loss:0.04871555096674839\n",
      "train loss:0.01627733167589703\n",
      "train loss:0.02165528659142425\n",
      "train loss:0.010165197052850143\n",
      "train loss:0.0026503056290851403\n",
      "train loss:0.01389549994775609\n",
      "train loss:0.006766706325284897\n",
      "train loss:0.003511610507860022\n",
      "train loss:0.009999119882773548\n",
      "train loss:0.015211267840033777\n",
      "train loss:0.0029484345336201006\n",
      "train loss:0.042630107120642566\n",
      "train loss:0.0012034101336685149\n",
      "train loss:0.004802895536567878\n",
      "train loss:0.0036502074698141914\n",
      "train loss:0.003741806034451646\n",
      "train loss:0.01073346083598863\n",
      "train loss:0.024922196562950583\n",
      "train loss:0.008337073088278137\n",
      "train loss:0.0012687934427264265\n",
      "train loss:0.005836030320198393\n",
      "train loss:0.02686667667555579\n",
      "train loss:0.001182816697520901\n",
      "train loss:0.01238575423280513\n",
      "train loss:0.015070424651993368\n",
      "train loss:0.028861447821560908\n",
      "train loss:0.014744017806776945\n",
      "train loss:0.0017738910667461064\n",
      "train loss:0.0024147994871763084\n",
      "train loss:0.007629164448485675\n",
      "train loss:0.006245253934505896\n",
      "train loss:0.010804976365996111\n",
      "train loss:0.006370377865397073\n",
      "train loss:0.03183044862128433\n",
      "train loss:0.006748161951092349\n",
      "train loss:0.011244033697365246\n",
      "train loss:0.007776063529057592\n",
      "train loss:0.0484977259722646\n",
      "train loss:0.021047815191633058\n",
      "train loss:0.00946781626563503\n",
      "train loss:0.00584349789882622\n",
      "train loss:0.026429855185412632\n",
      "train loss:0.023832038989024185\n",
      "train loss:0.011374887124788237\n",
      "train loss:0.00267624710555674\n",
      "train loss:0.004868450594295779\n",
      "train loss:0.004908667093959896\n",
      "train loss:0.0019148291874305679\n",
      "train loss:0.003728723208439235\n",
      "train loss:0.0031511982438035104\n",
      "train loss:0.0042344537426958215\n",
      "train loss:0.00310432050757198\n",
      "train loss:0.014729698216201523\n",
      "train loss:0.07327048243670836\n",
      "train loss:0.0035756639303465045\n",
      "train loss:0.053524996666381996\n",
      "train loss:0.034115400768141735\n",
      "train loss:0.005998629888271555\n",
      "train loss:0.009856599318289055\n",
      "train loss:0.005471253744896969\n",
      "train loss:0.015350878546681976\n",
      "train loss:0.0037160587429256996\n",
      "train loss:0.001684418172941084\n",
      "train loss:0.01628516554183498\n",
      "train loss:0.003254661969201816\n",
      "train loss:0.015306265025166698\n",
      "train loss:0.0011793117967938793\n",
      "train loss:0.0006880357539916619\n",
      "train loss:0.0009673832754734439\n",
      "train loss:0.020257343130737508\n",
      "train loss:0.04551277504329705\n",
      "train loss:0.0075661647322732666\n",
      "train loss:0.003570901397265962\n",
      "train loss:0.01718243864546824\n",
      "train loss:0.006953613931022704\n",
      "train loss:0.009548159202379135\n",
      "train loss:0.005095691616223886\n",
      "train loss:0.009801493533056132\n",
      "train loss:0.008880005488682624\n",
      "train loss:0.0024842526033971224\n",
      "train loss:0.0012453388396702443\n",
      "train loss:0.004627744012722157\n",
      "train loss:0.005710435298842354\n",
      "train loss:0.018177869376299127\n",
      "train loss:0.0021416888835208083\n",
      "train loss:0.0039322008439773865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.05009960789455356\n",
      "train loss:0.02779127931362172\n",
      "train loss:0.019030097601658573\n",
      "train loss:0.006578977884088904\n",
      "train loss:0.0014384565193521952\n",
      "train loss:0.001609824755447415\n",
      "train loss:0.0037139706557527924\n",
      "train loss:0.0034880515577853464\n",
      "train loss:0.018492660253194362\n",
      "train loss:0.010692014582035279\n",
      "train loss:0.0012505540990625534\n",
      "train loss:0.002465794487124931\n",
      "train loss:0.0028784361266290547\n",
      "train loss:0.012701629700002257\n",
      "train loss:0.0040471165101904835\n",
      "train loss:0.007277108679812991\n",
      "train loss:0.14685059093951694\n",
      "train loss:0.002121651851015597\n",
      "train loss:0.01818201406070076\n",
      "train loss:0.003229746077636915\n",
      "train loss:0.00118907807695208\n",
      "train loss:0.0020882510706425896\n",
      "train loss:0.018910389586289336\n",
      "train loss:0.015135498931000892\n",
      "train loss:0.016840663210745833\n",
      "train loss:0.005240301673826244\n",
      "train loss:0.008586385262111746\n",
      "train loss:0.008057124080370709\n",
      "train loss:0.0034175870268742027\n",
      "train loss:0.0032703708265856084\n",
      "train loss:0.004059157113529679\n",
      "train loss:0.004057081233156308\n",
      "train loss:0.003655308243019025\n",
      "train loss:0.003398931123899793\n",
      "train loss:0.01869130041810403\n",
      "train loss:0.008812964398676165\n",
      "train loss:0.008529736032450976\n",
      "train loss:0.005512612070795445\n",
      "train loss:0.0025180046529654117\n",
      "train loss:0.012978503566210404\n",
      "train loss:0.001949305793681511\n",
      "train loss:0.004484848190154484\n",
      "train loss:0.006711913830163219\n",
      "train loss:0.0038851289640567392\n",
      "train loss:0.017182655256687315\n",
      "train loss:0.005199229622375184\n",
      "train loss:0.013869738712802384\n",
      "train loss:0.0031513876754155324\n",
      "train loss:0.00991849322757925\n",
      "train loss:0.02121996901754616\n",
      "train loss:0.004744729101194696\n",
      "train loss:0.0033154013903108678\n",
      "train loss:0.021883592697572937\n",
      "train loss:0.03659200044195847\n",
      "train loss:0.0028819410798323186\n",
      "train loss:0.01941509263469688\n",
      "train loss:0.023515793767089\n",
      "train loss:0.007530702552147582\n",
      "train loss:0.017299994441894454\n",
      "train loss:0.02015670617112007\n",
      "train loss:0.012612030798454072\n",
      "train loss:0.012244760055620998\n",
      "train loss:0.048818566953420656\n",
      "train loss:0.04624826169723576\n",
      "train loss:0.011939115669142731\n",
      "train loss:0.004081545923194918\n",
      "train loss:0.005547657654906476\n",
      "train loss:0.004522226257291619\n",
      "train loss:0.006272012249279911\n",
      "train loss:0.0019787311206905874\n",
      "train loss:0.0036788134794122685\n",
      "train loss:0.024345699206293512\n",
      "train loss:0.006448058729375408\n",
      "train loss:0.0256243797450278\n",
      "train loss:0.004385380197438013\n",
      "train loss:0.009110217948308246\n",
      "train loss:0.006429846103306165\n",
      "train loss:0.0069513322089008334\n",
      "train loss:0.0034912452607153864\n",
      "train loss:0.007794538550880656\n",
      "train loss:0.0030427007199069567\n",
      "train loss:0.007223039831361885\n",
      "train loss:0.024514123674173\n",
      "train loss:0.055574622271666735\n",
      "train loss:0.04632576223754195\n",
      "train loss:0.007692109190644666\n",
      "train loss:0.010866346634036921\n",
      "train loss:0.006781169032440819\n",
      "train loss:0.027173869476113017\n",
      "train loss:0.002283062750137321\n",
      "train loss:0.007257085331664886\n",
      "train loss:0.009763416950735819\n",
      "train loss:0.03419076601478284\n",
      "train loss:0.006535611074762978\n",
      "train loss:0.041506256348123945\n",
      "train loss:0.018242441789586512\n",
      "train loss:0.0018250455246882208\n",
      "train loss:0.011571736635416824\n",
      "train loss:0.004656526783121439\n",
      "train loss:0.009586444119830492\n",
      "=== epoch:9, train acc:0.993, test acc:0.986 ===\n",
      "train loss:0.011446713094540031\n",
      "train loss:0.009141361683127054\n",
      "train loss:0.00550272460860844\n",
      "train loss:0.030827231546679715\n",
      "train loss:0.03196501590680041\n",
      "train loss:0.009944812721670504\n",
      "train loss:0.029834460472503627\n",
      "train loss:0.002680569823532134\n",
      "train loss:0.059110563833960114\n",
      "train loss:0.030098508021586205\n",
      "train loss:0.002549754137060028\n",
      "train loss:0.004836737015747606\n",
      "train loss:0.06363796782778235\n",
      "train loss:0.008320252460545234\n",
      "train loss:0.0026303017287041576\n",
      "train loss:0.027529884918528397\n",
      "train loss:0.0061631415163896554\n",
      "train loss:0.015493606468421923\n",
      "train loss:0.008563518749018659\n",
      "train loss:0.007666229095003495\n",
      "train loss:0.009874543421571002\n",
      "train loss:0.005917364719566192\n",
      "train loss:0.0055245948188984255\n",
      "train loss:0.014854452887047535\n",
      "train loss:0.023131374250134708\n",
      "train loss:0.002252729662483663\n",
      "train loss:0.009940583853169095\n",
      "train loss:0.0035282492122314796\n",
      "train loss:0.03805017934629005\n",
      "train loss:0.010099295371428573\n",
      "train loss:0.008174657512505163\n",
      "train loss:0.00374576822485022\n",
      "train loss:0.0116799021152637\n",
      "train loss:0.005740510799231863\n",
      "train loss:0.011739561942899192\n",
      "train loss:0.010782803076988264\n",
      "train loss:0.004514437428518437\n",
      "train loss:0.02732611435060828\n",
      "train loss:0.009752406244307128\n",
      "train loss:0.007571093820789566\n",
      "train loss:0.0030958210723268844\n",
      "train loss:0.023966475809045713\n",
      "train loss:0.009635137781635786\n",
      "train loss:0.007848038783629378\n",
      "train loss:0.0029836552008800188\n",
      "train loss:0.011010639411148701\n",
      "train loss:0.036855817672823143\n",
      "train loss:0.0494740174827263\n",
      "train loss:0.002755983878254251\n",
      "train loss:0.017621264526183688\n",
      "train loss:0.005546253559474584\n",
      "train loss:0.041467200874365666\n",
      "train loss:0.012001807499006206\n",
      "train loss:0.004587783605255971\n",
      "train loss:0.032617239829667334\n",
      "train loss:0.010467233882640948\n",
      "train loss:0.006351131513712437\n",
      "train loss:0.0052461063105270446\n",
      "train loss:0.050351643043252486\n",
      "train loss:0.006107232542338392\n",
      "train loss:0.0006473789084401605\n",
      "train loss:0.05227375029595478\n",
      "train loss:0.0019104342296428242\n",
      "train loss:0.06297105520975274\n",
      "train loss:0.0010559392008420475\n",
      "train loss:0.005069843045991191\n",
      "train loss:0.0055991802118678345\n",
      "train loss:0.046861041351406806\n",
      "train loss:0.017250605280295924\n",
      "train loss:0.010750562534544357\n",
      "train loss:0.004628426602747273\n",
      "train loss:0.014637894949121232\n",
      "train loss:0.030358825684303835\n",
      "train loss:0.0031984269880133164\n",
      "train loss:0.01000058692056953\n",
      "train loss:0.009241161337128274\n",
      "train loss:0.0019714909089413916\n",
      "train loss:0.005243293788721113\n",
      "train loss:0.13300315455398684\n",
      "train loss:0.0059236839748771815\n",
      "train loss:0.009824152782669673\n",
      "train loss:0.040332140698531076\n",
      "train loss:0.015090739836166355\n",
      "train loss:0.012076072759398941\n",
      "train loss:0.007105419269288469\n",
      "train loss:0.0036678071524136762\n",
      "train loss:0.01240898347225025\n",
      "train loss:0.013260740478435945\n",
      "train loss:0.020861206339536947\n",
      "train loss:0.03868814674098905\n",
      "train loss:0.026229673494938977\n",
      "train loss:0.002242042641708874\n",
      "train loss:0.004023479059634455\n",
      "train loss:0.021484331474747025\n",
      "train loss:0.0075070812688846226\n",
      "train loss:0.013670125009419559\n",
      "train loss:0.004122562740483077\n",
      "train loss:0.011501570547452966\n",
      "train loss:0.005680353515055696\n",
      "train loss:0.011953037697082511\n",
      "train loss:0.04446700220848469\n",
      "train loss:0.012733550125957862\n",
      "train loss:0.017425387625856045\n",
      "train loss:0.002878123789679318\n",
      "train loss:0.022326141488189302\n",
      "train loss:0.01847051615118016\n",
      "train loss:0.0019318711529215677\n",
      "train loss:0.03781844276149681\n",
      "train loss:0.023436341962943964\n",
      "train loss:0.039209692500720775\n",
      "train loss:0.003074104051570877\n",
      "train loss:0.010343966454658272\n",
      "train loss:0.006803237365438266\n",
      "train loss:0.002254751318882281\n",
      "train loss:0.00820710070589965\n",
      "train loss:0.03129826916686924\n",
      "train loss:0.005501944517089237\n",
      "train loss:0.006746582138296307\n",
      "train loss:0.011773757115420109\n",
      "train loss:0.017781414435002706\n",
      "train loss:0.0033681162909936346\n",
      "train loss:0.004417458275552493\n",
      "train loss:0.004442354166306906\n",
      "train loss:0.003856357200345517\n",
      "train loss:0.013185496035845089\n",
      "train loss:0.0029094530546603797\n",
      "train loss:0.010839423797293347\n",
      "train loss:0.0076022177354347475\n",
      "train loss:0.006225333175570364\n",
      "train loss:0.020675827600125013\n",
      "train loss:0.0008068162374498132\n",
      "train loss:0.0026293463886685243\n",
      "train loss:0.028393155552274285\n",
      "train loss:0.0018432218285293384\n",
      "train loss:0.006089305664329293\n",
      "train loss:0.035532337679024764\n",
      "train loss:0.0031154738809710558\n",
      "train loss:0.0015169908644211557\n",
      "train loss:0.01243386583922153\n",
      "train loss:0.010171294848414603\n",
      "train loss:0.002784231274205621\n",
      "train loss:0.0031847600015202466\n",
      "train loss:0.00751770156060714\n",
      "train loss:0.017444301132143993\n",
      "train loss:0.01404407616039915\n",
      "train loss:0.001999670194747476\n",
      "train loss:0.0060173640632830505\n",
      "train loss:0.001457284168686339\n",
      "train loss:0.008369675263983585\n",
      "train loss:0.022130508259816967\n",
      "train loss:0.009085888572253023\n",
      "train loss:0.005403150275741993\n",
      "train loss:0.023127528650763264\n",
      "train loss:0.006855498008279186\n",
      "train loss:0.0060560617236596935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.007959055854996934\n",
      "train loss:0.012320331196667937\n",
      "train loss:0.0035205466035936593\n",
      "train loss:0.005217815419720018\n",
      "train loss:0.02141553469423391\n",
      "train loss:0.003075481820051693\n",
      "train loss:0.007890898921462637\n",
      "train loss:0.01502916478944341\n",
      "train loss:0.006586249480127431\n",
      "train loss:0.0017240786890711742\n",
      "train loss:0.003955634720674622\n",
      "train loss:0.003448317427427206\n",
      "train loss:0.006047411084372847\n",
      "train loss:0.025877896510401652\n",
      "train loss:0.003935559212657164\n",
      "train loss:0.02397766860684615\n",
      "train loss:0.004959942684025962\n",
      "train loss:0.0036502571445326463\n",
      "train loss:0.024629039211428956\n",
      "train loss:0.004637073051405545\n",
      "train loss:0.026246956119439172\n",
      "train loss:0.015005313447765947\n",
      "train loss:0.01065968914881973\n",
      "train loss:0.008888950323832788\n",
      "train loss:0.02196742772595902\n",
      "train loss:0.009081125994323477\n",
      "train loss:0.006216659623884946\n",
      "train loss:0.004939013185094024\n",
      "train loss:0.021268371660091132\n",
      "train loss:0.009589398755190555\n",
      "train loss:0.005164939406699088\n",
      "train loss:0.008681449556851288\n",
      "train loss:0.007587082001057525\n",
      "train loss:0.007859183345689942\n",
      "train loss:0.00909507009025744\n",
      "train loss:0.012679679373668706\n",
      "train loss:0.003230295689817582\n",
      "train loss:0.0038372959598908713\n",
      "train loss:0.003010984773596289\n",
      "train loss:0.004076451768259842\n",
      "train loss:0.008986726508231749\n",
      "train loss:0.02573897092992447\n",
      "train loss:0.04767525051435533\n",
      "train loss:0.029454779607585347\n",
      "train loss:0.00653007436708685\n",
      "train loss:0.0041182757439227205\n",
      "train loss:0.0003691401761017362\n",
      "train loss:0.0015353926367052398\n",
      "train loss:0.006051326443761397\n",
      "train loss:0.002123223292340295\n",
      "train loss:0.07843691579759483\n",
      "train loss:0.0022120430554001896\n",
      "train loss:0.030835660404222878\n",
      "train loss:0.0069576820675245265\n",
      "train loss:0.005313078860245387\n",
      "train loss:0.008677043046387601\n",
      "train loss:0.002937059486842558\n",
      "train loss:0.0025878325307324202\n",
      "train loss:0.020465419650271967\n",
      "train loss:0.011080771546321285\n",
      "train loss:0.0017016096600973635\n",
      "train loss:0.0012965823863546678\n",
      "train loss:0.027240286508526633\n",
      "train loss:0.011249129333673002\n",
      "train loss:0.0004722429021331423\n",
      "train loss:0.020143184688617994\n",
      "train loss:0.006570615168332335\n",
      "train loss:0.0020362065161909295\n",
      "train loss:0.006786924087424767\n",
      "train loss:0.0028794395418691924\n",
      "train loss:0.012287392339096643\n",
      "train loss:0.017335991787806745\n",
      "train loss:0.00645381778711085\n",
      "train loss:0.003286163712936491\n",
      "train loss:0.0021391031569169285\n",
      "train loss:0.004515422205604174\n",
      "train loss:0.01348503139273536\n",
      "train loss:0.024595383538714658\n",
      "train loss:0.00908628456819607\n",
      "train loss:0.026942251092677883\n",
      "train loss:0.01154497431231665\n",
      "train loss:0.013538587736437185\n",
      "train loss:0.005324476845450604\n",
      "train loss:0.008395345614837048\n",
      "train loss:0.0307046047637199\n",
      "train loss:0.01829979294088739\n",
      "train loss:0.005009529417290091\n",
      "train loss:0.0008865078073813845\n",
      "train loss:0.005713190453896087\n",
      "train loss:0.0035549995411999456\n",
      "train loss:0.015041486184857596\n",
      "train loss:0.009682906567816731\n",
      "train loss:0.0008809911103245928\n",
      "train loss:0.003487330127914576\n",
      "train loss:0.002734489280498573\n",
      "train loss:0.004791583094305256\n",
      "train loss:0.0018742208747942783\n",
      "train loss:0.007594489674832361\n",
      "train loss:0.009800756082872251\n",
      "train loss:0.004391811582341488\n",
      "train loss:0.012880904654222343\n",
      "train loss:0.022522381483183893\n",
      "train loss:0.04335994507733378\n",
      "train loss:0.003358498073963341\n",
      "train loss:0.0025178688613187727\n",
      "train loss:0.03280389994813711\n",
      "train loss:0.004618075843630833\n",
      "train loss:0.003011822701087731\n",
      "train loss:0.003766915220691044\n",
      "train loss:0.005627251702275393\n",
      "train loss:0.008049613115752861\n",
      "train loss:0.009713658965113791\n",
      "train loss:0.006562917203184034\n",
      "train loss:0.007597138406309193\n",
      "train loss:0.009343002386547696\n",
      "train loss:0.015179143650416574\n",
      "train loss:0.00971291094439477\n",
      "train loss:0.006040729240282133\n",
      "train loss:0.004947964816458871\n",
      "train loss:0.0021875958724130447\n",
      "train loss:0.0033029331468482025\n",
      "train loss:0.018289947269290355\n",
      "train loss:0.004011028026326847\n",
      "train loss:0.006989849442878442\n",
      "train loss:0.014981397943533235\n",
      "train loss:0.0028639332363904705\n",
      "train loss:0.0027473186626481537\n",
      "train loss:0.005907760507097804\n",
      "train loss:0.012962771804343975\n",
      "train loss:0.004232998145672884\n",
      "train loss:0.005873569211459794\n",
      "train loss:0.0036685670542338216\n",
      "train loss:0.004941030270426121\n",
      "train loss:0.0035669496531884454\n",
      "train loss:0.0036540464779268246\n",
      "train loss:0.015317792157992439\n",
      "train loss:0.05768987450773897\n",
      "train loss:0.003409903332183287\n",
      "train loss:0.0012529783677447722\n",
      "train loss:0.007105258642520033\n",
      "train loss:0.013279397655321825\n",
      "train loss:0.003910272254303949\n",
      "train loss:0.021542751246169098\n",
      "train loss:0.007339075220729105\n",
      "train loss:0.022858355768172765\n",
      "train loss:0.0036309288310915682\n",
      "train loss:0.001806259375138399\n",
      "train loss:0.08515788474850923\n",
      "train loss:0.003943814454873794\n",
      "train loss:0.0051901391828552525\n",
      "train loss:0.004738518559624559\n",
      "train loss:0.028596166067341305\n",
      "train loss:0.004866209338143208\n",
      "train loss:0.004585788373880801\n",
      "train loss:0.00858261221118891\n",
      "train loss:0.050090371843040826\n",
      "train loss:0.013563156076009754\n",
      "train loss:0.0187754047468742\n",
      "train loss:0.009431880044062988\n",
      "train loss:0.003871347777922828\n",
      "train loss:0.006114830553954878\n",
      "train loss:0.010114136314898332\n",
      "train loss:0.0021369405703070693\n",
      "train loss:0.01295955672908615\n",
      "train loss:0.018680030116949763\n",
      "train loss:0.01040806206811509\n",
      "train loss:0.014435565672273862\n",
      "train loss:0.00831996226219008\n",
      "train loss:0.001620753695997306\n",
      "train loss:0.0022428700006308137\n",
      "train loss:0.046897914834824084\n",
      "train loss:0.004140861827502851\n",
      "train loss:0.004060943261584215\n",
      "train loss:0.002517202814556704\n",
      "train loss:0.002720746236330994\n",
      "train loss:0.02984762521679653\n",
      "train loss:0.04114693343180544\n",
      "train loss:0.004867335967433137\n",
      "train loss:0.013977528270549237\n",
      "train loss:0.020157040966017892\n",
      "train loss:0.0015028324449969952\n",
      "train loss:0.00569228535991925\n",
      "train loss:0.013237751939893015\n",
      "train loss:0.005511146070511401\n",
      "train loss:0.005882725910601622\n",
      "train loss:0.03223688068697572\n",
      "train loss:0.005912857951544734\n",
      "train loss:0.003049169970172723\n",
      "train loss:0.005472921244372252\n",
      "train loss:0.0032557409290475503\n",
      "train loss:0.016968207413900958\n",
      "train loss:0.006665962026755738\n",
      "train loss:0.004403631130017383\n",
      "train loss:0.007303607187994575\n",
      "train loss:0.007882979228780847\n",
      "train loss:0.0010183517616917804\n",
      "train loss:0.002067400428850398\n",
      "train loss:0.012203494173184197\n",
      "train loss:0.001952780615265746\n",
      "train loss:0.01047356431993188\n",
      "train loss:0.017365020533636116\n",
      "train loss:0.000999664758928271\n",
      "train loss:0.0016252502572185745\n",
      "train loss:0.004870714542062462\n",
      "train loss:0.0018253784833155361\n",
      "train loss:0.0028387224589483733\n",
      "train loss:0.005288324706674678\n",
      "train loss:0.008374942522907625\n",
      "train loss:0.005340141597331402\n",
      "train loss:0.004247021740775132\n",
      "train loss:0.0005202820970435002\n",
      "train loss:0.0022348987853181256\n",
      "train loss:0.007357448327640875\n",
      "train loss:0.006181235149650347\n",
      "train loss:0.002616063174332491\n",
      "train loss:0.0009971549882775092\n",
      "train loss:0.013604729288803248\n",
      "train loss:0.0036411113124640852\n",
      "train loss:0.0051737859001394345\n",
      "train loss:0.0022324653870931296\n",
      "train loss:0.0114625471921148\n",
      "train loss:0.017823788083622276\n",
      "train loss:0.001967492851024177\n",
      "train loss:0.013436900122530562\n",
      "train loss:0.008371927113766529\n",
      "train loss:0.0045484117740309605\n",
      "train loss:0.0014793890654100944\n",
      "train loss:0.002080286543045425\n",
      "train loss:0.015347787706142408\n",
      "train loss:0.0021123651453238816\n",
      "train loss:0.013691821504654533\n",
      "train loss:0.0072727061924348566\n",
      "train loss:0.0224341297628661\n",
      "train loss:0.001630518072913027\n",
      "train loss:0.0036749673766624698\n",
      "train loss:0.0063138304205317365\n",
      "train loss:0.012843850308430625\n",
      "train loss:0.0022110369216043592\n",
      "train loss:0.010410133871566783\n",
      "train loss:0.007027945030113597\n",
      "train loss:0.023111775188744018\n",
      "train loss:0.005794376145100567\n",
      "train loss:0.0021472306099417837\n",
      "train loss:0.008687563195584818\n",
      "train loss:0.004309852728550068\n",
      "train loss:0.009655664757977009\n",
      "train loss:0.01520917413572654\n",
      "train loss:0.007102273774300616\n",
      "train loss:0.02761758299577864\n",
      "train loss:0.007077524751509229\n",
      "train loss:0.00700786097198091\n",
      "train loss:0.002478575507012472\n",
      "train loss:0.0017317707268277019\n",
      "train loss:0.0032478111133899673\n",
      "train loss:0.03734833667185598\n",
      "train loss:0.0522687904207345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.007956835562139674\n",
      "train loss:0.0024691697956032784\n",
      "train loss:0.002302184640946649\n",
      "train loss:0.007949528234769273\n",
      "train loss:0.019792878144692445\n",
      "train loss:0.01594417304044637\n",
      "train loss:0.0029363752467704745\n",
      "train loss:0.024441903445481628\n",
      "train loss:0.006025516448273699\n",
      "train loss:0.0016861225775283222\n",
      "train loss:0.0048362359356776425\n",
      "train loss:0.0050019046527320955\n",
      "train loss:0.0038554063956785308\n",
      "train loss:0.0034008342998599157\n",
      "train loss:0.02754039342014392\n",
      "train loss:0.013213180654452834\n",
      "train loss:0.004205827913569049\n",
      "train loss:0.004258628502761819\n",
      "train loss:0.006446924425168545\n",
      "train loss:0.02523013248984178\n",
      "train loss:0.020148088894594757\n",
      "train loss:0.005259452116825088\n",
      "train loss:0.0021749760505816902\n",
      "train loss:0.019315286095287727\n",
      "train loss:0.042526929796768\n",
      "train loss:0.006285358920624044\n",
      "train loss:0.007694856802960332\n",
      "train loss:0.017344582499505476\n",
      "train loss:0.005817156244509606\n",
      "train loss:0.019578345972949097\n",
      "train loss:0.002355516406149442\n",
      "train loss:0.005262868115766678\n",
      "train loss:0.004924663860019632\n",
      "train loss:0.00466205932470845\n",
      "train loss:0.008796056992930894\n",
      "train loss:0.006575434909752039\n",
      "train loss:0.007343498162792422\n",
      "train loss:0.005512391666279436\n",
      "train loss:0.005502564776316618\n",
      "train loss:0.0028192338309457558\n",
      "train loss:0.013671283311086723\n",
      "train loss:0.0066040840330914875\n",
      "train loss:0.009024057034449343\n",
      "train loss:0.01917957638094117\n",
      "train loss:0.003641261447899932\n",
      "train loss:0.003104445345791865\n",
      "train loss:0.014154554951261208\n",
      "train loss:0.006269245839924316\n",
      "train loss:0.011153276608681501\n",
      "train loss:0.0035619637501546615\n",
      "train loss:0.0021343251908419927\n",
      "train loss:0.0035925561193373575\n",
      "train loss:0.01895469539081176\n",
      "train loss:0.0023136547126554113\n",
      "train loss:0.009566066839427156\n",
      "train loss:0.006422804936990597\n",
      "train loss:0.020385947279367947\n",
      "train loss:0.08986996079969989\n",
      "train loss:0.006739125011347418\n",
      "train loss:0.0024102920870885175\n",
      "train loss:0.0022837497438242807\n",
      "train loss:0.0011057964040411346\n",
      "train loss:0.0016879384806893335\n",
      "train loss:0.007352299849249149\n",
      "train loss:0.014260115516733294\n",
      "train loss:0.003652980829544102\n",
      "train loss:0.009511974800781387\n",
      "train loss:0.05221829013949439\n",
      "train loss:0.011887699840075306\n",
      "train loss:0.014834033788510162\n",
      "train loss:0.003899624595340863\n",
      "train loss:0.01120405022047315\n",
      "train loss:0.0032149312431037\n",
      "train loss:0.024581974287098407\n",
      "train loss:0.0064555265830581274\n",
      "train loss:0.007297247242042915\n",
      "train loss:0.0043384547413572476\n",
      "train loss:0.04477369242984087\n",
      "train loss:0.004791889555188003\n",
      "train loss:0.017240730501107665\n",
      "train loss:0.016459668512283726\n",
      "train loss:0.005342235760074075\n",
      "train loss:0.002502022802567446\n",
      "train loss:0.005739157632946865\n",
      "train loss:0.008084733043763866\n",
      "train loss:0.04809511924066423\n",
      "train loss:0.009275013206614455\n",
      "train loss:0.015490776122315286\n",
      "train loss:0.0029252031067012936\n",
      "train loss:0.005441977820835442\n",
      "train loss:0.058684614284084564\n",
      "train loss:0.0033789076741178514\n",
      "train loss:0.005969077986801182\n",
      "train loss:0.01470313697681511\n",
      "train loss:0.010975590750928209\n",
      "train loss:0.017424524306691683\n",
      "train loss:0.0008718339366706879\n",
      "train loss:0.005281749667923703\n",
      "train loss:0.005273244676206172\n",
      "train loss:0.005520424426912519\n",
      "train loss:0.0017824159548622137\n",
      "train loss:0.0012599059547467018\n",
      "train loss:0.001862339366688792\n",
      "train loss:0.04663009801060012\n",
      "train loss:0.004538820308473104\n",
      "train loss:0.010799159842713757\n",
      "train loss:0.012802560175755538\n",
      "train loss:0.11235036776192331\n",
      "train loss:0.0055775740462630004\n",
      "train loss:0.0024488380196555993\n",
      "train loss:0.003290364399245176\n",
      "train loss:0.01579274984266943\n",
      "train loss:0.017478543073232194\n",
      "train loss:0.0021107483735882428\n",
      "train loss:0.0027586466094990914\n",
      "train loss:0.013415830478984633\n",
      "train loss:0.0325493592858431\n",
      "train loss:0.002779670182593236\n",
      "train loss:0.005346024299149673\n",
      "train loss:0.0022459773783996954\n",
      "train loss:0.0013860321253074681\n",
      "train loss:0.0006266743894749504\n",
      "train loss:0.010225180251648617\n",
      "train loss:0.0020007038250371705\n",
      "train loss:0.0027585957739193253\n",
      "train loss:0.0081363545097904\n",
      "train loss:0.002853615579117297\n",
      "train loss:0.01165504279119695\n",
      "train loss:0.007474684878679484\n",
      "train loss:0.006210933734337118\n",
      "train loss:0.002389785433593136\n",
      "train loss:0.004192418415991315\n",
      "train loss:0.0059402510928298\n",
      "train loss:0.003821046828967005\n",
      "train loss:0.0017247160605349315\n",
      "train loss:0.002722178331771472\n",
      "train loss:0.000891986788095777\n",
      "train loss:0.04445406894178375\n",
      "train loss:0.006871088045956848\n",
      "train loss:0.006270319540735386\n",
      "train loss:0.0049816761844877905\n",
      "train loss:0.01112382914143085\n",
      "train loss:0.004004505017110383\n",
      "train loss:0.027668362538045638\n",
      "train loss:0.011280263151603387\n",
      "train loss:0.0023350698004275853\n",
      "train loss:0.007802048198299284\n",
      "train loss:0.012390186051828136\n",
      "train loss:0.002287859162500096\n",
      "train loss:0.0013434250774497266\n",
      "train loss:0.008481593244179358\n",
      "train loss:0.0037585557948581014\n",
      "train loss:0.013222178327427139\n",
      "train loss:0.007104585317669333\n",
      "train loss:0.004654487529018436\n",
      "train loss:0.00791418184872127\n",
      "train loss:0.037238706017929876\n",
      "train loss:0.015943821444608958\n",
      "train loss:0.01214561664360099\n",
      "train loss:0.009888852862812126\n",
      "train loss:0.005360092622592377\n",
      "train loss:0.013270856641224363\n",
      "train loss:0.022101455758516613\n",
      "train loss:0.0029550801779021983\n",
      "train loss:0.09010553915509269\n",
      "train loss:0.013629204305697544\n",
      "train loss:0.020627932910652423\n",
      "train loss:0.028160048740297\n",
      "train loss:0.006043135374385406\n",
      "train loss:0.001119822077431958\n",
      "train loss:0.014694896408654257\n",
      "train loss:0.008468333372753012\n",
      "train loss:0.0023677249015628264\n",
      "train loss:0.032360562693419574\n",
      "train loss:0.0069867256411662755\n",
      "train loss:0.0015681860411561048\n",
      "train loss:0.00243135425035235\n",
      "train loss:0.014998868582021969\n",
      "train loss:0.002543551741807313\n",
      "train loss:0.022263392836051367\n",
      "train loss:0.013664814431872096\n",
      "train loss:0.007213302122351113\n",
      "train loss:0.0071784853103659995\n",
      "train loss:0.004052111758845265\n",
      "train loss:0.01016824227232282\n",
      "train loss:0.019955642474286668\n",
      "train loss:0.014274278036878389\n",
      "train loss:0.01684067762862817\n",
      "train loss:0.004345060437208728\n",
      "=== epoch:10, train acc:0.993, test acc:0.986 ===\n",
      "train loss:0.009484793337181708\n",
      "train loss:0.016011772351358325\n",
      "train loss:0.005219339351739401\n",
      "train loss:0.004611513957350671\n",
      "train loss:0.005187492393758878\n",
      "train loss:0.015237418252693003\n",
      "train loss:0.002751581326003558\n",
      "train loss:0.0032012161653963964\n",
      "train loss:0.019781220432570055\n",
      "train loss:0.004491487708776647\n",
      "train loss:0.020114656316759127\n",
      "train loss:0.0070752241040501155\n",
      "train loss:0.0047225194129301195\n",
      "train loss:0.021995113718985642\n",
      "train loss:0.0033410538364582808\n",
      "train loss:0.01792062277451463\n",
      "train loss:0.025103156048936807\n",
      "train loss:0.0033833508680306008\n",
      "train loss:0.00598002982758541\n",
      "train loss:0.008228642110332848\n",
      "train loss:0.0013529817211537034\n",
      "train loss:0.003321247462182948\n",
      "train loss:0.008546742833534937\n",
      "train loss:0.0073837924061803594\n",
      "train loss:0.03180798493702276\n",
      "train loss:0.0018015548835432973\n",
      "train loss:0.006747648610236598\n",
      "train loss:0.015960282749605762\n",
      "train loss:0.008549425404035096\n",
      "train loss:0.003611275057710098\n",
      "train loss:0.0006343838257004222\n",
      "train loss:0.027465673678499898\n",
      "train loss:0.009292213330398391\n",
      "train loss:0.012753574975744246\n",
      "train loss:0.008884391341997313\n",
      "train loss:0.009883098152370097\n",
      "train loss:0.019330858098991214\n",
      "train loss:0.005569380989165226\n",
      "train loss:0.004120471162990161\n",
      "train loss:0.006974281932699445\n",
      "train loss:0.000811711640685452\n",
      "train loss:0.004807321894275987\n",
      "train loss:0.004065022357547003\n",
      "train loss:0.020010110198024372\n",
      "train loss:0.004944895206709783\n",
      "train loss:0.021700628752819067\n",
      "train loss:0.007442150980034119\n",
      "train loss:0.00850511274015748\n",
      "train loss:0.00888420273620864\n",
      "train loss:0.0033071683130531594\n",
      "train loss:0.0051315561223462414\n",
      "train loss:0.000632734296228285\n",
      "train loss:0.006455776735657293\n",
      "train loss:0.0019225895058037664\n",
      "train loss:0.0006636022109834805\n",
      "train loss:0.003653783706496668\n",
      "train loss:0.005143051334132684\n",
      "train loss:0.0015049258230598944\n",
      "train loss:0.014245961343120143\n",
      "train loss:0.003568276516910591\n",
      "train loss:0.003360911792637613\n",
      "train loss:0.007340131114972908\n",
      "train loss:0.004891961472375698\n",
      "train loss:0.002986461959386189\n",
      "train loss:0.004942520719820243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0005347743579880961\n",
      "train loss:0.005672329529207511\n",
      "train loss:0.00247999490485828\n",
      "train loss:0.0029059593975831314\n",
      "train loss:0.0012222655087582252\n",
      "train loss:0.0014496657279144858\n",
      "train loss:0.006887408988347947\n",
      "train loss:0.0071393842267176485\n",
      "train loss:0.002431854877005504\n",
      "train loss:0.004286435461345155\n",
      "train loss:0.04431898410753636\n",
      "train loss:0.01952831546049844\n",
      "train loss:0.00906882674408278\n",
      "train loss:0.001970161553528647\n",
      "train loss:0.0009539840307847068\n",
      "train loss:0.0018806095847098824\n",
      "train loss:0.008300458945786382\n",
      "train loss:0.0005526894322305634\n",
      "train loss:0.00625802178454281\n",
      "train loss:0.0010056867986574652\n",
      "train loss:0.0018687414650712358\n",
      "train loss:0.0009830854457056485\n",
      "train loss:0.04361666578970847\n",
      "train loss:0.0066067485451101115\n",
      "train loss:0.015224537117767773\n",
      "train loss:0.006862185348950358\n",
      "train loss:0.016899179918002116\n",
      "train loss:0.006719441254006471\n",
      "train loss:0.0030773176544405794\n",
      "train loss:0.012964349649925924\n",
      "train loss:0.009356679599949675\n",
      "train loss:0.035999779146992365\n",
      "train loss:0.007040048450718504\n",
      "train loss:0.004653292067807543\n",
      "train loss:0.020165765193903028\n",
      "train loss:0.006680884375068506\n",
      "train loss:0.005956918106597134\n",
      "train loss:0.0026676510018976934\n",
      "train loss:0.019988638447411652\n",
      "train loss:0.004200131440695873\n",
      "train loss:0.0009333593485098015\n",
      "train loss:0.00483796486977639\n",
      "train loss:0.0010855791861252783\n",
      "train loss:0.0029973400000528473\n",
      "train loss:0.0034301015714386864\n",
      "train loss:0.010696085673855868\n",
      "train loss:0.03993551213171172\n",
      "train loss:0.0010105371303457825\n",
      "train loss:0.005112647665624609\n",
      "train loss:0.011214426269315726\n",
      "train loss:0.01916032103835156\n",
      "train loss:0.015703373204489682\n",
      "train loss:0.006309032272409279\n",
      "train loss:0.001204388168343741\n",
      "train loss:0.008718834085564673\n",
      "train loss:0.0027712035859801592\n",
      "train loss:0.010226617463278374\n",
      "train loss:0.012709829657348706\n",
      "train loss:0.004360789945712222\n",
      "train loss:0.002785269749746784\n",
      "train loss:0.0032654412537897358\n",
      "train loss:0.006090044913285464\n",
      "train loss:0.07733874088988556\n",
      "train loss:0.01095445146846326\n",
      "train loss:0.007985778525944833\n",
      "train loss:0.007259326982615812\n",
      "train loss:0.01799505167076641\n",
      "train loss:0.018926294973124157\n",
      "train loss:0.00713654707559264\n",
      "train loss:0.015568294890181886\n",
      "train loss:0.01800428751977859\n",
      "train loss:0.0018562724404786078\n",
      "train loss:0.00454178260095558\n",
      "train loss:0.004317125942478839\n",
      "train loss:0.0028574160751537792\n",
      "train loss:0.011424986269302566\n",
      "train loss:0.004407609135800626\n",
      "train loss:0.009336687610050907\n",
      "train loss:0.004085894537196247\n",
      "train loss:0.0021508284034833167\n",
      "train loss:0.005299346498048285\n",
      "train loss:0.024785468735005433\n",
      "train loss:0.007005020974588338\n",
      "train loss:0.0069460317852133415\n",
      "train loss:0.0030521417975473636\n",
      "train loss:0.0022695434867372453\n",
      "train loss:0.003977826729856927\n",
      "train loss:0.0014664294737431103\n",
      "train loss:0.0028832891288794395\n",
      "train loss:0.010886574796982972\n",
      "train loss:0.0006346948579114986\n",
      "train loss:0.01375947875891671\n",
      "train loss:0.007083941388738638\n",
      "train loss:0.0036969080845435437\n",
      "train loss:0.0072846071273651725\n",
      "train loss:0.004697077936157448\n",
      "train loss:0.001402812494873376\n",
      "train loss:0.00529655478017039\n",
      "train loss:0.006564164940339115\n",
      "train loss:0.004490774765329926\n",
      "train loss:0.009872525086515795\n",
      "train loss:0.0026525448474918\n",
      "train loss:0.0050749508644727034\n",
      "train loss:0.0019128904468150784\n",
      "train loss:0.0053450324868815225\n",
      "train loss:0.005466662738927536\n",
      "train loss:0.017041985187824796\n",
      "train loss:0.0006130653733864704\n",
      "train loss:0.009880709820059463\n",
      "train loss:0.012701176756956893\n",
      "train loss:0.0006688747169583391\n",
      "train loss:0.016086999532197367\n",
      "train loss:0.03793131997832518\n",
      "train loss:0.0068286417931284205\n",
      "train loss:0.007779634289705481\n",
      "train loss:0.0013107459736922437\n",
      "train loss:0.0028612995961575915\n",
      "train loss:0.01444830141739778\n",
      "train loss:0.023597371705956265\n",
      "train loss:0.008316394455868664\n",
      "train loss:0.006455280893130747\n",
      "train loss:0.004654614485093304\n",
      "train loss:0.005816660513614611\n",
      "train loss:0.008429801457663616\n",
      "train loss:0.007783134990942582\n",
      "train loss:0.01124397998884486\n",
      "train loss:0.04126221730166206\n",
      "train loss:0.002857841089703984\n",
      "train loss:0.043574474441021\n",
      "train loss:0.007575547838454846\n",
      "train loss:0.02839156732769672\n",
      "train loss:0.04109647088013351\n",
      "train loss:0.023441401199833765\n",
      "train loss:0.00551371986557491\n",
      "train loss:0.015051258125398816\n",
      "train loss:0.0056440134262397655\n",
      "train loss:0.024861222485060654\n",
      "train loss:0.010091692251289277\n",
      "train loss:0.02098884558142209\n",
      "train loss:0.0013373360687672878\n",
      "train loss:0.009538774269177435\n",
      "train loss:0.007563504977114976\n",
      "train loss:0.0026136867701092655\n",
      "train loss:0.006458764728273974\n",
      "train loss:0.03154994533201265\n",
      "train loss:0.011878048644442404\n",
      "train loss:0.0014650422326506194\n",
      "train loss:0.004287016466292983\n",
      "train loss:0.009339824059957114\n",
      "train loss:0.006619850208693819\n",
      "train loss:0.06344062021162983\n",
      "train loss:0.0074941853994111175\n",
      "train loss:0.01154625595129527\n",
      "train loss:0.0037138752577297813\n",
      "train loss:0.003372446986534705\n",
      "train loss:0.006182757713237579\n",
      "train loss:0.01693976587844864\n",
      "train loss:0.00587318628306818\n",
      "train loss:0.001695945132290739\n",
      "train loss:0.0014881591045619819\n",
      "train loss:0.010955435528575488\n",
      "train loss:0.00602831914237581\n",
      "train loss:0.008414429304568411\n",
      "train loss:0.007031522852064537\n",
      "train loss:0.02017046281612731\n",
      "train loss:0.009168522485829757\n",
      "train loss:0.009165703001759187\n",
      "train loss:0.0036688252252823524\n",
      "train loss:0.0020878547505715855\n",
      "train loss:0.008112313621187178\n",
      "train loss:0.0020216624503110376\n",
      "train loss:0.000434360488536373\n",
      "train loss:0.014801176410864106\n",
      "train loss:0.033455369239455024\n",
      "train loss:0.0049185720365099925\n",
      "train loss:0.0017789871333480222\n",
      "train loss:0.0011712481522921812\n",
      "train loss:0.008885264848542887\n",
      "train loss:0.0012423906640578184\n",
      "train loss:0.008891130129378871\n",
      "train loss:0.009956900862689376\n",
      "train loss:0.0015576482690407\n",
      "train loss:0.009039454497330904\n",
      "train loss:0.020695323017262374\n",
      "train loss:0.004738637482210119\n",
      "train loss:0.004078052082003684\n",
      "train loss:0.0009344721382073212\n",
      "train loss:0.0032832895083554294\n",
      "train loss:0.004822466959681089\n",
      "train loss:0.007526474611693448\n",
      "train loss:0.05371597560773496\n",
      "train loss:0.0013591448085127646\n",
      "train loss:0.001222967609067559\n",
      "train loss:0.04015421532080507\n",
      "train loss:0.00457339082445448\n",
      "train loss:0.0009963825155793514\n",
      "train loss:0.02688837468768485\n",
      "train loss:0.0036230533413648654\n",
      "train loss:0.01149968927884472\n",
      "train loss:0.008322406949922645\n",
      "train loss:0.0008756213991315466\n",
      "train loss:0.0038294464167227802\n",
      "train loss:0.09008655021002701\n",
      "train loss:0.048350957350596795\n",
      "train loss:0.0048745481392409975\n",
      "train loss:0.003073822833268954\n",
      "train loss:0.009448433729181695\n",
      "train loss:0.048485299466164325\n",
      "train loss:0.0030521753847506873\n",
      "train loss:0.006534520372835435\n",
      "train loss:0.002073464828532117\n",
      "train loss:0.0050633219195019875\n",
      "train loss:0.003159869530950293\n",
      "train loss:0.0022063096294727487\n",
      "train loss:0.001829307414680349\n",
      "train loss:0.005343148948478239\n",
      "train loss:0.01839489313916664\n",
      "train loss:0.0011027572477164036\n",
      "train loss:0.007067801988486527\n",
      "train loss:0.0033557640283400857\n",
      "train loss:0.01345557287477259\n",
      "train loss:0.019324908444413688\n",
      "train loss:0.0018074216134625384\n",
      "train loss:0.007075138171580318\n",
      "train loss:0.025850175640708583\n",
      "train loss:0.010374080652289537\n",
      "train loss:0.0009101506964122394\n",
      "train loss:0.0048540090466283135\n",
      "train loss:0.006496753949246944\n",
      "train loss:0.0006990503494095357\n",
      "train loss:0.007271736434777212\n",
      "train loss:0.0018312911267660114\n",
      "train loss:0.010345028857389717\n",
      "train loss:0.006191432470175416\n",
      "train loss:0.011092135119479929\n",
      "train loss:0.0038129250259054115\n",
      "train loss:0.007764516888284952\n",
      "train loss:0.0032863397903478675\n",
      "train loss:0.014389689185722096\n",
      "train loss:0.013753178813391538\n",
      "train loss:0.0024402916531372845\n",
      "train loss:0.00879399675653583\n",
      "train loss:0.00444573450923244\n",
      "train loss:0.013700831510321664\n",
      "train loss:0.00395758672787058\n",
      "train loss:0.0031044643582494318\n",
      "train loss:0.019251110563596453\n",
      "train loss:0.008847763991296172\n",
      "train loss:0.0014735369343244562\n",
      "train loss:0.00291921042897155\n",
      "train loss:0.005554923758974876\n",
      "train loss:0.00813667045818558\n",
      "train loss:0.004630527797142903\n",
      "train loss:0.004946710572166168\n",
      "train loss:0.001116291997201975\n",
      "train loss:0.0027032054073208773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004748963523588776\n",
      "train loss:0.001587687020787698\n",
      "train loss:0.000552975481997422\n",
      "train loss:0.0009209106653558578\n",
      "train loss:0.002891768168511239\n",
      "train loss:0.0016782334308525115\n",
      "train loss:0.02122766973970572\n",
      "train loss:0.004026171238250626\n",
      "train loss:0.0016666947135896212\n",
      "train loss:0.008965613664566843\n",
      "train loss:0.0025245971734960053\n",
      "train loss:0.008992187967120922\n",
      "train loss:0.0060134067211645185\n",
      "train loss:0.006834475515404964\n",
      "train loss:0.0035735553779767826\n",
      "train loss:0.006584581732678898\n",
      "train loss:0.014419655530373141\n",
      "train loss:0.0032807752672406178\n",
      "train loss:0.007060851790332412\n",
      "train loss:0.04375744807678442\n",
      "train loss:0.0014050100143474175\n",
      "train loss:0.000806577436077381\n",
      "train loss:0.010943878756155805\n",
      "train loss:0.004031754691814219\n",
      "train loss:0.005970934607268481\n",
      "train loss:0.0012340300840627961\n",
      "train loss:0.004803054803232687\n",
      "train loss:0.018580178089557517\n",
      "train loss:0.018890974403858864\n",
      "train loss:0.1249921992948045\n",
      "train loss:0.008080715043652145\n",
      "train loss:0.0031841914407577817\n",
      "train loss:0.010259941639218194\n",
      "train loss:0.004361247896538923\n",
      "train loss:0.0037574147444899737\n",
      "train loss:0.040980405020001935\n",
      "train loss:0.0059759997828715715\n",
      "train loss:0.007587431704951738\n",
      "train loss:0.00663601622418171\n",
      "train loss:0.0050018463440238935\n",
      "train loss:0.002130650908339421\n",
      "train loss:0.006678907568990989\n",
      "train loss:0.007857166718217058\n",
      "train loss:0.0022031830607175907\n",
      "train loss:0.003790663923497687\n",
      "train loss:0.006244557094171021\n",
      "train loss:0.04384677444582538\n",
      "train loss:0.00821612212224239\n",
      "train loss:0.010680174778435305\n",
      "train loss:0.010182470754794216\n",
      "train loss:0.006776182873201911\n",
      "train loss:0.00519786448937587\n",
      "train loss:0.00544827688966928\n",
      "train loss:0.001149663521127988\n",
      "train loss:0.0024591708908487304\n",
      "train loss:0.0033958276704559175\n",
      "train loss:0.006026116405660988\n",
      "train loss:0.0035761775896484323\n",
      "train loss:0.0011792288945350774\n",
      "train loss:0.017302044470699506\n",
      "train loss:0.006571468893954536\n",
      "train loss:0.0034479708956016548\n",
      "train loss:0.032364086329433106\n",
      "train loss:0.0006547543479211343\n",
      "train loss:0.013481123681486311\n",
      "train loss:0.0015612969172664206\n",
      "train loss:0.006988542603141888\n",
      "train loss:0.015997354468103107\n",
      "train loss:0.010969105693971762\n",
      "train loss:0.003651123367200949\n",
      "train loss:0.00542333894268983\n",
      "train loss:0.038700312310628496\n",
      "train loss:0.0038622874652914263\n",
      "train loss:0.0019500835312781775\n",
      "train loss:0.011208811090881086\n",
      "train loss:0.004578198492073616\n",
      "train loss:0.0038591760339063016\n",
      "train loss:0.0023399388422878425\n",
      "train loss:0.004245325762385521\n",
      "train loss:0.0013412731525531824\n",
      "train loss:0.03531598925957922\n",
      "train loss:0.001305404425988322\n",
      "train loss:0.0068069100934313245\n",
      "train loss:0.0007317348576885824\n",
      "train loss:0.002341740913635452\n",
      "train loss:0.0031536212893949435\n",
      "train loss:0.007949354006327458\n",
      "train loss:0.0012478346746198593\n",
      "train loss:0.015698575606267633\n",
      "train loss:0.00143183204127741\n",
      "train loss:0.015005782263261918\n",
      "train loss:0.007510474567475722\n",
      "train loss:0.0073563411392475065\n",
      "train loss:0.007151413700236142\n",
      "train loss:0.017518326706493562\n",
      "train loss:0.010032751179121231\n",
      "train loss:0.0026615778190800052\n",
      "train loss:0.005161745308394015\n",
      "train loss:0.0014479793609647436\n",
      "train loss:0.0024517429884927337\n",
      "train loss:0.009260967363941606\n",
      "train loss:0.009511917723614568\n",
      "train loss:0.0008257338321947343\n",
      "train loss:0.010450931390994723\n",
      "train loss:0.03544779812871835\n",
      "train loss:0.0020386877239737854\n",
      "train loss:0.004118212236480331\n",
      "train loss:0.008612952652609562\n",
      "train loss:0.007727544506038657\n",
      "train loss:0.00194111925083122\n",
      "train loss:0.00809239859779283\n",
      "train loss:0.00643620688888577\n",
      "train loss:0.005554116150752264\n",
      "train loss:0.005217070327885659\n",
      "train loss:0.001811767348021508\n",
      "train loss:0.013180618242189523\n",
      "train loss:0.010316257339461598\n",
      "train loss:0.0036163623857857585\n",
      "train loss:0.003023755129882268\n",
      "train loss:0.00666494775663567\n",
      "train loss:0.050587551522095014\n",
      "train loss:0.0010479031643477383\n",
      "train loss:0.009861696576197511\n",
      "train loss:0.010471256140478611\n",
      "train loss:0.0020766368594589547\n",
      "train loss:0.0045039950495353535\n",
      "train loss:0.02247710754484029\n",
      "train loss:0.0010676848602832292\n",
      "train loss:0.0019380613997396774\n",
      "train loss:0.0024284745040148653\n",
      "train loss:0.006323563182902256\n",
      "train loss:0.02156801329180252\n",
      "train loss:0.0020616963154736646\n",
      "train loss:0.0028239633427515286\n",
      "train loss:0.006515707629237803\n",
      "train loss:0.006042392908643447\n",
      "train loss:0.019476607793856654\n",
      "train loss:0.0732515388181394\n",
      "train loss:0.001344430465850142\n",
      "train loss:0.029660994128013297\n",
      "train loss:0.005406201904182546\n",
      "train loss:0.014712656495469136\n",
      "train loss:0.001660160635183403\n",
      "train loss:0.0006143938780829906\n",
      "train loss:0.0010936598605182932\n",
      "train loss:0.0025326806340101133\n",
      "train loss:0.01704523615506397\n",
      "train loss:0.0036697324587771298\n",
      "train loss:0.0012542074605558261\n",
      "train loss:0.004193209158729911\n",
      "train loss:0.0006470768117737695\n",
      "train loss:0.0004950116319902024\n",
      "train loss:0.001406698870239307\n",
      "train loss:0.005439361221744821\n",
      "train loss:0.0016602016968327582\n",
      "train loss:0.008286224915220996\n",
      "train loss:0.009052884219736788\n",
      "train loss:0.05151933082127811\n",
      "train loss:0.0016588908160115104\n",
      "train loss:0.0024180771347166994\n",
      "train loss:0.00655492334849374\n",
      "train loss:0.003925179431581221\n",
      "train loss:0.0070620140125791965\n",
      "train loss:0.007103517126081154\n",
      "train loss:0.020718300275510103\n",
      "train loss:0.0035863387478205374\n",
      "train loss:0.0010101815307254026\n",
      "train loss:0.021457845202380588\n",
      "train loss:0.0018009393200188603\n",
      "train loss:0.0017332923952970978\n",
      "train loss:0.00853234598488329\n",
      "train loss:0.0032623591568851345\n",
      "train loss:0.012611849536661869\n",
      "train loss:0.006992412874825094\n",
      "train loss:0.003308191412307618\n",
      "train loss:0.0017838867980387125\n",
      "train loss:0.0034852568626190113\n",
      "train loss:0.005080300423195295\n",
      "train loss:0.008520841706243582\n",
      "train loss:0.004633377626023897\n",
      "train loss:0.024895120238046676\n",
      "train loss:0.0009807218881383714\n",
      "train loss:0.0009857270488323093\n",
      "train loss:0.0036785275970203086\n",
      "train loss:0.006995378997507868\n",
      "train loss:0.0018827279457682574\n",
      "train loss:0.003504305548905207\n",
      "train loss:0.0064728119436038515\n",
      "train loss:0.0018241442993922946\n",
      "train loss:0.010723075855577562\n",
      "train loss:0.0009268183120039636\n",
      "train loss:0.0063419989757000665\n",
      "train loss:0.005683978427569462\n",
      "train loss:0.006974988686665261\n",
      "train loss:0.006294160212220509\n",
      "train loss:0.005406624645055289\n",
      "train loss:0.003384617714676776\n",
      "train loss:0.004333128860282413\n",
      "train loss:0.0034271305509524196\n",
      "train loss:0.0027205745056457665\n",
      "train loss:0.009557127515209853\n",
      "train loss:0.006109597069005895\n",
      "train loss:0.052157880944549664\n",
      "train loss:0.016777168931168228\n",
      "train loss:0.0037113706379528367\n",
      "train loss:0.004587623500723888\n",
      "train loss:0.0010925148218092833\n",
      "train loss:0.003535838829325282\n",
      "train loss:0.0019618201485969156\n",
      "train loss:0.006557002571174506\n",
      "train loss:0.003104527633405507\n",
      "train loss:0.00397099904203528\n",
      "train loss:0.014690832210532714\n",
      "train loss:0.005039148250499598\n",
      "train loss:0.0018385914123533343\n",
      "train loss:0.0019613677479287006\n",
      "train loss:0.0020782447256052976\n",
      "train loss:0.005491972332650989\n",
      "train loss:0.006889442159901371\n",
      "train loss:0.015799120650418278\n",
      "train loss:0.0032210239216212437\n",
      "train loss:0.00046988598304999554\n",
      "train loss:0.0024920947505281264\n",
      "train loss:0.0018164700342245335\n",
      "train loss:0.0034492652560614216\n",
      "train loss:0.0031446293695281645\n",
      "train loss:0.00427308410614156\n",
      "train loss:0.005390499681265248\n",
      "train loss:0.006268282409127714\n",
      "train loss:0.010637337709620932\n",
      "train loss:0.0012952856718744887\n",
      "train loss:0.009149055469819862\n",
      "train loss:0.024519344853850725\n",
      "train loss:0.012528264105959053\n",
      "train loss:0.0036980600606670187\n",
      "train loss:0.0010377114919597407\n",
      "train loss:0.008051570033269794\n",
      "train loss:0.007793035018107852\n",
      "train loss:0.004365217586568636\n",
      "train loss:0.0004074323699800989\n",
      "train loss:0.0021688055680642955\n",
      "train loss:0.003894807499701399\n",
      "train loss:0.002430115901539383\n",
      "train loss:0.0023546230700461713\n",
      "train loss:0.0008114937105589842\n",
      "train loss:0.004137367541730357\n",
      "train loss:0.007381332548824957\n",
      "train loss:0.02458642854756539\n",
      "train loss:0.0034521969675994258\n",
      "train loss:0.022281096123353064\n",
      "train loss:0.00888102572424357\n",
      "train loss:0.008059255556375917\n",
      "train loss:0.01590267030490108\n",
      "train loss:0.009922600836727523\n",
      "train loss:0.0040725952352490095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.04766474571085986\n",
      "train loss:0.0068063186753357496\n",
      "train loss:0.0013849267109072852\n",
      "train loss:0.011169283751935467\n",
      "train loss:0.01924427443872263\n",
      "train loss:0.008039524220519035\n",
      "train loss:0.000441098413528251\n",
      "train loss:0.001613344129772084\n",
      "train loss:0.0013637993433413265\n",
      "train loss:0.0010986682956580153\n",
      "train loss:0.0013852303226232388\n",
      "train loss:0.0029124602293193395\n",
      "train loss:0.0008306797135917937\n",
      "train loss:0.002600560467123645\n",
      "train loss:0.0014110457289183873\n",
      "train loss:0.0007604963238276531\n",
      "train loss:0.00168086226969552\n",
      "train loss:0.005556668119579503\n",
      "train loss:0.007080883739993149\n",
      "train loss:0.0030295224344171023\n",
      "train loss:0.0005532034223429198\n",
      "train loss:0.006194876521963392\n",
      "train loss:0.007352978171126699\n",
      "train loss:0.005786065773928435\n",
      "=== epoch:11, train acc:0.998, test acc:0.984 ===\n",
      "train loss:0.0011746078912643514\n",
      "train loss:0.008390745927990778\n",
      "train loss:0.04599988327426732\n",
      "train loss:0.0036162300201252645\n",
      "train loss:0.004201588098485948\n",
      "train loss:0.007200669276134365\n",
      "train loss:0.004693551181462181\n",
      "train loss:0.0013413344759698532\n",
      "train loss:0.008626520072701491\n",
      "train loss:0.007431732899324837\n",
      "train loss:0.0010017978624049435\n",
      "train loss:0.011240261524886606\n",
      "train loss:0.001912200917335068\n",
      "train loss:0.0034259772870115783\n",
      "train loss:0.004198799192108389\n",
      "train loss:0.005960777379714836\n",
      "train loss:0.0012856538912591122\n",
      "train loss:0.06105060466235128\n",
      "train loss:0.0032233612192217914\n",
      "train loss:0.018460990593876334\n",
      "train loss:0.006126443162684442\n",
      "train loss:0.004266413175436891\n",
      "train loss:0.0006842098506326104\n",
      "train loss:0.0023657238952418964\n",
      "train loss:0.0020624535637555107\n",
      "train loss:0.007726767902535019\n",
      "train loss:0.002015910351711025\n",
      "train loss:0.005806750091264667\n",
      "train loss:0.004712373113485605\n",
      "train loss:0.010939626624781684\n",
      "train loss:0.005042327275706109\n",
      "train loss:0.00878753787576056\n",
      "train loss:0.006220958926614502\n",
      "train loss:0.0025026992818852787\n",
      "train loss:0.005861876844701777\n",
      "train loss:0.004472769153888133\n",
      "train loss:0.00028755621573607637\n",
      "train loss:0.0056976209887015595\n",
      "train loss:0.0008421151677268053\n",
      "train loss:0.003657639245947616\n",
      "train loss:0.003774068967213031\n",
      "train loss:0.06150403116493916\n",
      "train loss:0.004212739055637624\n",
      "train loss:0.012805462684250346\n",
      "train loss:0.0016069285409965467\n",
      "train loss:0.008878422329869795\n",
      "train loss:0.007225050797749651\n",
      "train loss:0.023175952470587152\n",
      "train loss:0.005490000657967966\n",
      "train loss:0.008383772217532502\n",
      "train loss:0.0029470087891361745\n",
      "train loss:0.011694221992127269\n",
      "train loss:0.002200114023398949\n",
      "train loss:0.0016912126681807441\n",
      "train loss:0.004144659503340092\n",
      "train loss:0.010864699430952909\n",
      "train loss:0.010783669112840477\n",
      "train loss:0.005356948217336983\n",
      "train loss:0.004341468547149647\n",
      "train loss:0.0027165316094697727\n",
      "train loss:0.04191450022482286\n",
      "train loss:0.0027951174822500643\n",
      "train loss:0.01064953628676522\n",
      "train loss:0.003733258623814671\n",
      "train loss:0.004074817659219091\n",
      "train loss:0.004427023506206324\n",
      "train loss:0.0026092775582183866\n",
      "train loss:0.001331869985773611\n",
      "train loss:0.019474762326357472\n",
      "train loss:0.004681357012141823\n",
      "train loss:0.0033273329613715454\n",
      "train loss:0.0007782383913352592\n",
      "train loss:0.00024265193863457613\n",
      "train loss:0.0046024876245965825\n",
      "train loss:0.000291143561516199\n",
      "train loss:0.010694062405557907\n",
      "train loss:0.0011225289711406833\n",
      "train loss:0.003775748124409278\n",
      "train loss:0.0025373977938978652\n",
      "train loss:0.007539813328126363\n",
      "train loss:0.0012870474344571056\n",
      "train loss:0.010716222443598617\n",
      "train loss:0.0015530551293087317\n",
      "train loss:0.00857530355306841\n",
      "train loss:0.009592515270425851\n",
      "train loss:0.004296732262397019\n",
      "train loss:0.0013783551010912733\n",
      "train loss:0.0031359614279558795\n",
      "train loss:0.0036249770857014756\n",
      "train loss:0.009635717939582625\n",
      "train loss:0.0028931379647945603\n",
      "train loss:0.010417626189212555\n",
      "train loss:0.0003180508514386378\n",
      "train loss:0.0027859689604815933\n",
      "train loss:0.012388091704951034\n",
      "train loss:0.0018631483332116599\n",
      "train loss:0.000746100842033932\n",
      "train loss:0.0005550185603388739\n",
      "train loss:0.0037130769606731656\n",
      "train loss:0.008769481334110115\n",
      "train loss:0.01306934360962896\n",
      "train loss:0.004393907439181568\n",
      "train loss:0.002980318844284572\n",
      "train loss:0.0006250154697384342\n",
      "train loss:0.0007284586467084578\n",
      "train loss:0.0032877303795843544\n",
      "train loss:0.002414199686087174\n",
      "train loss:0.0027585796276193976\n",
      "train loss:0.006907970857374212\n",
      "train loss:0.0033543245704323594\n",
      "train loss:0.004157153310945948\n",
      "train loss:0.0013257892311665576\n",
      "train loss:0.006052464698688986\n",
      "train loss:0.003189968564816974\n",
      "train loss:0.056475985575113956\n",
      "train loss:0.005877680986734551\n",
      "train loss:0.0033407989212030985\n",
      "train loss:0.012531832780335\n",
      "train loss:0.009995512582502213\n",
      "train loss:0.014828781649961171\n",
      "train loss:0.009451192258149227\n",
      "train loss:0.0026857829610501234\n",
      "train loss:0.00018059359569837515\n",
      "train loss:0.004422817817902299\n",
      "train loss:0.007721783528962764\n",
      "train loss:0.014437716962925444\n",
      "train loss:0.010176088861361511\n",
      "train loss:0.012257233178189634\n",
      "train loss:0.004478324964405613\n",
      "train loss:0.005011581780671392\n",
      "train loss:0.017227878339870252\n",
      "train loss:0.009312891981029681\n",
      "train loss:0.006236091469505037\n",
      "train loss:0.003760941283294804\n",
      "train loss:0.0012899976955244965\n",
      "train loss:0.001046936903312834\n",
      "train loss:0.0038899121357573925\n",
      "train loss:0.004212116585797338\n",
      "train loss:0.0069286692561741315\n",
      "train loss:0.0007618150041677961\n",
      "train loss:0.07901087012910088\n",
      "train loss:0.002447555127925107\n",
      "train loss:0.0014566320942393945\n",
      "train loss:0.006114957918616335\n",
      "train loss:0.010762007548370438\n",
      "train loss:0.00778390197882505\n",
      "train loss:0.0019470276516702126\n",
      "train loss:0.01329264230420817\n",
      "train loss:0.006490768397919008\n",
      "train loss:0.0010387199183732078\n",
      "train loss:0.02225289692195671\n",
      "train loss:0.011734039722881964\n",
      "train loss:0.002919879915198285\n",
      "train loss:0.02762887294723071\n",
      "train loss:0.0012845777347245879\n",
      "train loss:0.00667691600533756\n",
      "train loss:0.011232831987645636\n",
      "train loss:0.012513320236029973\n",
      "train loss:0.005539043290387746\n",
      "train loss:0.0034145106787698476\n",
      "train loss:0.0019455284632358793\n",
      "train loss:0.0019882543375665004\n",
      "train loss:0.003162706505940919\n",
      "train loss:0.0027325750188178333\n",
      "train loss:0.005262869726314555\n",
      "train loss:0.011899174849582566\n",
      "train loss:0.0028974556546077818\n",
      "train loss:0.001994963587602001\n",
      "train loss:0.000524860694235216\n",
      "train loss:0.0013088123058079637\n",
      "train loss:0.0039337403205269034\n",
      "train loss:0.0044999915741906074\n",
      "train loss:0.003616613237906656\n",
      "train loss:0.004161816820160623\n",
      "train loss:0.0031489747551178456\n",
      "train loss:0.014230208013070544\n",
      "train loss:0.0009219307176029394\n",
      "train loss:0.011762800144939396\n",
      "train loss:0.0017513252413967268\n",
      "train loss:0.0018087900552678404\n",
      "train loss:0.0031153769751110796\n",
      "train loss:0.010753186408461153\n",
      "train loss:0.001076755860108102\n",
      "train loss:0.009120628790338429\n",
      "train loss:0.0005380876102023885\n",
      "train loss:0.0017767909166067134\n",
      "train loss:0.008988087217778567\n",
      "train loss:0.0014684865800083853\n",
      "train loss:0.0023967251005439947\n",
      "train loss:0.014716447198621158\n",
      "train loss:0.015935884563323607\n",
      "train loss:0.017739640720085572\n",
      "train loss:0.0020621314798417267\n",
      "train loss:0.0015489862396829653\n",
      "train loss:0.002359629312634068\n",
      "train loss:0.002159138355404928\n",
      "train loss:0.009604038165401327\n",
      "train loss:0.00509667022340871\n",
      "train loss:0.020554407615648435\n",
      "train loss:0.0038523809515154696\n",
      "train loss:0.002814684722613471\n",
      "train loss:0.0015642852807177304\n",
      "train loss:0.008325398495263698\n",
      "train loss:0.00284706005157526\n",
      "train loss:0.005282198571550784\n",
      "train loss:0.029385445977575753\n",
      "train loss:0.002494445482481581\n",
      "train loss:0.013572404797642448\n",
      "train loss:0.009389736968450114\n",
      "train loss:0.0038581298210188077\n",
      "train loss:0.0021584271982877656\n",
      "train loss:0.0074543043698298075\n",
      "train loss:0.011173762187479825\n",
      "train loss:0.004294245883829473\n",
      "train loss:0.0030113063713314\n",
      "train loss:0.0030607667791392036\n",
      "train loss:0.04412520196800005\n",
      "train loss:0.0016572728937604868\n",
      "train loss:0.02329080130467251\n",
      "train loss:0.0016647790606043177\n",
      "train loss:0.004057045381424222\n",
      "train loss:0.00761934887674268\n",
      "train loss:0.007266374288814012\n",
      "train loss:0.003881185811341585\n",
      "train loss:0.01456026536945405\n",
      "train loss:0.018608500247804267\n",
      "train loss:0.053655784958947655\n",
      "train loss:0.024030137963644872\n",
      "train loss:0.005674602082460876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0022372858412756207\n",
      "train loss:0.007858399854449315\n",
      "train loss:0.01781059502168322\n",
      "train loss:0.0059025552132114115\n",
      "train loss:0.006307471620865934\n",
      "train loss:0.004213543739479738\n",
      "train loss:0.0027511516775333145\n",
      "train loss:0.008765330339559577\n",
      "train loss:0.027103936131487552\n",
      "train loss:0.003765259356693197\n",
      "train loss:0.012998837313666068\n",
      "train loss:0.009391016605182635\n",
      "train loss:0.022239836386044463\n",
      "train loss:0.053854000109461043\n",
      "train loss:0.017972429237393717\n",
      "train loss:0.0026523959454038733\n",
      "train loss:0.010884914209265255\n",
      "train loss:0.0031259994260880992\n",
      "train loss:0.0008039901593651535\n",
      "train loss:0.009354316819004217\n",
      "train loss:0.0008391150716900331\n",
      "train loss:0.012846014947745671\n",
      "train loss:0.009957868766888797\n",
      "train loss:0.0005675834425370975\n",
      "train loss:0.012445562561047958\n",
      "train loss:0.03190019054619918\n",
      "train loss:0.008995923678759064\n",
      "train loss:0.029725396246089168\n",
      "train loss:0.006377480618435222\n",
      "train loss:0.003621584690756782\n",
      "train loss:0.0012277313163843373\n",
      "train loss:0.0010182260869284112\n",
      "train loss:0.008836533273202283\n",
      "train loss:0.0024985685209808314\n",
      "train loss:0.003570766504341358\n",
      "train loss:0.003135853449308105\n",
      "train loss:0.004967114770398219\n",
      "train loss:0.015499641471212904\n",
      "train loss:0.0015421384800435964\n",
      "train loss:0.006136090257163916\n",
      "train loss:0.021337730815599167\n",
      "train loss:0.002205968940133076\n",
      "train loss:0.001714325379557968\n",
      "train loss:0.0029749780171857963\n",
      "train loss:0.0039666457429107255\n",
      "train loss:0.0007055874116833821\n",
      "train loss:0.003952437019057125\n",
      "train loss:0.017431162055104157\n",
      "train loss:0.005342045074376085\n",
      "train loss:0.004314610056071365\n",
      "train loss:0.001366586020287871\n",
      "train loss:0.008547205741562224\n",
      "train loss:0.02810087751760742\n",
      "train loss:0.00257193180748514\n",
      "train loss:0.032732000807390846\n",
      "train loss:0.0017973422142742188\n",
      "train loss:0.015460371298751198\n",
      "train loss:0.001976852682271105\n",
      "train loss:0.0006472054878273626\n",
      "train loss:0.004292907942472414\n",
      "train loss:0.002254302066968992\n",
      "train loss:0.004185619377589325\n",
      "train loss:0.0027422484509125244\n",
      "train loss:0.0004527602555012495\n",
      "train loss:0.05050655075855718\n",
      "train loss:0.001436802428855768\n",
      "train loss:0.0015738198694752032\n",
      "train loss:0.004656877410622027\n",
      "train loss:0.010456023121472894\n",
      "train loss:0.001911709598248967\n",
      "train loss:0.00255612137277966\n",
      "train loss:0.022612433167214577\n",
      "train loss:0.004564863222001337\n",
      "train loss:0.0012314605876279554\n",
      "train loss:0.0005885957149948051\n",
      "train loss:0.006155000847664111\n",
      "train loss:0.006498071152095866\n",
      "train loss:0.0031235528963086227\n",
      "train loss:0.03390897488404257\n",
      "train loss:0.003932411206631993\n",
      "train loss:0.0017774256033164018\n",
      "train loss:0.002486474737442847\n",
      "train loss:0.015292499930442138\n",
      "train loss:0.006312400156405385\n",
      "train loss:0.0073590250977058945\n",
      "train loss:0.0008445648885447292\n",
      "train loss:0.022026020604326436\n",
      "train loss:0.001789367994026734\n",
      "train loss:0.023774438439173956\n",
      "train loss:0.015456180488411329\n",
      "train loss:0.0024557208800203623\n",
      "train loss:0.011256695693941079\n",
      "train loss:0.007188050690520099\n",
      "train loss:0.03415049421641005\n",
      "train loss:0.008060228684241484\n",
      "train loss:0.0019959311598690206\n",
      "train loss:0.003862686998936856\n",
      "train loss:0.005153379436655649\n",
      "train loss:0.003843211530972918\n",
      "train loss:0.0037234894478523663\n",
      "train loss:0.003973562998376512\n",
      "train loss:0.007362056151952184\n",
      "train loss:0.002774117418585563\n",
      "train loss:0.007129664711777634\n",
      "train loss:0.004678707790618484\n",
      "train loss:0.005786465983278657\n",
      "train loss:0.0009483108050073765\n",
      "train loss:0.002414289090552502\n",
      "train loss:0.005022828583385659\n",
      "train loss:0.007801304878180188\n",
      "train loss:0.0018818853586660533\n",
      "train loss:0.0020003603157968067\n",
      "train loss:0.014012855446171797\n",
      "train loss:0.002831750988509491\n",
      "train loss:0.0040480941806386615\n",
      "train loss:0.005276377275421525\n",
      "train loss:0.002581964082453389\n",
      "train loss:0.00990131204505908\n",
      "train loss:0.004040950469611537\n",
      "train loss:0.0015464207464435228\n",
      "train loss:0.005587768931112445\n",
      "train loss:0.004366981487455453\n",
      "train loss:0.003179674185448762\n",
      "train loss:0.007930222072382651\n",
      "train loss:0.0044165690751877765\n",
      "train loss:0.006728453093377118\n",
      "train loss:0.03953437329739205\n",
      "train loss:0.0036497827151853036\n",
      "train loss:0.013488520572402065\n",
      "train loss:0.004712348098766695\n",
      "train loss:0.0004754947411585593\n",
      "train loss:0.001957623653218634\n",
      "train loss:0.0018867310102536619\n",
      "train loss:0.00676926740751592\n",
      "train loss:0.0023423417922732587\n",
      "train loss:0.0039018667338391205\n",
      "train loss:0.00904265328201611\n",
      "train loss:0.006843372606215694\n",
      "train loss:0.003523652714415071\n",
      "train loss:0.0021771029401464756\n",
      "train loss:0.001542163383803307\n",
      "train loss:0.008192885160557507\n",
      "train loss:0.0018392699234990454\n",
      "train loss:0.002612152509981014\n",
      "train loss:0.003173636071914193\n",
      "train loss:0.00260052107549698\n",
      "train loss:0.004942404609069512\n",
      "train loss:0.006885528426965737\n",
      "train loss:0.0014645052278114083\n",
      "train loss:0.00487086918213096\n",
      "train loss:0.007223058808082423\n",
      "train loss:0.0013425866289721795\n",
      "train loss:0.004704540316488475\n",
      "train loss:0.003006526362975486\n",
      "train loss:0.0022452274741033926\n",
      "train loss:0.004879795368792813\n",
      "train loss:0.0007239147638981062\n",
      "train loss:0.003279882666842016\n",
      "train loss:0.0016346050547193017\n",
      "train loss:0.0037528436437678364\n",
      "train loss:0.011997554485817479\n",
      "train loss:0.006712330156196355\n",
      "train loss:0.004654646406542128\n",
      "train loss:0.007465063368854231\n",
      "train loss:0.005262429737636746\n",
      "train loss:0.0013218037625600343\n",
      "train loss:0.002025040233576617\n",
      "train loss:0.0004436011792481368\n",
      "train loss:0.005735061537074112\n",
      "train loss:0.0012683724772006356\n",
      "train loss:0.008476938068567164\n",
      "train loss:0.00047615896586269095\n",
      "train loss:0.0014473559808091177\n",
      "train loss:0.0031190528822474264\n",
      "train loss:0.0021184189887807673\n",
      "train loss:0.002984957307143686\n",
      "train loss:0.0011083623148498952\n",
      "train loss:0.002373326341364947\n",
      "train loss:0.002112995920866333\n",
      "train loss:0.0015704083068828595\n",
      "train loss:0.0018675258662306882\n",
      "train loss:0.0021989205350484925\n",
      "train loss:0.007860427773270385\n",
      "train loss:0.062255772121425794\n",
      "train loss:0.0007590184830289668\n",
      "train loss:0.003915931625522075\n",
      "train loss:0.00040868205874593965\n",
      "train loss:0.0009071761299243229\n",
      "train loss:0.002075218922288448\n",
      "train loss:0.0010332049208988795\n",
      "train loss:0.031428890474238816\n",
      "train loss:0.0015510745465682318\n",
      "train loss:0.0012337595469350793\n",
      "train loss:0.007585273100726451\n",
      "train loss:0.0017656341088218357\n",
      "train loss:0.003552851437132055\n",
      "train loss:0.004801810483079957\n",
      "train loss:0.005036611875775\n",
      "train loss:0.0010595898163135377\n",
      "train loss:0.001668727876920796\n",
      "train loss:0.003235266584521854\n",
      "train loss:0.013647313264937922\n",
      "train loss:0.0006616948844237712\n",
      "train loss:0.011384021953497811\n",
      "train loss:0.009941131479815585\n",
      "train loss:0.0008470125031554304\n",
      "train loss:0.00472820102007093\n",
      "train loss:0.01223140929874308\n",
      "train loss:0.011404527284590748\n",
      "train loss:0.0037207339292309\n",
      "train loss:0.0034772027565441507\n",
      "train loss:0.011831815060476234\n",
      "train loss:0.0027670785214549713\n",
      "train loss:0.002381999839612265\n",
      "train loss:0.0028303965308694957\n",
      "train loss:0.0036076940963692145\n",
      "train loss:0.0009493044157161631\n",
      "train loss:0.0014818373117859698\n",
      "train loss:0.00011781304735956773\n",
      "train loss:0.004008558973872739\n",
      "train loss:0.0016347570254413083\n",
      "train loss:0.05825618561323969\n",
      "train loss:0.0013467404580531509\n",
      "train loss:0.003357609924967802\n",
      "train loss:0.0016765481293425225\n",
      "train loss:0.0012002008701271392\n",
      "train loss:0.06196802030139969\n",
      "train loss:0.020165928203856664\n",
      "train loss:0.011996990603676014\n",
      "train loss:0.0036582961900366224\n",
      "train loss:0.005243118004060049\n",
      "train loss:0.026819917561434103\n",
      "train loss:0.0008863855569876329\n",
      "train loss:0.005329893846397848\n",
      "train loss:0.0005209876102186977\n",
      "train loss:0.002337241466808423\n",
      "train loss:0.002084330133801206\n",
      "train loss:0.005647659325988501\n",
      "train loss:0.0049760936941432125\n",
      "train loss:0.0028289288925709296\n",
      "train loss:0.0007546261801877986\n",
      "train loss:0.0041584010720341884\n",
      "train loss:0.005487727812437716\n",
      "train loss:0.0015612323035575728\n",
      "train loss:0.0018136288604543877\n",
      "train loss:0.004616676802535674\n",
      "train loss:0.003153417355122302\n",
      "train loss:0.004338801044495477\n",
      "train loss:0.0011611398500496937\n",
      "train loss:0.0012181400741885931\n",
      "train loss:0.009032746812577123\n",
      "train loss:0.006412364649835558\n",
      "train loss:0.002242504379215182\n",
      "train loss:0.0012454663190587054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.006968005710459079\n",
      "train loss:0.002836228528042758\n",
      "train loss:0.002311036205483508\n",
      "train loss:0.001959835615767754\n",
      "train loss:0.006341048326987367\n",
      "train loss:0.003080337040044498\n",
      "train loss:0.0019277472131186608\n",
      "train loss:0.0011047979201981753\n",
      "train loss:0.0017657051849595778\n",
      "train loss:0.04060209837161774\n",
      "train loss:0.005395298979219064\n",
      "train loss:0.012646460967463887\n",
      "train loss:0.0014107924368946465\n",
      "train loss:0.004399601522703287\n",
      "train loss:0.006172794713522788\n",
      "train loss:0.0036617568698069235\n",
      "train loss:0.0016435612699956831\n",
      "train loss:0.004872436580001037\n",
      "train loss:0.0036764768422606815\n",
      "train loss:0.002564301576065252\n",
      "train loss:0.00561586580525366\n",
      "train loss:0.001752905201970186\n",
      "train loss:0.0018179515652183107\n",
      "train loss:0.0031040784887028405\n",
      "train loss:0.000995535378118825\n",
      "train loss:0.0014707886315892928\n",
      "train loss:0.003711521123278888\n",
      "train loss:0.0007086455028140069\n",
      "train loss:0.0003718329739752456\n",
      "train loss:0.000733735742746452\n",
      "train loss:0.000978107712571426\n",
      "train loss:0.0015087942188783596\n",
      "train loss:0.001552391922880895\n",
      "train loss:0.014530608237684227\n",
      "train loss:0.0024201302887800176\n",
      "train loss:0.0020099971355978263\n",
      "train loss:0.0028252105794200582\n",
      "train loss:0.02102011490998734\n",
      "train loss:0.003283786640359068\n",
      "train loss:0.0021556537629206147\n",
      "train loss:0.0026435695590437645\n",
      "train loss:0.015765443670543153\n",
      "train loss:0.0003962622717390225\n",
      "train loss:0.002373599447949201\n",
      "train loss:0.000862665725886263\n",
      "train loss:0.0033351053839068066\n",
      "train loss:0.0032901121218166713\n",
      "train loss:0.012993442590064762\n",
      "train loss:0.003756054987944543\n",
      "train loss:0.0009222918495542502\n",
      "train loss:0.005809493785998226\n",
      "train loss:0.00909700534603559\n",
      "train loss:0.0020858419981826075\n",
      "train loss:0.0011931261794995308\n",
      "train loss:0.014142032406937512\n",
      "train loss:0.0014621977127043146\n",
      "train loss:0.006081212406960217\n",
      "train loss:0.009406419317701923\n",
      "train loss:0.006933322255806702\n",
      "train loss:0.0036944991026733516\n",
      "train loss:0.005010835972633566\n",
      "train loss:0.0036748835292199963\n",
      "train loss:0.0019984530299420747\n",
      "train loss:0.010373514721640354\n",
      "train loss:0.0006246156021277649\n",
      "train loss:0.0006271029601721302\n",
      "train loss:0.0025334583186881953\n",
      "train loss:0.00792187766821871\n",
      "train loss:0.0020311705881170105\n",
      "train loss:0.0019591636394226\n",
      "train loss:0.0013867131709612347\n",
      "train loss:0.006439226193866898\n",
      "train loss:0.001794913890585623\n",
      "train loss:0.001359764480614254\n",
      "train loss:0.00046858877203682675\n",
      "train loss:0.003147666606689595\n",
      "train loss:0.0001558601851630503\n",
      "train loss:0.0027816860273180617\n",
      "train loss:0.00564079252502549\n",
      "train loss:0.0038754466690657744\n",
      "train loss:0.0019711268512559114\n",
      "train loss:0.00787771738690462\n",
      "train loss:0.0015437557422962101\n",
      "train loss:0.002317348380460575\n",
      "train loss:0.002164148139788461\n",
      "train loss:0.017643062156702236\n",
      "train loss:0.00140439630858254\n",
      "train loss:0.00222691150407202\n",
      "train loss:0.0028402770776902076\n",
      "train loss:0.007414696839737258\n",
      "train loss:0.0024397534074599883\n",
      "train loss:0.0013983331880330194\n",
      "train loss:0.00202602411702292\n",
      "train loss:0.009391133104358516\n",
      "train loss:0.020913903643565566\n",
      "train loss:0.0043446449085591385\n",
      "train loss:0.03346222012627663\n",
      "train loss:0.004218642857954962\n",
      "train loss:0.0037464506426765063\n",
      "train loss:0.0014394297203080475\n",
      "train loss:0.0015940090398554767\n",
      "train loss:0.018354378427070297\n",
      "train loss:0.003269345121222651\n",
      "train loss:0.004441833390287999\n",
      "train loss:0.002753682862040183\n",
      "train loss:0.0027486850317812576\n",
      "train loss:0.00153642442739307\n",
      "train loss:0.008449806099316044\n",
      "train loss:0.002363078250414543\n",
      "train loss:0.0005010473459693708\n",
      "train loss:0.0021264373288518287\n",
      "train loss:0.0011301232920226413\n",
      "train loss:0.001301329593886541\n",
      "train loss:0.0023431844075514807\n",
      "train loss:0.0007873549274567817\n",
      "train loss:0.0036358959111345303\n",
      "train loss:0.006994565394088475\n",
      "=== epoch:12, train acc:0.997, test acc:0.987 ===\n",
      "train loss:0.0008259242816388224\n",
      "train loss:0.004284732406337316\n",
      "train loss:0.001894424958847204\n",
      "train loss:0.0021748909495943425\n",
      "train loss:0.0028874828405887013\n",
      "train loss:0.034247318746524494\n",
      "train loss:0.006127433321518981\n",
      "train loss:0.0003346309091838539\n",
      "train loss:0.0010593245083472729\n",
      "train loss:0.00826939123829605\n",
      "train loss:0.031147465355257416\n",
      "train loss:0.0014198469748371194\n",
      "train loss:0.000946601660136148\n",
      "train loss:0.0029017578213028795\n",
      "train loss:0.0024105050449922533\n",
      "train loss:0.0034906397289460062\n",
      "train loss:0.002792058679502456\n",
      "train loss:0.000903419345666372\n",
      "train loss:0.02921940356677764\n",
      "train loss:0.03595447419613459\n",
      "train loss:0.0031498342637110532\n",
      "train loss:0.00044221166245336075\n",
      "train loss:0.0005884365520708465\n",
      "train loss:0.003959897970674547\n",
      "train loss:0.012074372979414057\n",
      "train loss:0.001744154840749254\n",
      "train loss:0.01986944469248161\n",
      "train loss:0.0005492324232088358\n",
      "train loss:0.005626862817386646\n",
      "train loss:0.0002832785148804743\n",
      "train loss:0.0024605834154434454\n",
      "train loss:0.004992558985026316\n",
      "train loss:0.002238449087177838\n",
      "train loss:0.007361851678036656\n",
      "train loss:0.0023610916444900725\n",
      "train loss:0.003795715660064183\n",
      "train loss:0.0014109045221430484\n",
      "train loss:0.009595973941226294\n",
      "train loss:0.010334444530342579\n",
      "train loss:0.00042923095681951783\n",
      "train loss:0.007007172840235617\n",
      "train loss:0.004343550083581057\n",
      "train loss:0.0009235501087294089\n",
      "train loss:0.004613815251376281\n",
      "train loss:0.00081315277009807\n",
      "train loss:0.010874731584534664\n",
      "train loss:0.004205203444404927\n",
      "train loss:0.0009377269355017393\n",
      "train loss:0.0015413815146873087\n",
      "train loss:0.0028172796645231225\n",
      "train loss:0.0024986854959808268\n",
      "train loss:0.0041240594289472686\n",
      "train loss:0.0027286458205301694\n",
      "train loss:0.001252541588201422\n",
      "train loss:0.00463330360957229\n",
      "train loss:0.003040376479446893\n",
      "train loss:0.0034698611247558618\n",
      "train loss:0.0067553426230810695\n",
      "train loss:0.0012040729328860792\n",
      "train loss:0.013762668614197482\n",
      "train loss:0.008086330727640286\n",
      "train loss:0.004150567899296856\n",
      "train loss:0.002089324121694911\n",
      "train loss:0.0028509219370489725\n",
      "train loss:0.001704106286968684\n",
      "train loss:0.009311906631243675\n",
      "train loss:0.0023253099653970082\n",
      "train loss:0.0010932039734542697\n",
      "train loss:0.020557404336194414\n",
      "train loss:0.002618802001035189\n",
      "train loss:0.003730441934823107\n",
      "train loss:0.007413424148725437\n",
      "train loss:0.002546221731096716\n",
      "train loss:0.0020528890084432587\n",
      "train loss:0.009950795384209678\n",
      "train loss:0.002766622613093741\n",
      "train loss:0.002463961086817376\n",
      "train loss:0.005128294760336527\n",
      "train loss:0.0023944785747997657\n",
      "train loss:0.0017723288106580662\n",
      "train loss:0.0021816024735471485\n",
      "train loss:0.0014243208949352127\n",
      "train loss:0.004350888018320883\n",
      "train loss:0.0006360898684657826\n",
      "train loss:0.008164139748549045\n",
      "train loss:0.00023100787083269906\n",
      "train loss:0.000352006473057573\n",
      "train loss:0.0016999256407427875\n",
      "train loss:0.0011481794325181713\n",
      "train loss:0.004049902169424427\n",
      "train loss:0.0012020791855527108\n",
      "train loss:0.007965858326071511\n",
      "train loss:0.008030779908078335\n",
      "train loss:0.029342163681644454\n",
      "train loss:0.0027638043534852115\n",
      "train loss:0.0012629142735584948\n",
      "train loss:0.005211411296799837\n",
      "train loss:0.0032268454160301625\n",
      "train loss:0.0006587675359376062\n",
      "train loss:0.001688382459364579\n",
      "train loss:0.001314732615973843\n",
      "train loss:0.0032794544297327847\n",
      "train loss:0.0076148342967779\n",
      "train loss:0.008439897333827998\n",
      "train loss:0.000556885071335516\n",
      "train loss:0.0006270924157682885\n",
      "train loss:0.0011899042061633768\n",
      "train loss:0.011813250295105113\n",
      "train loss:0.029349025399106693\n",
      "train loss:0.003963596590491499\n",
      "train loss:0.005689175589446613\n",
      "train loss:0.0036495548285059064\n",
      "train loss:0.006837834837098966\n",
      "train loss:0.0007274870340663929\n",
      "train loss:0.010230876167112294\n",
      "train loss:0.0027183094677601864\n",
      "train loss:0.004546989676836217\n",
      "train loss:0.0020939067759159014\n",
      "train loss:0.001871189132384429\n",
      "train loss:0.009947915035614995\n",
      "train loss:0.0008614332198686975\n",
      "train loss:0.002032392303912149\n",
      "train loss:0.0020160240672269215\n",
      "train loss:0.003776139236698796\n",
      "train loss:0.016142972615014465\n",
      "train loss:0.004345017877949889\n",
      "train loss:0.0016554562610338885\n",
      "train loss:0.013994561971000965\n",
      "train loss:0.013279407980924963\n",
      "train loss:0.0018354765379090857\n",
      "train loss:0.006497235315000971\n",
      "train loss:0.0012275959952444278\n",
      "train loss:0.004484173875613376\n",
      "train loss:0.007258030209891508\n",
      "train loss:0.0009669768561854434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.028019191854753864\n",
      "train loss:0.04267565055272491\n",
      "train loss:0.0009196471415146615\n",
      "train loss:0.06095373235610748\n",
      "train loss:0.0005739072767841493\n",
      "train loss:0.009074720620239576\n",
      "train loss:0.003594316115122196\n",
      "train loss:0.0006237664649709805\n",
      "train loss:0.0037141224929563353\n",
      "train loss:0.007089174751263167\n",
      "train loss:0.019606166486171236\n",
      "train loss:0.012282134135822534\n",
      "train loss:0.0043757190133428625\n",
      "train loss:0.009165039958784489\n",
      "train loss:0.000574909968933451\n",
      "train loss:0.0044367574839907515\n",
      "train loss:0.005606994318978971\n",
      "train loss:0.0012842464798138815\n",
      "train loss:0.006113620754738151\n",
      "train loss:0.0026258719613531253\n",
      "train loss:0.0011163859818318306\n",
      "train loss:0.0031923185450494786\n",
      "train loss:0.004354374031561705\n",
      "train loss:0.001357718323960058\n",
      "train loss:0.0013396007922729302\n",
      "train loss:0.001645561276152809\n",
      "train loss:0.00219059259227561\n",
      "train loss:0.005924306612731817\n",
      "train loss:0.004593123859133999\n",
      "train loss:0.0007209685726337048\n",
      "train loss:0.0016521910018014025\n",
      "train loss:0.0023297710630887972\n",
      "train loss:0.0002152091230752122\n",
      "train loss:0.008039213598112535\n",
      "train loss:0.0021529682796744757\n",
      "train loss:0.003444722445926747\n",
      "train loss:0.003674811941542744\n",
      "train loss:0.00538600745303\n",
      "train loss:0.0042631076020005175\n",
      "train loss:0.0032445005934307884\n",
      "train loss:0.0005520381950877202\n",
      "train loss:0.0036721965064520318\n",
      "train loss:0.0008699222294059717\n",
      "train loss:0.003161426901836477\n",
      "train loss:0.008906253243452778\n",
      "train loss:0.008585660424310726\n",
      "train loss:0.00044205311063450154\n",
      "train loss:0.001407204291843136\n",
      "train loss:0.0009860616122697766\n",
      "train loss:0.002632308101327922\n",
      "train loss:0.05445002813124133\n",
      "train loss:0.00042170958440837926\n",
      "train loss:0.004532866873078797\n",
      "train loss:0.00047740906193969923\n",
      "train loss:0.003980077414107684\n",
      "train loss:0.002242441074918683\n",
      "train loss:0.0063641779069354065\n",
      "train loss:0.0023476909042996113\n",
      "train loss:0.002917807902977041\n",
      "train loss:0.002105686661834885\n",
      "train loss:0.007789662888037175\n",
      "train loss:0.0067729941576591245\n",
      "train loss:0.004657401146627446\n",
      "train loss:0.005135893805191019\n",
      "train loss:0.0018326918472397486\n",
      "train loss:0.0025022190999639538\n",
      "train loss:0.017381527329438776\n",
      "train loss:0.016764528869935458\n",
      "train loss:0.006259919940296756\n",
      "train loss:0.0022731064648603876\n",
      "train loss:0.0060802319790319095\n",
      "train loss:0.003930145593177694\n",
      "train loss:0.004706035116002369\n",
      "train loss:0.002895979225590932\n",
      "train loss:0.0049581975505969865\n",
      "train loss:0.0013307526812382446\n",
      "train loss:0.008976452445390247\n",
      "train loss:0.00182842908184575\n",
      "train loss:0.002020947384294322\n",
      "train loss:0.020141026849538307\n",
      "train loss:0.021068827362282196\n",
      "train loss:0.008856620306823475\n",
      "train loss:0.005748598935086622\n",
      "train loss:0.010269508932080396\n",
      "train loss:0.0003756304842787369\n",
      "train loss:0.004220927261076246\n",
      "train loss:0.0009545916142130348\n",
      "train loss:0.009426409087633597\n",
      "train loss:0.0028424604922726924\n",
      "train loss:0.0001278627920411549\n",
      "train loss:0.011235032273160113\n",
      "train loss:0.0015536275763026798\n",
      "train loss:0.009681413057296365\n",
      "train loss:0.0017140642758926774\n",
      "train loss:0.002927803082970907\n",
      "train loss:0.00593737188172196\n",
      "train loss:0.0030087058030431758\n",
      "train loss:0.004246147129279135\n",
      "train loss:0.0027311280829154065\n",
      "train loss:0.009050270477561862\n",
      "train loss:0.003036383329240489\n",
      "train loss:0.0005553715377846357\n",
      "train loss:0.0016119253187782678\n",
      "train loss:0.010535643622542827\n",
      "train loss:0.03390556581668291\n",
      "train loss:0.0021442476205110676\n",
      "train loss:0.0016214321956914603\n",
      "train loss:0.0004093214126309317\n",
      "train loss:0.001963572723976943\n",
      "train loss:0.005031387728053507\n",
      "train loss:0.0076957664534215275\n",
      "train loss:0.0038470016319756706\n",
      "train loss:0.0016990569769643718\n",
      "train loss:0.0028771287807188785\n",
      "train loss:0.0007487587384937454\n",
      "train loss:0.00309206276758801\n",
      "train loss:0.00041246427314551687\n",
      "train loss:0.005832831078782761\n",
      "train loss:0.0013193111028908145\n",
      "train loss:0.007518535515566757\n",
      "train loss:0.012915681125662087\n",
      "train loss:0.017137203757390335\n",
      "train loss:0.00544982959073559\n",
      "train loss:0.001887921372690513\n",
      "train loss:0.001397496373660902\n",
      "train loss:0.00206832511486782\n",
      "train loss:0.0056495405280891035\n",
      "train loss:0.005110645313294895\n",
      "train loss:0.023281247099927356\n",
      "train loss:0.002713205110127319\n",
      "train loss:0.0012912998109084709\n",
      "train loss:0.0010904625064512674\n",
      "train loss:0.018282544692908697\n",
      "train loss:0.01499819219484774\n",
      "train loss:0.004494088852665044\n",
      "train loss:0.02873788220506487\n",
      "train loss:0.010342900712266607\n",
      "train loss:0.006660001943235539\n",
      "train loss:0.008697737433788044\n",
      "train loss:0.002112974770165742\n",
      "train loss:0.018323027237649163\n",
      "train loss:0.0023290035744692643\n",
      "train loss:0.017329546510612054\n",
      "train loss:0.0042797367993403805\n",
      "train loss:0.00484456554441813\n",
      "train loss:0.004896312985711981\n",
      "train loss:0.004213682387102397\n",
      "train loss:0.017504050293477517\n",
      "train loss:0.005786500992516036\n",
      "train loss:0.0032281695107588266\n",
      "train loss:0.0043974231151910756\n",
      "train loss:0.0012910073083223933\n",
      "train loss:0.008625807189009434\n",
      "train loss:0.0037907519342207222\n",
      "train loss:0.007252271695188278\n",
      "train loss:0.0027486490872207364\n",
      "train loss:0.08363127080322455\n",
      "train loss:0.00931268460948897\n",
      "train loss:0.0006343500171044937\n",
      "train loss:0.0003674847049460497\n",
      "train loss:0.015149491615032217\n",
      "train loss:0.0007619672228629769\n",
      "train loss:0.005941872433173465\n",
      "train loss:0.005864624111314408\n",
      "train loss:0.0014957335771906026\n",
      "train loss:0.0010925468303179405\n",
      "train loss:0.021853757390159913\n",
      "train loss:0.00396986429397331\n",
      "train loss:0.005339965372979329\n",
      "train loss:0.0045502544413562\n",
      "train loss:0.004964076444187751\n",
      "train loss:0.004684921805347288\n",
      "train loss:0.00843007623429788\n",
      "train loss:0.0010916520432264806\n",
      "train loss:0.004449465506882957\n",
      "train loss:0.003363095639969836\n",
      "train loss:0.0037521710984940444\n",
      "train loss:0.003257610537205148\n",
      "train loss:0.003596514724577736\n",
      "train loss:0.006617606996981978\n",
      "train loss:0.008295414458521498\n",
      "train loss:0.002968678540798416\n",
      "train loss:0.005690888930116576\n",
      "train loss:0.026426537626737533\n",
      "train loss:0.0011574433584857337\n",
      "train loss:0.0018915430137345158\n",
      "train loss:0.009862817631598296\n",
      "train loss:0.021573249262086657\n",
      "train loss:0.0002589690456140919\n",
      "train loss:0.005949525048328019\n",
      "train loss:0.0012147743114930517\n",
      "train loss:0.0013268164283465082\n",
      "train loss:0.009012022897031246\n",
      "train loss:0.005415440458058453\n",
      "train loss:0.007152498385533422\n",
      "train loss:0.001148971313180768\n",
      "train loss:0.005440725961715228\n",
      "train loss:0.0031632483166686353\n",
      "train loss:0.014125129692161877\n",
      "train loss:0.0026555309266942185\n",
      "train loss:0.006109200495694921\n",
      "train loss:0.0014399514162483885\n",
      "train loss:0.011305535955722184\n",
      "train loss:0.012312794646045537\n",
      "train loss:0.0006907507127048246\n",
      "train loss:0.0020476392235919817\n",
      "train loss:0.003300499320437256\n",
      "train loss:0.00130857591032515\n",
      "train loss:0.011542989403795431\n",
      "train loss:0.00685488666074886\n",
      "train loss:0.005209511032013046\n",
      "train loss:0.006141087960215901\n",
      "train loss:0.003518154102362723\n",
      "train loss:0.002544790011550615\n",
      "train loss:0.011443696544628387\n",
      "train loss:0.002388184439518545\n",
      "train loss:0.005413232898290114\n",
      "train loss:0.004054017457960569\n",
      "train loss:0.0009311683985203838\n",
      "train loss:0.0171457976711538\n",
      "train loss:0.0007827752508157483\n",
      "train loss:0.0020110917582580727\n",
      "train loss:0.00035384793579379555\n",
      "train loss:0.001302987465956374\n",
      "train loss:0.0018187721612398452\n",
      "train loss:0.00254412140964529\n",
      "train loss:0.0014969505095796649\n",
      "train loss:0.011521257554199164\n",
      "train loss:0.001942757282771197\n",
      "train loss:0.002401917202389083\n",
      "train loss:0.017813842901060174\n",
      "train loss:0.0019901707954151243\n",
      "train loss:0.002618930124849721\n",
      "train loss:0.000840664093001063\n",
      "train loss:0.0028024214744163446\n",
      "train loss:0.0010909289775765047\n",
      "train loss:0.004930996273753065\n",
      "train loss:0.0004113604271342084\n",
      "train loss:0.0045050730616645026\n",
      "train loss:0.0003639026635297579\n",
      "train loss:0.00038524832630739683\n",
      "train loss:0.05384008111871597\n",
      "train loss:0.0017162445654107504\n",
      "train loss:0.00366609114149674\n",
      "train loss:0.0032804898947831657\n",
      "train loss:0.011804098647328452\n",
      "train loss:0.06868369889839761\n",
      "train loss:0.005399512026541261\n",
      "train loss:0.0005443031585564037\n",
      "train loss:0.0006635138971074553\n",
      "train loss:0.0015538507497764385\n",
      "train loss:0.005712390124822197\n",
      "train loss:0.0040154558343125845\n",
      "train loss:0.005444548621375176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00540826552008816\n",
      "train loss:0.007192398173796441\n",
      "train loss:0.007685529126970248\n",
      "train loss:0.012052410226354823\n",
      "train loss:0.0019308386093387089\n",
      "train loss:0.0003216592050488059\n",
      "train loss:0.0028724240491075814\n",
      "train loss:0.007420730520084879\n",
      "train loss:0.0032173272078733686\n",
      "train loss:0.004123079274293979\n",
      "train loss:0.001434546203193003\n",
      "train loss:0.005351070722764838\n",
      "train loss:0.009349633472987453\n",
      "train loss:0.007381627842061213\n",
      "train loss:0.00247320696735911\n",
      "train loss:0.0019456070696107445\n",
      "train loss:0.00564076779724465\n",
      "train loss:0.0017583047710315446\n",
      "train loss:0.011581079834673063\n",
      "train loss:0.0008290790728635855\n",
      "train loss:0.0012448491098512135\n",
      "train loss:0.0013517877126844888\n",
      "train loss:0.00036230458804127294\n",
      "train loss:0.00803626167894627\n",
      "train loss:0.029066724316880288\n",
      "train loss:0.005688992596153518\n",
      "train loss:0.010410727518826143\n",
      "train loss:0.0012243184197835227\n",
      "train loss:0.0013462787277804993\n",
      "train loss:0.0038386953744014175\n",
      "train loss:0.012962933083717034\n",
      "train loss:0.0005294019183245751\n",
      "train loss:0.006690595122097277\n",
      "train loss:0.0011328512255098647\n",
      "train loss:0.006289909126165407\n",
      "train loss:0.007797143670541259\n",
      "train loss:0.0004786550554842402\n",
      "train loss:0.06517309402344894\n",
      "train loss:0.0002592463812448076\n",
      "train loss:0.00045416423402180173\n",
      "train loss:0.0021279543408452535\n",
      "train loss:0.0029549347050398258\n",
      "train loss:0.002075985812028774\n",
      "train loss:0.005663908633576369\n",
      "train loss:0.0003863196947229539\n",
      "train loss:0.002320456670258074\n",
      "train loss:0.0028390307810649295\n",
      "train loss:0.0012338631153740777\n",
      "train loss:0.0019130199426610425\n",
      "train loss:0.003359183857746527\n",
      "train loss:0.009565325282502481\n",
      "train loss:0.00032393099138167266\n",
      "train loss:0.0006474104745369404\n",
      "train loss:0.002857653516216826\n",
      "train loss:0.0006572448640433144\n",
      "train loss:0.0035734825860933013\n",
      "train loss:0.006193960267316216\n",
      "train loss:0.0011553181013548147\n",
      "train loss:0.0008624905820042439\n",
      "train loss:0.0034680176817912505\n",
      "train loss:0.001075860966376876\n",
      "train loss:0.0002793416592099683\n",
      "train loss:0.0015649220785852603\n",
      "train loss:0.0009775609222999694\n",
      "train loss:0.0019847319315230622\n",
      "train loss:0.0013492419068299507\n",
      "train loss:0.002448379489052322\n",
      "train loss:0.0007208343785507185\n",
      "train loss:0.0026771014930860792\n",
      "train loss:0.00493075112639016\n",
      "train loss:0.015020679524510644\n",
      "train loss:0.013004463469356393\n",
      "train loss:0.0040970608863905526\n",
      "train loss:0.00020881199849448104\n",
      "train loss:0.002431319817996049\n",
      "train loss:0.00370652145791336\n",
      "train loss:0.004296504601047953\n",
      "train loss:0.00351197057888952\n",
      "train loss:0.006409211946094902\n",
      "train loss:0.056793879454018974\n",
      "train loss:0.008809410855178704\n",
      "train loss:0.0008767210530218442\n",
      "train loss:0.01090429328056183\n",
      "train loss:0.002958223815453949\n",
      "train loss:0.00782805362602798\n",
      "train loss:0.012142075296432584\n",
      "train loss:0.006666145454036984\n",
      "train loss:0.011972804920793388\n",
      "train loss:0.0023781264236367354\n",
      "train loss:0.0031064247965581883\n",
      "train loss:0.008699407351639965\n",
      "train loss:0.006521152068031949\n",
      "train loss:0.008950795950175765\n",
      "train loss:0.0013058655517441914\n",
      "train loss:0.0008705724494703485\n",
      "train loss:0.003996996468021319\n",
      "train loss:0.0015222978069769752\n",
      "train loss:0.001908624963299185\n",
      "train loss:0.001248532108599351\n",
      "train loss:0.008647377503149499\n",
      "train loss:0.00663014816253128\n",
      "train loss:0.007267161179468118\n",
      "train loss:0.0018687849208656624\n",
      "train loss:0.002202714742442974\n",
      "train loss:0.003177526819880699\n",
      "train loss:0.0013916227086145233\n",
      "train loss:0.0008644331738098285\n",
      "train loss:0.011572205964766219\n",
      "train loss:0.0006913850292051417\n",
      "train loss:0.003630090451916968\n",
      "train loss:0.005560788440165954\n",
      "train loss:0.005610308865987742\n",
      "train loss:0.009657719662253898\n",
      "train loss:0.004019333439845309\n",
      "train loss:0.006646572675625595\n",
      "train loss:0.013793978228388784\n",
      "train loss:0.004193852268966757\n",
      "train loss:0.0002207171622122161\n",
      "train loss:0.0023192187406523793\n",
      "train loss:0.009886958481703019\n",
      "train loss:0.002242916269271168\n",
      "train loss:0.00094209192964749\n",
      "train loss:0.0008001447617238022\n",
      "train loss:0.002051617992519276\n",
      "train loss:0.0027033731171019603\n",
      "train loss:0.0045483256915992264\n",
      "train loss:0.001162400894839352\n",
      "train loss:0.00993380840733266\n",
      "train loss:0.00146856900852175\n",
      "train loss:0.0011495573056190015\n",
      "train loss:0.0198860148752373\n",
      "train loss:0.00040007654298248577\n",
      "train loss:0.003800929617882498\n",
      "train loss:0.0051840642606696165\n",
      "train loss:0.001028290125076957\n",
      "train loss:0.024789190160300553\n",
      "train loss:0.0034663301415583407\n",
      "train loss:0.0003698927946419519\n",
      "train loss:0.0009232081948050002\n",
      "train loss:0.02283686072095151\n",
      "train loss:0.002278464750011359\n",
      "train loss:0.0037859032455070806\n",
      "train loss:0.00235979730447324\n",
      "train loss:0.008467368869561257\n",
      "train loss:0.0011846348987254705\n",
      "train loss:0.005371667669707691\n",
      "train loss:0.011273369675293183\n",
      "train loss:0.011393258424194322\n",
      "train loss:0.002015838898937063\n",
      "train loss:0.0044893918317805695\n",
      "train loss:0.015651113595468502\n",
      "train loss:0.0023687447605184927\n",
      "train loss:0.0038102875372961354\n",
      "train loss:0.001190449842928588\n",
      "train loss:0.0027046055517998473\n",
      "train loss:0.005432273345834801\n",
      "train loss:0.0037726128735463865\n",
      "train loss:0.0008218944847830734\n",
      "train loss:0.0026986460921645627\n",
      "train loss:0.011167212953114593\n",
      "train loss:0.0007099874427746408\n",
      "train loss:0.008619914506047932\n",
      "train loss:0.0075214091503144585\n",
      "train loss:0.001375308541139713\n",
      "train loss:0.0070405211596083015\n",
      "train loss:0.004122485223362847\n",
      "train loss:0.008999432157847272\n",
      "train loss:0.0036033729221391763\n",
      "train loss:0.0009655258305242012\n",
      "train loss:0.0026151345103134576\n",
      "train loss:0.013174324067521845\n",
      "train loss:0.008956670977949766\n",
      "train loss:0.006789381596144357\n",
      "train loss:0.0005392000716838027\n",
      "train loss:0.0009997691558986384\n",
      "train loss:0.0005401144092891808\n",
      "train loss:0.000960794448178688\n",
      "train loss:0.008477433237696706\n",
      "train loss:0.001744200037568003\n",
      "train loss:0.001263588439822402\n",
      "train loss:0.0006763073011734829\n",
      "train loss:0.0030319872495045597\n",
      "train loss:0.001173129082727629\n",
      "train loss:0.00676160419983001\n",
      "train loss:0.0009681780174549561\n",
      "train loss:0.046447120488236744\n",
      "train loss:0.002519082167744909\n",
      "train loss:0.0034105853575165978\n",
      "train loss:0.0029139195753497705\n",
      "train loss:0.01482211167291767\n",
      "train loss:0.0023694845342453782\n",
      "train loss:0.0032093845454145326\n",
      "train loss:0.03252664044618551\n",
      "train loss:0.001775090381013908\n",
      "train loss:0.0045095196118518635\n",
      "train loss:0.009341943314424549\n",
      "train loss:0.013907959430237905\n",
      "train loss:0.010541453852172375\n",
      "train loss:0.011081620375728346\n",
      "train loss:0.0016135777237248142\n",
      "train loss:0.0006846299764453255\n",
      "train loss:0.012148167335797582\n",
      "train loss:0.0018705697424609394\n",
      "train loss:0.013077888050788754\n",
      "train loss:0.01271381624164784\n",
      "train loss:0.0011958494671430323\n",
      "train loss:0.0020823418272836315\n",
      "train loss:0.0004018155191467026\n",
      "train loss:0.0014242334712417787\n",
      "train loss:0.0032009789554044094\n",
      "train loss:0.003278839593723369\n",
      "=== epoch:13, train acc:0.997, test acc:0.98 ===\n",
      "train loss:0.006610149968507259\n",
      "train loss:0.001758718631558008\n",
      "train loss:0.0015154084902999966\n",
      "train loss:0.003684942344497128\n",
      "train loss:0.002738255611547958\n",
      "train loss:0.0021854572127361638\n",
      "train loss:0.0018311302130099905\n",
      "train loss:0.007474431415274849\n",
      "train loss:0.002903756127012671\n",
      "train loss:0.002466284517111463\n",
      "train loss:0.006954443559046345\n",
      "train loss:0.0013012245381210377\n",
      "train loss:0.0026771194149333207\n",
      "train loss:0.0017860768350247413\n",
      "train loss:0.03874608354500292\n",
      "train loss:0.002471112192149536\n",
      "train loss:0.0030906298010813134\n",
      "train loss:0.003414282483164584\n",
      "train loss:0.0013029816308279478\n",
      "train loss:0.0010407927388655475\n",
      "train loss:0.004281874941854406\n",
      "train loss:0.0025815447563001803\n",
      "train loss:0.0035561809574053884\n",
      "train loss:0.01883866277734221\n",
      "train loss:0.0033607518203151022\n",
      "train loss:0.0003957832482816844\n",
      "train loss:0.0005040190814554658\n",
      "train loss:0.0022594600891929924\n",
      "train loss:0.004295640734247321\n",
      "train loss:0.004176048929061077\n",
      "train loss:0.002618979463138788\n",
      "train loss:0.00033379576185991805\n",
      "train loss:0.010002408307008827\n",
      "train loss:0.003996887996126674\n",
      "train loss:0.004501886358289274\n",
      "train loss:0.0003422459904680179\n",
      "train loss:0.0008182837975503032\n",
      "train loss:0.0010396965157981738\n",
      "train loss:6.818711357628198e-05\n",
      "train loss:0.0004881828774009236\n",
      "train loss:0.0016072547793045042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002826355485406723\n",
      "train loss:0.0009557267782250067\n",
      "train loss:0.0030269853750783528\n",
      "train loss:0.002098852491301247\n",
      "train loss:0.006142023404574518\n",
      "train loss:0.0014353876346357972\n",
      "train loss:0.004686544774390497\n",
      "train loss:0.004194599781287911\n",
      "train loss:0.004019528369218693\n",
      "train loss:0.0015096955490316857\n",
      "train loss:0.0016813166599514448\n",
      "train loss:0.0028508055569572118\n",
      "train loss:0.001411978400419533\n",
      "train loss:0.005099816933130621\n",
      "train loss:0.006317272438616977\n",
      "train loss:0.0062613326432383685\n",
      "train loss:0.01735607088938873\n",
      "train loss:0.012489888185727065\n",
      "train loss:0.0025641050692816604\n",
      "train loss:0.0021476660213057947\n",
      "train loss:0.003281195604281968\n",
      "train loss:0.0005959435232972001\n",
      "train loss:0.00839890166882086\n",
      "train loss:0.00898032366198512\n",
      "train loss:0.00014640313780443846\n",
      "train loss:0.001220539182398528\n",
      "train loss:0.0001389505261160025\n",
      "train loss:0.011392416171375506\n",
      "train loss:0.0029744341598345776\n",
      "train loss:0.0038155878925407016\n",
      "train loss:0.0003981531822322122\n",
      "train loss:0.0006157886942122698\n",
      "train loss:0.0004998783883546682\n",
      "train loss:0.0017799774618740666\n",
      "train loss:0.0017332986448039562\n",
      "train loss:0.03324621382973821\n",
      "train loss:0.0045769799547458745\n",
      "train loss:0.01742584535607858\n",
      "train loss:0.0007633127137174353\n",
      "train loss:0.0008367209330668294\n",
      "train loss:0.014640919085989183\n",
      "train loss:0.00382945191355344\n",
      "train loss:0.025243455286056142\n",
      "train loss:0.002325772693113627\n",
      "train loss:0.0016267461837748687\n",
      "train loss:0.0015145891072260076\n",
      "train loss:0.0681828465667386\n",
      "train loss:0.002307381011620057\n",
      "train loss:0.004039447790238001\n",
      "train loss:0.0022729536075433\n",
      "train loss:0.0009076005915813523\n",
      "train loss:0.006896275236757574\n",
      "train loss:0.000641918900700289\n",
      "train loss:0.0017763687514534474\n",
      "train loss:0.002868718818992554\n",
      "train loss:0.021337339563258464\n",
      "train loss:0.0005989786183600977\n",
      "train loss:0.002194987400180474\n",
      "train loss:0.0058166380824897146\n",
      "train loss:0.0011268721912051644\n",
      "train loss:0.0008697360272153033\n",
      "train loss:0.05405131730993312\n",
      "train loss:0.01070055885811659\n",
      "train loss:0.000778859558716259\n",
      "train loss:0.0008739880811419451\n",
      "train loss:0.0029070567277457503\n",
      "train loss:0.009124275836207786\n",
      "train loss:0.0018823778470694172\n",
      "train loss:0.007473233366245392\n",
      "train loss:0.0006215450896683546\n",
      "train loss:0.0029931242198592005\n",
      "train loss:0.008743634939764053\n",
      "train loss:0.00044238977359509706\n",
      "train loss:0.0013843996250794289\n",
      "train loss:0.0003486287529226006\n",
      "train loss:0.0012649758895322222\n",
      "train loss:0.0010498846653979744\n",
      "train loss:0.003982450913466846\n",
      "train loss:0.003966688955720824\n",
      "train loss:0.011442708159542988\n",
      "train loss:0.0011357986071982547\n",
      "train loss:0.0012049462001448542\n",
      "train loss:0.0004874809658003865\n",
      "train loss:0.005203123571072887\n",
      "train loss:0.030481026135358014\n",
      "train loss:0.002037510399472891\n",
      "train loss:0.005089755052968184\n",
      "train loss:0.00035692600800714673\n",
      "train loss:0.002444500711667313\n",
      "train loss:0.0028150731959145927\n",
      "train loss:0.003623644899519397\n",
      "train loss:0.004356214991997173\n",
      "train loss:0.004287797402310835\n",
      "train loss:0.013920689197973906\n",
      "train loss:0.0005300822496186596\n",
      "train loss:0.008170807345767795\n",
      "train loss:0.0018015409694075698\n",
      "train loss:0.03601900182040967\n",
      "train loss:0.012202425516903412\n",
      "train loss:0.003395804536931236\n",
      "train loss:0.0005442196245244506\n",
      "train loss:0.008618679377961984\n",
      "train loss:0.026163547973501403\n",
      "train loss:0.00827091092615121\n",
      "train loss:0.0015345024700932528\n",
      "train loss:0.0012609520100774448\n",
      "train loss:0.0017363367507149444\n",
      "train loss:0.007593059707588242\n",
      "train loss:0.0045084712540776\n",
      "train loss:0.001969879647168127\n",
      "train loss:0.003959893123309389\n",
      "train loss:0.0030189272693010557\n",
      "train loss:0.011584730797888153\n",
      "train loss:0.004086523807463655\n",
      "train loss:0.01769989658225907\n",
      "train loss:0.004500912409640814\n",
      "train loss:0.0026658856145026586\n",
      "train loss:0.0033969290829841607\n",
      "train loss:0.021232672778583046\n",
      "train loss:0.00037274875487540703\n",
      "train loss:0.0013676511001147753\n",
      "train loss:0.01486363726058999\n",
      "train loss:0.001548488754007809\n",
      "train loss:0.008195920981666953\n",
      "train loss:0.002934071689720761\n",
      "train loss:0.006182288835435523\n",
      "train loss:0.00236659500425452\n",
      "train loss:0.011313347105012639\n",
      "train loss:0.010702467939661377\n",
      "train loss:0.022771991267473878\n",
      "train loss:0.008411603429164513\n",
      "train loss:0.0013184690999343879\n",
      "train loss:0.0027275153502138248\n",
      "train loss:0.011573214447343856\n",
      "train loss:0.0023523986725406264\n",
      "train loss:0.00291179179611705\n",
      "train loss:0.001303973656985227\n",
      "train loss:0.0025583964401028935\n",
      "train loss:0.00516992273562536\n",
      "train loss:0.008870510080927919\n",
      "train loss:0.0056758592757766525\n",
      "train loss:0.0018788966652803453\n",
      "train loss:0.006739137684336002\n",
      "train loss:0.02149601213248974\n",
      "train loss:0.0011660107052308764\n",
      "train loss:0.000666564212422196\n",
      "train loss:0.00027587267926274846\n",
      "train loss:0.003236175247102204\n",
      "train loss:0.00913392133094678\n",
      "train loss:0.0025320408301569477\n",
      "train loss:0.00039651672322826956\n",
      "train loss:0.005558364338609013\n",
      "train loss:0.0005083368584469432\n",
      "train loss:0.023934580857710653\n",
      "train loss:0.00807046111496905\n",
      "train loss:0.0017840958448555801\n",
      "train loss:0.004043461038165127\n",
      "train loss:0.010811536914461559\n",
      "train loss:0.0032033462405149093\n",
      "train loss:0.0017249305622183914\n",
      "train loss:0.004513882560802595\n",
      "train loss:0.00606019771530193\n",
      "train loss:0.004107368357898763\n",
      "train loss:0.0029085083543338545\n",
      "train loss:0.006714662272813943\n",
      "train loss:0.000914244680215721\n",
      "train loss:0.0027477225121416956\n",
      "train loss:0.007759785564477235\n",
      "train loss:0.0007731742096550704\n",
      "train loss:0.0027759615704530823\n",
      "train loss:0.0017579077586038713\n",
      "train loss:0.0014557528950163313\n",
      "train loss:0.0041603314304423785\n",
      "train loss:0.00610441794196016\n",
      "train loss:0.006752866510420163\n",
      "train loss:0.014762037925462275\n",
      "train loss:0.0009454376160948775\n",
      "train loss:0.0018780885584177408\n",
      "train loss:0.018541984277250397\n",
      "train loss:0.0014294245987189708\n",
      "train loss:0.00028074565241880425\n",
      "train loss:0.01755100599590215\n",
      "train loss:0.002366209574850531\n",
      "train loss:0.0015058886281914513\n",
      "train loss:0.005130572161105553\n",
      "train loss:0.017524286177333724\n",
      "train loss:0.001650775426144339\n",
      "train loss:0.02131635981711333\n",
      "train loss:0.01358092628547876\n",
      "train loss:0.004349637696785432\n",
      "train loss:0.00503870833959532\n",
      "train loss:0.0008470807431899968\n",
      "train loss:0.004241953007837122\n",
      "train loss:0.0055110568433358875\n",
      "train loss:0.001447577553302095\n",
      "train loss:0.006360841993470171\n",
      "train loss:0.0036857279185938145\n",
      "train loss:0.009227096471907281\n",
      "train loss:0.0016852382555286505\n",
      "train loss:0.0013381947740446992\n",
      "train loss:0.011214161951065069\n",
      "train loss:0.0012724005682848041\n",
      "train loss:0.008146687005465534\n",
      "train loss:0.0030882130475519613\n",
      "train loss:0.002675436458373602\n",
      "train loss:0.01079305717684816\n",
      "train loss:0.006092244330228586\n",
      "train loss:0.0002908015457521399\n",
      "train loss:0.011696630681161694\n",
      "train loss:0.0015667985619938643\n",
      "train loss:0.001096355118810379\n",
      "train loss:0.0028060185717574972\n",
      "train loss:0.0033479332512086598\n",
      "train loss:0.0009539463239521087\n",
      "train loss:0.0028782571577504177\n",
      "train loss:0.0054584986536769095\n",
      "train loss:0.005880626294370427\n",
      "train loss:0.0025198066635480298\n",
      "train loss:0.0025625494970145145\n",
      "train loss:0.00029397208774482994\n",
      "train loss:0.001142951124086656\n",
      "train loss:0.003049037234714554\n",
      "train loss:0.0015097847389930947\n",
      "train loss:0.0003958601750963598\n",
      "train loss:0.00021882454472360786\n",
      "train loss:0.004416039377700767\n",
      "train loss:0.008552010097448255\n",
      "train loss:0.003434078614236718\n",
      "train loss:0.001098581925049813\n",
      "train loss:0.0023363099719623404\n",
      "train loss:0.004734144315991692\n",
      "train loss:0.0029880089099627804\n",
      "train loss:0.0004629854172590775\n",
      "train loss:0.003403622757402015\n",
      "train loss:0.0014110092022294254\n",
      "train loss:0.002047257701254317\n",
      "train loss:0.005098609185979705\n",
      "train loss:0.05781626203877208\n",
      "train loss:0.001676428898555028\n",
      "train loss:0.0013032273468007005\n",
      "train loss:0.003970370906398672\n",
      "train loss:0.0004483446144817708\n",
      "train loss:0.0010812488684797726\n",
      "train loss:0.0054221635354803465\n",
      "train loss:0.012237573278137332\n",
      "train loss:0.002715346756127366\n",
      "train loss:0.010629915216384598\n",
      "train loss:0.004124709592380376\n",
      "train loss:0.0017366278730808178\n",
      "train loss:0.0015064100425785305\n",
      "train loss:0.0008976788048171473\n",
      "train loss:0.0003317935533808224\n",
      "train loss:0.0006804996934984772\n",
      "train loss:0.008799407363205869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.003643815564652529\n",
      "train loss:0.005518011505568861\n",
      "train loss:0.0010810373719294985\n",
      "train loss:0.0015347613824405301\n",
      "train loss:0.0027297222486697852\n",
      "train loss:0.0022169501852949336\n",
      "train loss:0.004164161197526401\n",
      "train loss:0.0021433726004117097\n",
      "train loss:0.002081833687110436\n",
      "train loss:0.0029317494612835877\n",
      "train loss:0.01442535583226662\n",
      "train loss:0.0024654598054011916\n",
      "train loss:0.0005823832766993998\n",
      "train loss:0.001108957096221465\n",
      "train loss:0.003281140798515644\n",
      "train loss:0.0018224505110371791\n",
      "train loss:0.0002997692345697983\n",
      "train loss:0.000436116404578245\n",
      "train loss:0.000993400511588901\n",
      "train loss:0.0035530465114283647\n",
      "train loss:0.0014978899618197485\n",
      "train loss:0.0065017412950459106\n",
      "train loss:0.009775740652443951\n",
      "train loss:0.0041837717671993355\n",
      "train loss:0.003046688388259516\n",
      "train loss:0.0005801370976229881\n",
      "train loss:0.0005432573193612691\n",
      "train loss:0.0069841277356417365\n",
      "train loss:0.009486444553258689\n",
      "train loss:0.0035153024944079574\n",
      "train loss:0.001358944316611342\n",
      "train loss:0.002227650610586173\n",
      "train loss:0.012919671282564398\n",
      "train loss:0.0014639678491468792\n",
      "train loss:0.004393032628219001\n",
      "train loss:0.004972360605017498\n",
      "train loss:0.0005749045922818359\n",
      "train loss:0.028198885011774224\n",
      "train loss:0.0005245059971677345\n",
      "train loss:0.0058895822657218655\n",
      "train loss:0.0033627033682236945\n",
      "train loss:0.004318423516646209\n",
      "train loss:0.0001630160123437734\n",
      "train loss:0.0006580765822437238\n",
      "train loss:0.003573851983412772\n",
      "train loss:0.0005197855299821464\n",
      "train loss:0.004850883081710092\n",
      "train loss:0.0006501535438324608\n",
      "train loss:0.006786006767728555\n",
      "train loss:0.0024992658507731664\n",
      "train loss:0.01058217263590294\n",
      "train loss:0.0023530836470028087\n",
      "train loss:0.0005146379826253196\n",
      "train loss:0.005209929657170611\n",
      "train loss:0.0018471450682370878\n",
      "train loss:0.0031413415245708353\n",
      "train loss:0.0017854008452910146\n",
      "train loss:0.0032362340524475313\n",
      "train loss:0.00469530520530587\n",
      "train loss:0.0011266386153805522\n",
      "train loss:0.0026407284471915587\n",
      "train loss:0.0092117850087068\n",
      "train loss:0.0017994336477770345\n",
      "train loss:0.015415039244799035\n",
      "train loss:0.0005564288642578303\n",
      "train loss:0.0032051945066731043\n",
      "train loss:0.003803858398292072\n",
      "train loss:0.0020239395439364386\n",
      "train loss:0.0032196179617217683\n",
      "train loss:0.0037753146644998177\n",
      "train loss:0.004448459505393573\n",
      "train loss:0.0005404581842581123\n",
      "train loss:0.0020470461262929807\n",
      "train loss:0.004166141672909924\n",
      "train loss:0.001254135691268727\n",
      "train loss:0.0019096608016500919\n",
      "train loss:0.0007313433057885586\n",
      "train loss:0.007573967165485137\n",
      "train loss:0.0006353920885868508\n",
      "train loss:0.0002394870566755985\n",
      "train loss:0.001325889184935872\n",
      "train loss:0.0008989903373648843\n",
      "train loss:0.003695891322299917\n",
      "train loss:0.002100723798022322\n",
      "train loss:0.0019125704969706224\n",
      "train loss:0.06158226678323503\n",
      "train loss:0.003507289873167595\n",
      "train loss:0.0031053459632870407\n",
      "train loss:0.0008238559587149593\n",
      "train loss:0.010053524550551009\n",
      "train loss:0.009223234223252707\n",
      "train loss:0.0019005726300357377\n",
      "train loss:0.002194526745691063\n",
      "train loss:0.007925395299016272\n",
      "train loss:0.002870955979890023\n",
      "train loss:0.00168815554066767\n",
      "train loss:0.0006828006520500713\n",
      "train loss:0.001188925763767929\n",
      "train loss:0.00014261958846558033\n",
      "train loss:0.00431288340642797\n",
      "train loss:0.0013962080836660013\n",
      "train loss:0.00027717198113855744\n",
      "train loss:0.008633643244329785\n",
      "train loss:0.0013068235995690016\n",
      "train loss:0.004547081791075769\n",
      "train loss:0.0035079735538962463\n",
      "train loss:0.018737025597140456\n",
      "train loss:0.0016915392989456455\n",
      "train loss:0.001601740123066666\n",
      "train loss:0.0027046475199548952\n",
      "train loss:0.0007193000325729478\n",
      "train loss:0.0012109229144335024\n",
      "train loss:0.0007568318594849965\n",
      "train loss:0.0002553262644592508\n",
      "train loss:0.056156372266009204\n",
      "train loss:0.0043133038707581514\n",
      "train loss:0.00041145093864199947\n",
      "train loss:0.001974853143790705\n",
      "train loss:0.00045990471151971844\n",
      "train loss:0.004153249187110954\n",
      "train loss:0.010995455998739672\n",
      "train loss:0.001767024963789956\n",
      "train loss:0.006792114196649667\n",
      "train loss:0.00030535244511363004\n",
      "train loss:0.00025363772152113334\n",
      "train loss:0.0014424711968984427\n",
      "train loss:0.0005255423411752283\n",
      "train loss:0.0016509308983200693\n",
      "train loss:0.0011600679602754701\n",
      "train loss:0.006780095052556953\n",
      "train loss:0.0023126503960145275\n",
      "train loss:0.0008308447793665889\n",
      "train loss:0.0010581214878216693\n",
      "train loss:0.002457684519595684\n",
      "train loss:0.0014237629171260438\n",
      "train loss:0.001199897573883619\n",
      "train loss:0.016612840437362796\n",
      "train loss:0.0016349958435391157\n",
      "train loss:0.005924287570450516\n",
      "train loss:0.0035469854921236403\n",
      "train loss:0.000969121208096316\n",
      "train loss:0.002013175697812328\n",
      "train loss:0.0016840534918382037\n",
      "train loss:0.013393383677246901\n",
      "train loss:0.004918736535408411\n",
      "train loss:0.010898290800594696\n",
      "train loss:0.0026607445407732084\n",
      "train loss:0.002983179565147281\n",
      "train loss:0.0018283473435479671\n",
      "train loss:0.003346502300083206\n",
      "train loss:0.0021552937104585856\n",
      "train loss:0.0033557334269739406\n",
      "train loss:0.00029848921040598277\n",
      "train loss:0.001821184005584532\n",
      "train loss:0.0032557064027898854\n",
      "train loss:0.011681199260803764\n",
      "train loss:0.0035936611310633223\n",
      "train loss:0.002369142320184578\n",
      "train loss:0.004366132608772524\n",
      "train loss:0.0018607474461997974\n",
      "train loss:0.002198115789598538\n",
      "train loss:0.003570335407438916\n",
      "train loss:0.0006642590134100865\n",
      "train loss:0.0007881358935746294\n",
      "train loss:0.004045844522889321\n",
      "train loss:0.0008969429924233977\n",
      "train loss:0.004431014412613187\n",
      "train loss:0.0008364058980482328\n",
      "train loss:0.009770603509290968\n",
      "train loss:0.009351778962368922\n",
      "train loss:0.0007161824448445074\n",
      "train loss:0.0017300808948031716\n",
      "train loss:0.0020081330153665315\n",
      "train loss:0.006630377028202228\n",
      "train loss:0.0012860684076331595\n",
      "train loss:0.0035559098163685746\n",
      "train loss:0.0022272564686589102\n",
      "train loss:0.0008716153759115003\n",
      "train loss:0.002791919048555249\n",
      "train loss:0.004259721709687809\n",
      "train loss:0.01468834055605846\n",
      "train loss:0.00275027227916744\n",
      "train loss:0.0002062064309734506\n",
      "train loss:0.00985653115763692\n",
      "train loss:0.0037272641237476507\n",
      "train loss:0.005528351131589373\n",
      "train loss:0.007627558170484661\n",
      "train loss:0.002099939789374464\n",
      "train loss:0.0020756014855668327\n",
      "train loss:0.0017586561737894947\n",
      "train loss:0.003908520035858738\n",
      "train loss:0.0013478302997054054\n",
      "train loss:0.002474180890433459\n",
      "train loss:0.0007861936975092201\n",
      "train loss:0.000532661725028324\n",
      "train loss:0.007091107848340859\n",
      "train loss:0.0009134393772104035\n",
      "train loss:0.003650085416325155\n",
      "train loss:0.0005766852177447105\n",
      "train loss:0.00045074628251470057\n",
      "train loss:0.000423202422332969\n",
      "train loss:0.00036996569759896556\n",
      "train loss:0.004340146613200392\n",
      "train loss:0.00977675812164724\n",
      "train loss:0.007289954498143142\n",
      "train loss:0.000833133377700595\n",
      "train loss:0.03416623471039617\n",
      "train loss:0.001159183318808115\n",
      "train loss:0.0013379919988335592\n",
      "train loss:0.0008778168488672712\n",
      "train loss:0.0014945723400134623\n",
      "train loss:0.006896903544400947\n",
      "train loss:0.0006168822909466171\n",
      "train loss:0.0034022240893151496\n",
      "train loss:0.008583749889344851\n",
      "train loss:0.0012739867919631565\n",
      "train loss:0.003734616011679822\n",
      "train loss:0.0012492022067985384\n",
      "train loss:0.009576115225669252\n",
      "train loss:0.004327950113345607\n",
      "train loss:0.00045186492519852956\n",
      "train loss:0.0014503645537703885\n",
      "train loss:0.00210289658241956\n",
      "train loss:0.006795926435669233\n",
      "train loss:0.006849291033623315\n",
      "train loss:0.009736079485469968\n",
      "train loss:0.019903526337858374\n",
      "train loss:0.0036165219652360427\n",
      "train loss:0.002131789300924468\n",
      "train loss:0.0022271725563527993\n",
      "train loss:0.0012731671098058736\n",
      "train loss:0.0007680071643263294\n",
      "train loss:0.00014459246516227082\n",
      "train loss:0.0003864137542739545\n",
      "train loss:0.00042295610787363927\n",
      "train loss:0.001366542069422843\n",
      "train loss:0.0008047672357170617\n",
      "train loss:0.0012009672377915304\n",
      "train loss:0.00069881363942137\n",
      "train loss:0.0049575737942480075\n",
      "train loss:0.006404389248817045\n",
      "train loss:0.009171048093045616\n",
      "train loss:0.0016883995166540652\n",
      "train loss:0.0030761684885650662\n",
      "train loss:0.000505204443189279\n",
      "train loss:0.0003503942279394541\n",
      "train loss:0.0009258326275671787\n",
      "train loss:0.0027858554081635826\n",
      "train loss:0.01586771789329915\n",
      "train loss:0.00754254672973894\n",
      "train loss:0.0020949236595914503\n",
      "train loss:0.004510625135866979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.003724534190847534\n",
      "train loss:0.008689666638881613\n",
      "train loss:0.0019183675847679591\n",
      "train loss:0.014660055085651442\n",
      "train loss:0.001900064336726861\n",
      "train loss:7.058170297878158e-05\n",
      "train loss:0.009843635191404411\n",
      "train loss:0.0013313570382669077\n",
      "train loss:0.00033190623665854284\n",
      "train loss:0.0009629482250875608\n",
      "train loss:0.003165231137579326\n",
      "train loss:0.0009414304870944109\n",
      "train loss:0.003687906921751845\n",
      "train loss:0.0007017552783943426\n",
      "train loss:0.000335214766462106\n",
      "train loss:0.004710482108065428\n",
      "train loss:0.00017012234967502145\n",
      "train loss:0.0075739788213614635\n",
      "train loss:0.0005787977592697141\n",
      "train loss:0.0019394011272868875\n",
      "train loss:0.00230341560559539\n",
      "train loss:0.0028234621260197802\n",
      "train loss:0.00414206722188722\n",
      "train loss:0.0007124663884030839\n",
      "train loss:0.002285377040787703\n",
      "train loss:0.0003041331975593983\n",
      "train loss:0.0033828087819414974\n",
      "train loss:0.001271468173883576\n",
      "train loss:0.0003147776720097545\n",
      "train loss:0.00039206035902736926\n",
      "train loss:0.013876401940203634\n",
      "train loss:0.0007149428805037835\n",
      "train loss:0.0016169368163976444\n",
      "train loss:0.013907517394746043\n",
      "train loss:0.0006393344466344595\n",
      "train loss:0.0036464592682315723\n",
      "train loss:0.0048780340477599235\n",
      "train loss:0.0025500373262528093\n",
      "train loss:0.0008580720112393703\n",
      "train loss:0.002599594847875729\n",
      "train loss:0.0008015333398830681\n",
      "train loss:0.02933047206773619\n",
      "train loss:0.0013674512893370155\n",
      "train loss:0.0006008486412968553\n",
      "train loss:0.010295772849388983\n",
      "train loss:0.044306587060077535\n",
      "train loss:0.0011715792643070234\n",
      "train loss:0.006486665979989325\n",
      "train loss:0.01121073286959576\n",
      "train loss:0.012051418580943805\n",
      "train loss:0.0038883978267611795\n",
      "train loss:0.007379161170041987\n",
      "train loss:0.004076162763999931\n",
      "=== epoch:14, train acc:0.999, test acc:0.983 ===\n",
      "train loss:0.0013296026288013097\n",
      "train loss:0.006156021754739041\n",
      "train loss:0.003978270444142121\n",
      "train loss:0.02285284326102091\n",
      "train loss:0.0002925731944523771\n",
      "train loss:0.0007839497801046783\n",
      "train loss:0.0017819432398930818\n",
      "train loss:0.009124460737791508\n",
      "train loss:0.0037225846229537317\n",
      "train loss:0.004066040162151058\n",
      "train loss:0.002481052762730073\n",
      "train loss:0.0033741277803346643\n",
      "train loss:0.00442137633232072\n",
      "train loss:0.0021832892792350545\n",
      "train loss:0.004787894298984048\n",
      "train loss:0.04249951390657901\n",
      "train loss:0.021963200285078234\n",
      "train loss:0.0021343500511449842\n",
      "train loss:0.0036325089507213706\n",
      "train loss:0.003036783689736392\n",
      "train loss:0.0026102614766222052\n",
      "train loss:0.004235635067609029\n",
      "train loss:0.002784563609841344\n",
      "train loss:0.0008304391974028237\n",
      "train loss:0.003104816857721579\n",
      "train loss:0.0008698252700127217\n",
      "train loss:0.001532855754539973\n",
      "train loss:0.004061673531712818\n",
      "train loss:0.0025620987582532628\n",
      "train loss:0.0018832996508744923\n",
      "train loss:0.0013710654730642313\n",
      "train loss:0.015258100220321414\n",
      "train loss:0.006635323192107487\n",
      "train loss:0.0016307919387203906\n",
      "train loss:0.003214979702120194\n",
      "train loss:0.012718024799509793\n",
      "train loss:0.00042286667844370447\n",
      "train loss:0.002417416269186451\n",
      "train loss:0.00803865141877939\n",
      "train loss:0.006871563650359566\n",
      "train loss:0.0006946494071873524\n",
      "train loss:0.00020471122660836006\n",
      "train loss:0.003620087899575771\n",
      "train loss:0.015587096146441855\n",
      "train loss:0.0019619277542676328\n",
      "train loss:0.0006521856594684652\n",
      "train loss:0.0015523555730606172\n",
      "train loss:0.009362333881583453\n",
      "train loss:0.01587682660992869\n",
      "train loss:0.005996830042131331\n",
      "train loss:0.0008723693197391978\n",
      "train loss:0.000289980523750347\n",
      "train loss:0.0009501435395314556\n",
      "train loss:0.006678914049614026\n",
      "train loss:0.005104074877373528\n",
      "train loss:0.0020774228968773265\n",
      "train loss:0.00021119801194184671\n",
      "train loss:0.004440436166785652\n",
      "train loss:0.0005663288687663052\n",
      "train loss:0.005434563919962422\n",
      "train loss:0.002367029199457396\n",
      "train loss:0.0005637233170419577\n",
      "train loss:0.0051191290202376345\n",
      "train loss:0.0022269862334566093\n",
      "train loss:0.004099664125611099\n",
      "train loss:0.0013789888713932582\n",
      "train loss:0.0017989729196095637\n",
      "train loss:0.001713317293119218\n",
      "train loss:0.0042947671063426115\n",
      "train loss:0.001097640868408989\n",
      "train loss:0.00619824722243941\n",
      "train loss:0.0029226032774784193\n",
      "train loss:0.0008762018906196758\n",
      "train loss:0.0013447630888436407\n",
      "train loss:0.00976661714370293\n",
      "train loss:0.0027797540132967753\n",
      "train loss:0.00018734353650737412\n",
      "train loss:0.009604931286625353\n",
      "train loss:0.006556209676627472\n",
      "train loss:0.0021595487721915566\n",
      "train loss:0.001129115875607552\n",
      "train loss:0.0004986996311978881\n",
      "train loss:0.002547080641863369\n",
      "train loss:0.0013797840594777613\n",
      "train loss:0.0014762788568511021\n",
      "train loss:0.0025395567524784455\n",
      "train loss:0.005308330413744919\n",
      "train loss:0.011178438603198186\n",
      "train loss:0.003955900211956277\n",
      "train loss:0.008377996899108767\n",
      "train loss:0.002817861583011747\n",
      "train loss:0.006492829790148186\n",
      "train loss:0.0007518804945059605\n",
      "train loss:0.003250778670156037\n",
      "train loss:0.0005440265988698946\n",
      "train loss:0.0024954573588704876\n",
      "train loss:0.0011756655721127441\n",
      "train loss:0.0002021914396009811\n",
      "train loss:0.0025874725394150195\n",
      "train loss:0.006856370860982492\n",
      "train loss:0.004866353457979197\n",
      "train loss:0.00622279207220936\n",
      "train loss:0.004359355659171499\n",
      "train loss:0.003678146589003966\n",
      "train loss:0.00028913087235843225\n",
      "train loss:0.0005663213734359424\n",
      "train loss:0.002734904319485924\n",
      "train loss:0.0022888913152226812\n",
      "train loss:0.0005868658861218961\n",
      "train loss:0.007370486573711955\n",
      "train loss:0.004077507219637549\n",
      "train loss:0.0008369976008966044\n",
      "train loss:0.010737681569072883\n",
      "train loss:0.00030468626162542914\n",
      "train loss:0.0023139823274521045\n",
      "train loss:0.0033008425215584392\n",
      "train loss:0.0008238517094043394\n",
      "train loss:9.597802291989213e-05\n",
      "train loss:0.0226011435449012\n",
      "train loss:0.019053275167813896\n",
      "train loss:8.220672237933564e-05\n",
      "train loss:0.0015475965504173862\n",
      "train loss:0.001951353678672033\n",
      "train loss:0.0026881922946548737\n",
      "train loss:0.004182748445407964\n",
      "train loss:0.002407033931606791\n",
      "train loss:0.006533748798459196\n",
      "train loss:0.0013987122948287117\n",
      "train loss:0.0026111749492542125\n",
      "train loss:0.0024086226414369986\n",
      "train loss:0.002028239288194002\n",
      "train loss:0.025762036695383822\n",
      "train loss:0.001054117703244822\n",
      "train loss:0.002153119887109676\n",
      "train loss:0.004991987819315232\n",
      "train loss:0.0019829444003653437\n",
      "train loss:0.006215548685827562\n",
      "train loss:0.0036741483901647615\n",
      "train loss:0.0006876418983313609\n",
      "train loss:0.005831866519149587\n",
      "train loss:0.0005750327395007833\n",
      "train loss:0.003798894943240427\n",
      "train loss:0.002853776375742182\n",
      "train loss:0.0022363758388178594\n",
      "train loss:0.009902999630259186\n",
      "train loss:0.00432562692441311\n",
      "train loss:0.0013682648914185242\n",
      "train loss:0.004684252520690455\n",
      "train loss:0.0004578884700949784\n",
      "train loss:0.00019102138060172306\n",
      "train loss:0.0001923050195886484\n",
      "train loss:0.003874674396541615\n",
      "train loss:0.002916363816245306\n",
      "train loss:8.974175480916657e-05\n",
      "train loss:0.00034493790111336423\n",
      "train loss:0.002706186366104932\n",
      "train loss:0.0002892330938177461\n",
      "train loss:0.001356782334251291\n",
      "train loss:0.00047195550464836555\n",
      "train loss:0.0008884060813807662\n",
      "train loss:0.004433185107370314\n",
      "train loss:0.0020628634371391524\n",
      "train loss:0.0007869541741634012\n",
      "train loss:0.0035416259393489125\n",
      "train loss:0.0007578502514823211\n",
      "train loss:0.005262918916074915\n",
      "train loss:0.002583792621387651\n",
      "train loss:0.008247570140889868\n",
      "train loss:0.012382561117138487\n",
      "train loss:0.021255756114775863\n",
      "train loss:0.0018524423548987468\n",
      "train loss:0.0090190855406666\n",
      "train loss:0.0012995609975070882\n",
      "train loss:0.0007820429912106092\n",
      "train loss:0.0004874048558960338\n",
      "train loss:0.0030551992365011886\n",
      "train loss:0.006564731668539217\n",
      "train loss:0.0014011538182912388\n",
      "train loss:0.007433121849771489\n",
      "train loss:0.0012571636462710434\n",
      "train loss:0.0023654108370264274\n",
      "train loss:0.002530562326219183\n",
      "train loss:0.011069458231663104\n",
      "train loss:0.0019309022958837053\n",
      "train loss:0.0019032486403865883\n",
      "train loss:0.002874440262293935\n",
      "train loss:0.005131296276193152\n",
      "train loss:0.004292848122351392\n",
      "train loss:0.003676128939672036\n",
      "train loss:0.0043883459824066535\n",
      "train loss:0.001301839784055749\n",
      "train loss:0.0004428599684042918\n",
      "train loss:0.0044687269475896544\n",
      "train loss:0.027522277290151158\n",
      "train loss:0.004925405057464088\n",
      "train loss:0.001940221638306406\n",
      "train loss:0.007716633583689263\n",
      "train loss:0.0008509085170209207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.003756328551966389\n",
      "train loss:0.0015267309417332686\n",
      "train loss:0.0017116408560299038\n",
      "train loss:0.012425496082800103\n",
      "train loss:0.006144745426641924\n",
      "train loss:0.002555087172909215\n",
      "train loss:0.0008052888571783748\n",
      "train loss:0.01217467941240176\n",
      "train loss:0.0012570038368290306\n",
      "train loss:0.007816128157349424\n",
      "train loss:0.017327645319924513\n",
      "train loss:0.000667067959851757\n",
      "train loss:0.04024860684393363\n",
      "train loss:0.0033010637922751577\n",
      "train loss:0.007847369694572962\n",
      "train loss:0.0008523875397440027\n",
      "train loss:0.0038980617498460698\n",
      "train loss:0.0035198635906403598\n",
      "train loss:0.003289801840135125\n",
      "train loss:0.003641411438567092\n",
      "train loss:0.0004754348812791928\n",
      "train loss:0.008988272220334851\n",
      "train loss:0.00231367401257914\n",
      "train loss:0.001787735241484576\n",
      "train loss:0.002478220797491746\n",
      "train loss:0.0016081167931093297\n",
      "train loss:0.004200479167390445\n",
      "train loss:0.019816451607298682\n",
      "train loss:0.0004975713204100236\n",
      "train loss:0.0027508080336817457\n",
      "train loss:0.0038133656139219\n",
      "train loss:0.00336948291017815\n",
      "train loss:0.005348031702650174\n",
      "train loss:0.0007680197018292428\n",
      "train loss:0.010755652648241123\n",
      "train loss:0.006813172541745701\n",
      "train loss:0.00029633093934945204\n",
      "train loss:0.01014517671088435\n",
      "train loss:0.021939257471932955\n",
      "train loss:0.004020137520094538\n",
      "train loss:0.0006876844601361334\n",
      "train loss:0.0016372050538521038\n",
      "train loss:0.0025299569447331484\n",
      "train loss:0.004593660251883358\n",
      "train loss:0.008698351672372576\n",
      "train loss:0.004255676372390954\n",
      "train loss:0.024871822431599567\n",
      "train loss:0.006250899506871855\n",
      "train loss:0.02868603856329356\n",
      "train loss:0.0033207955567450113\n",
      "train loss:0.0008916798772595005\n",
      "train loss:0.0004149304165330492\n",
      "train loss:0.006038817681394804\n",
      "train loss:0.010002223139971265\n",
      "train loss:0.014289780751833072\n",
      "train loss:0.0011186924392229897\n",
      "train loss:0.0006401128228201505\n",
      "train loss:0.004064845502369146\n",
      "train loss:0.0009640453775194731\n",
      "train loss:0.0012918421718616582\n",
      "train loss:0.008916188001905643\n",
      "train loss:0.0024905013095200016\n",
      "train loss:0.0009258257623688038\n",
      "train loss:0.0029337975765898056\n",
      "train loss:0.001449975939913928\n",
      "train loss:0.0015270793949961642\n",
      "train loss:0.005397790716318049\n",
      "train loss:0.008818539797053737\n",
      "train loss:0.0014006689187725852\n",
      "train loss:0.0003045130361560512\n",
      "train loss:0.002765184402179334\n",
      "train loss:0.00046215665765330955\n",
      "train loss:0.004244119592214413\n",
      "train loss:0.01137413906465244\n",
      "train loss:0.0007224699919805705\n",
      "train loss:0.006150640924567413\n",
      "train loss:0.0015777503023977305\n",
      "train loss:0.0005688715107565188\n",
      "train loss:0.0012911736093527654\n",
      "train loss:0.00023359027274376013\n",
      "train loss:0.0036590949684744277\n",
      "train loss:0.00362510794971805\n",
      "train loss:0.0014122759982396268\n",
      "train loss:0.0005236450180824844\n",
      "train loss:0.005979159332606151\n",
      "train loss:0.0024109816506188383\n",
      "train loss:0.0019458988762896625\n",
      "train loss:0.0004079226869823081\n",
      "train loss:0.006225540227656008\n",
      "train loss:0.007131972383599535\n",
      "train loss:0.003598500539538209\n",
      "train loss:0.0011444271235887668\n",
      "train loss:0.0013029363969172289\n",
      "train loss:0.0013358660364944325\n",
      "train loss:0.002016395866419187\n",
      "train loss:0.019790857470100683\n",
      "train loss:0.0014550456862890714\n",
      "train loss:0.0016413175418846652\n",
      "train loss:0.0014474077446991447\n",
      "train loss:0.006328228600045313\n",
      "train loss:0.008965141501163591\n",
      "train loss:0.005114802962204704\n",
      "train loss:0.004550029418836952\n",
      "train loss:0.012880346380535763\n",
      "train loss:0.0020242870162930416\n",
      "train loss:0.002091651341757004\n",
      "train loss:0.0029478923325402594\n",
      "train loss:0.0007619800691613009\n",
      "train loss:0.006151820202432398\n",
      "train loss:0.002262775801625376\n",
      "train loss:0.006607753948373743\n",
      "train loss:0.0013383780690737243\n",
      "train loss:0.003540146566991499\n",
      "train loss:0.0022653829022912597\n",
      "train loss:0.007317319413820478\n",
      "train loss:0.0013532030559772858\n",
      "train loss:0.0015165746064123185\n",
      "train loss:0.010279043152298281\n",
      "train loss:0.0015944188287584896\n",
      "train loss:0.0011022006948326463\n",
      "train loss:0.002441149610774943\n",
      "train loss:0.005571903148789272\n",
      "train loss:0.0368145066950369\n",
      "train loss:0.0015243118990883916\n",
      "train loss:0.0012574051402568496\n",
      "train loss:0.0003972778504719237\n",
      "train loss:0.00450747295413048\n",
      "train loss:0.0031313209710978366\n",
      "train loss:0.0009293864728056724\n",
      "train loss:0.0027584194873108803\n",
      "train loss:0.03827013594600604\n",
      "train loss:0.0021387901876803784\n",
      "train loss:0.008947475735290278\n",
      "train loss:0.0020086980217765434\n",
      "train loss:0.0018925374339957138\n",
      "train loss:0.0002081986015117041\n",
      "train loss:0.0007550604034143187\n",
      "train loss:0.0012570838942261653\n",
      "train loss:0.006680779043853893\n",
      "train loss:0.003052533162265759\n",
      "train loss:0.00312542290487763\n",
      "train loss:0.0032628754498186512\n",
      "train loss:0.004810068284330854\n",
      "train loss:0.002545718276950215\n",
      "train loss:0.0007410532688976695\n",
      "train loss:0.00040918927831627515\n",
      "train loss:0.0014397474274650702\n",
      "train loss:0.0017582420526300114\n",
      "train loss:0.0061608853549792245\n",
      "train loss:0.014144170958118527\n",
      "train loss:0.008668069603744827\n",
      "train loss:0.03230936188299956\n",
      "train loss:0.0002976710645350118\n",
      "train loss:0.003033167741614354\n",
      "train loss:0.0010340133032643772\n",
      "train loss:0.000370642165888119\n",
      "train loss:0.0012210750317750354\n",
      "train loss:0.0005340819481928025\n",
      "train loss:0.0002372058891347324\n",
      "train loss:0.00582792527409422\n",
      "train loss:0.0007364070397397518\n",
      "train loss:0.0007015651614347849\n",
      "train loss:0.009760511490751118\n",
      "train loss:0.0007223526563627737\n",
      "train loss:0.026189540230517106\n",
      "train loss:0.0006452280570545933\n",
      "train loss:0.0022851488749239704\n",
      "train loss:0.00856470822075134\n",
      "train loss:0.0038731184669016415\n",
      "train loss:0.0031023924635852373\n",
      "train loss:0.003667416621550273\n",
      "train loss:0.0006549093333872716\n",
      "train loss:0.002603834181938216\n",
      "train loss:0.0017916107443121496\n",
      "train loss:0.015382472266032338\n",
      "train loss:0.00041955794688053804\n",
      "train loss:0.0011267734568161626\n",
      "train loss:0.0011046212283458978\n",
      "train loss:0.008195231533519696\n",
      "train loss:0.0009338277618616874\n",
      "train loss:0.006315784001707441\n",
      "train loss:0.003197187216500984\n",
      "train loss:0.001562970721465976\n",
      "train loss:0.0024722382531752072\n",
      "train loss:0.01310875947582534\n",
      "train loss:0.009567917669193031\n",
      "train loss:0.009198067376160045\n",
      "train loss:0.001101820380370315\n",
      "train loss:0.0023537682595751704\n",
      "train loss:0.014142028940000176\n",
      "train loss:0.0008024130463082583\n",
      "train loss:0.004713470691701338\n",
      "train loss:0.0014764765631685294\n",
      "train loss:0.0008874109584012047\n",
      "train loss:0.004291387134918293\n",
      "train loss:0.0008456650969215948\n",
      "train loss:0.0003098652937143109\n",
      "train loss:0.007763527091737299\n",
      "train loss:0.0021017600771137753\n",
      "train loss:0.0018023208534402042\n",
      "train loss:0.0012029320683405956\n",
      "train loss:0.00019534696168726628\n",
      "train loss:0.002262771229287703\n",
      "train loss:0.0002899221622367544\n",
      "train loss:0.001571169637970942\n",
      "train loss:0.005409341784176827\n",
      "train loss:0.00023480702612764263\n",
      "train loss:0.0020212415212947986\n",
      "train loss:0.0023747547346691794\n",
      "train loss:0.001125526095647898\n",
      "train loss:0.0020723449157451414\n",
      "train loss:0.0003889534701971675\n",
      "train loss:0.0012900958917407763\n",
      "train loss:0.0006139300527329705\n",
      "train loss:0.000279152836096762\n",
      "train loss:0.00018158425641815335\n",
      "train loss:0.030901921738009347\n",
      "train loss:0.0013152005316284772\n",
      "train loss:0.0022179842003844682\n",
      "train loss:0.00017451660750243838\n",
      "train loss:0.0005942312313405978\n",
      "train loss:0.002353248409918779\n",
      "train loss:0.0007080528228157672\n",
      "train loss:0.002503919215585244\n",
      "train loss:0.004691076296478157\n",
      "train loss:0.0002698821382841544\n",
      "train loss:0.0004701371186289763\n",
      "train loss:0.0031672076994339136\n",
      "train loss:0.0017385370367122102\n",
      "train loss:0.00035880550794589386\n",
      "train loss:0.0003972117595989722\n",
      "train loss:0.0017910382249866253\n",
      "train loss:0.005145467122897977\n",
      "train loss:0.0014871470692368024\n",
      "train loss:0.00021413368003632668\n",
      "train loss:0.000494104803335916\n",
      "train loss:0.0020243273221629064\n",
      "train loss:0.0033371411554190987\n",
      "train loss:0.00042595934474812936\n",
      "train loss:0.0009941252284282327\n",
      "train loss:0.0018824270040259732\n",
      "train loss:0.0011184824192983793\n",
      "train loss:0.0007147208668493492\n",
      "train loss:9.585314642132772e-05\n",
      "train loss:0.0009020840931775721\n",
      "train loss:0.004502489868891246\n",
      "train loss:0.0007233773274525905\n",
      "train loss:0.0006858399331723346\n",
      "train loss:0.0023379612662300354\n",
      "train loss:0.002035141133420759\n",
      "train loss:0.003284082937052082\n",
      "train loss:0.0009067352439665874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.006777281216040609\n",
      "train loss:0.00031196181717687253\n",
      "train loss:0.0014046200269339426\n",
      "train loss:0.002122141531161306\n",
      "train loss:0.0017133927716634393\n",
      "train loss:0.002238670794293456\n",
      "train loss:0.00027851624391429005\n",
      "train loss:0.0031036653999511354\n",
      "train loss:0.002445460601426148\n",
      "train loss:0.0035160173958245578\n",
      "train loss:0.00021145625994001518\n",
      "train loss:0.001895159263407909\n",
      "train loss:0.005395078809124092\n",
      "train loss:0.004923056411245888\n",
      "train loss:0.0030547549759013305\n",
      "train loss:0.004439288116418229\n",
      "train loss:0.002271531599106286\n",
      "train loss:0.0009114401116384696\n",
      "train loss:0.0005666693606478635\n",
      "train loss:0.004973549487631446\n",
      "train loss:0.025840339886384914\n",
      "train loss:0.0024056167786421635\n",
      "train loss:0.0013622727420631985\n",
      "train loss:0.00204525197815374\n",
      "train loss:0.0015492546891246355\n",
      "train loss:0.0006137067533148254\n",
      "train loss:0.001504431902786915\n",
      "train loss:0.011678235215597538\n",
      "train loss:0.006490595012652329\n",
      "train loss:0.00045547592297219303\n",
      "train loss:0.00032276742923399146\n",
      "train loss:0.0026560861961441562\n",
      "train loss:0.0007413580040315917\n",
      "train loss:0.00031767631208447206\n",
      "train loss:0.020246668685152604\n",
      "train loss:0.0005020288355130446\n",
      "train loss:0.0017027008451224394\n",
      "train loss:0.013878705825386993\n",
      "train loss:0.0013484512570719255\n",
      "train loss:0.002608992725469794\n",
      "train loss:0.001475475174444215\n",
      "train loss:0.002510713612170042\n",
      "train loss:0.000642241449074609\n",
      "train loss:0.0022518950021767794\n",
      "train loss:0.0024101555663197886\n",
      "train loss:0.003098015565941049\n",
      "train loss:0.00030193842297686466\n",
      "train loss:0.006032912666259878\n",
      "train loss:0.0019134333090642692\n",
      "train loss:0.0006862706726318789\n",
      "train loss:0.0017797869802767563\n",
      "train loss:0.001978796471250411\n",
      "train loss:0.00035014022514528456\n",
      "train loss:0.0014833910856801916\n",
      "train loss:0.000281135068392314\n",
      "train loss:0.003095591515987672\n",
      "train loss:0.0008216545415245104\n",
      "train loss:0.004043802710491092\n",
      "train loss:0.0013247129026943952\n",
      "train loss:0.006127760896754789\n",
      "train loss:0.0009588697365706042\n",
      "train loss:0.0007011421235482889\n",
      "train loss:0.0011283868507640062\n",
      "train loss:0.0007039556029776521\n",
      "train loss:0.0004050507053801881\n",
      "train loss:0.003244622527843184\n",
      "train loss:0.00010934403376234077\n",
      "train loss:0.0022292590192519533\n",
      "train loss:0.0002891156952773003\n",
      "train loss:0.0021037987764844185\n",
      "train loss:0.004547449844520003\n",
      "train loss:0.0028970882335688465\n",
      "train loss:0.004165031004675554\n",
      "train loss:0.00046877578473561324\n",
      "train loss:0.0008887971713589224\n",
      "train loss:0.0022259093632725204\n",
      "train loss:0.0011810528220369911\n",
      "train loss:0.002761976541068662\n",
      "train loss:0.03292845955791821\n",
      "train loss:0.004685574285017793\n",
      "train loss:0.0013055111131701888\n",
      "train loss:0.0011931135015494075\n",
      "train loss:0.0035148288253787326\n",
      "train loss:0.006926984177351047\n",
      "train loss:0.006657497842557317\n",
      "train loss:0.002690856325800422\n",
      "train loss:0.004157036908934504\n",
      "train loss:0.002582383978423598\n",
      "train loss:0.0020654209637637104\n",
      "train loss:0.005169658770494863\n",
      "train loss:0.005749837856054141\n",
      "train loss:0.00045350179122794274\n",
      "train loss:0.006354828984985754\n",
      "train loss:0.0012272407356885954\n",
      "train loss:0.001581756983153825\n",
      "train loss:0.0007645488910156396\n",
      "train loss:0.002138443241309512\n",
      "train loss:0.0009667098226732882\n",
      "train loss:0.00012393208102903165\n",
      "train loss:0.0004970785068803773\n",
      "train loss:0.0020892698803405673\n",
      "train loss:0.00031669487925827466\n",
      "train loss:0.0011548632242697474\n",
      "train loss:0.0037018572605674797\n",
      "train loss:0.002946376725399963\n",
      "train loss:0.0005237824820829259\n",
      "train loss:0.001768400680613102\n",
      "train loss:0.004745993659195974\n",
      "train loss:0.0016324148024774077\n",
      "train loss:0.001874941523771921\n",
      "train loss:0.0018012276925822998\n",
      "train loss:0.00032570725005595034\n",
      "train loss:0.0005773408331301171\n",
      "train loss:2.7170613200066715e-05\n",
      "train loss:0.003593014169356528\n",
      "train loss:0.0020823323203356873\n",
      "train loss:0.0007481525095747519\n",
      "train loss:0.0006561029856717157\n",
      "train loss:0.0010061892606928946\n",
      "train loss:0.0020921633051987666\n",
      "train loss:0.002625205917902012\n",
      "train loss:0.003991199558859821\n",
      "train loss:0.000663896914646429\n",
      "train loss:0.001866026353486894\n",
      "train loss:0.0012386413943710377\n",
      "train loss:0.0016046637353985985\n",
      "train loss:0.0006739622918030642\n",
      "train loss:0.005493754921504496\n",
      "train loss:0.0015629285368919455\n",
      "train loss:0.0010928411422309679\n",
      "train loss:0.0006183591956572399\n",
      "train loss:0.00019111823805100753\n",
      "train loss:0.003297700789260515\n",
      "train loss:0.0038042787881640543\n",
      "train loss:0.0008955288579810939\n",
      "train loss:0.0008536301912295016\n",
      "train loss:0.000977227039585561\n",
      "train loss:0.0022622980680010235\n",
      "train loss:0.002253694533498646\n",
      "train loss:0.00024910735310465455\n",
      "train loss:0.0011957208004441172\n",
      "train loss:0.025966571177630408\n",
      "train loss:0.0008598028123915867\n",
      "train loss:0.0012408747925151137\n",
      "train loss:0.0014985911960307507\n",
      "train loss:0.014347997690257493\n",
      "train loss:0.00036570992535367013\n",
      "train loss:0.004976200355988638\n",
      "train loss:0.0008164336574539155\n",
      "train loss:0.00032089948126140896\n",
      "=== epoch:15, train acc:0.994, test acc:0.985 ===\n",
      "train loss:0.008951864788283055\n",
      "train loss:0.00025430507970453564\n",
      "train loss:0.0008129208800445695\n",
      "train loss:0.0003614400356904071\n",
      "train loss:0.00043462354529175476\n",
      "train loss:0.004704807278714857\n",
      "train loss:0.007371795568045698\n",
      "train loss:0.0005785929270560352\n",
      "train loss:0.0033396593624684828\n",
      "train loss:0.0027602475179625825\n",
      "train loss:0.009726902319331316\n",
      "train loss:0.0021270786086716375\n",
      "train loss:0.0015588883817413291\n",
      "train loss:0.0008434889453028657\n",
      "train loss:0.0012266926297932084\n",
      "train loss:0.00436499608378798\n",
      "train loss:0.00010251113721873993\n",
      "train loss:0.00025603067985934447\n",
      "train loss:0.0007316037599779354\n",
      "train loss:0.00013187873524941\n",
      "train loss:0.0010071136829946446\n",
      "train loss:0.010679373605405608\n",
      "train loss:0.0019179130262547096\n",
      "train loss:0.0018932267767848893\n",
      "train loss:0.018490108878039542\n",
      "train loss:0.001297882053089502\n",
      "train loss:0.023249839839057578\n",
      "train loss:0.008412594614911612\n",
      "train loss:0.005794709178157556\n",
      "train loss:0.0015908178913173533\n",
      "train loss:0.0036279085938284617\n",
      "train loss:0.0030043761981453153\n",
      "train loss:0.0036584386755019933\n",
      "train loss:0.0012062993166421215\n",
      "train loss:0.0011611553587158436\n",
      "train loss:0.0006922455128054679\n",
      "train loss:0.0003201540696419134\n",
      "train loss:0.0026529844291778965\n",
      "train loss:0.00013228698434986286\n",
      "train loss:0.00026089083767632284\n",
      "train loss:0.0018514711494700222\n",
      "train loss:0.0003993011278927687\n",
      "train loss:0.0014181855186884138\n",
      "train loss:0.005568325213851851\n",
      "train loss:0.001050154757400036\n",
      "train loss:0.0035545562940108083\n",
      "train loss:0.005098392591709911\n",
      "train loss:0.00139675350660931\n",
      "train loss:0.003551937746536928\n",
      "train loss:0.003276079187972657\n",
      "train loss:0.002285834570688893\n",
      "train loss:0.00047658443998496\n",
      "train loss:0.0009828837808902276\n",
      "train loss:0.001639023334270445\n",
      "train loss:0.0030084956766477087\n",
      "train loss:0.0025089441400165118\n",
      "train loss:0.0014621923078669888\n",
      "train loss:0.0008797946844219548\n",
      "train loss:0.0018155747012783866\n",
      "train loss:0.0013452657266502463\n",
      "train loss:0.001967058103198033\n",
      "train loss:0.011655778844024885\n",
      "train loss:0.0009988860716399922\n",
      "train loss:0.0007144378737011728\n",
      "train loss:0.0022212595192491248\n",
      "train loss:0.0044273504435227195\n",
      "train loss:0.019630259436647195\n",
      "train loss:0.0014487467323298592\n",
      "train loss:0.0018351064159160737\n",
      "train loss:0.0006834940468512951\n",
      "train loss:0.004184857290283916\n",
      "train loss:0.005243036072848988\n",
      "train loss:0.0015021738715032989\n",
      "train loss:0.00027854227140250865\n",
      "train loss:0.0020870120572351707\n",
      "train loss:0.004260075907706394\n",
      "train loss:0.0005250076870269479\n",
      "train loss:0.004087832997524677\n",
      "train loss:0.005740864619068199\n",
      "train loss:0.0009886659716484912\n",
      "train loss:0.001033825641735933\n",
      "train loss:0.0022850930086746207\n",
      "train loss:0.00018748604200535476\n",
      "train loss:0.0002928664160766562\n",
      "train loss:0.0002855706009366767\n",
      "train loss:0.002607930666531115\n",
      "train loss:0.001499604410568809\n",
      "train loss:0.0016193410000317828\n",
      "train loss:0.0023633066437969323\n",
      "train loss:0.0005932816956408249\n",
      "train loss:0.001560031933136767\n",
      "train loss:0.0022362176590033553\n",
      "train loss:0.003332204777721381\n",
      "train loss:0.010770455830548033\n",
      "train loss:0.0020997983936505518\n",
      "train loss:0.0023692409115242527\n",
      "train loss:0.01187132118053279\n",
      "train loss:0.0038646388555617695\n",
      "train loss:0.005021398455512885\n",
      "train loss:0.002889401394238195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002133080128684907\n",
      "train loss:0.0047904720526910005\n",
      "train loss:0.0009233831674819171\n",
      "train loss:3.226443244493875e-05\n",
      "train loss:0.014791214057728892\n",
      "train loss:0.0013312230272325154\n",
      "train loss:0.016017641821927407\n",
      "train loss:0.00560091148861456\n",
      "train loss:0.005002829853690627\n",
      "train loss:0.0021893626684323297\n",
      "train loss:0.0003598503442514379\n",
      "train loss:0.00012214128602810477\n",
      "train loss:0.0010187792287781263\n",
      "train loss:0.017343370641114568\n",
      "train loss:0.00014090235198181225\n",
      "train loss:0.000641047062909525\n",
      "train loss:0.0012612807338571123\n",
      "train loss:0.0013177307485732579\n",
      "train loss:0.003092927041941382\n",
      "train loss:0.0033202315109075566\n",
      "train loss:0.00040785564490324804\n",
      "train loss:0.0008840265588207944\n",
      "train loss:0.005603262884305437\n",
      "train loss:0.0045392090467364496\n",
      "train loss:0.0013298766505835766\n",
      "train loss:0.00034161515645903857\n",
      "train loss:0.0004837646456380389\n",
      "train loss:0.002791601169678295\n",
      "train loss:0.008128459440289077\n",
      "train loss:0.0005715560146040444\n",
      "train loss:0.0038067346626980596\n",
      "train loss:0.0019924918439780137\n",
      "train loss:0.006296357364340256\n",
      "train loss:0.00464333173251196\n",
      "train loss:0.0017959224869294715\n",
      "train loss:0.001620673819573924\n",
      "train loss:0.0039814190958005835\n",
      "train loss:0.008044084671217635\n",
      "train loss:0.001275670270657284\n",
      "train loss:0.0009307109736185997\n",
      "train loss:0.0023093204840925956\n",
      "train loss:0.005120837824544062\n",
      "train loss:0.002839560837228502\n",
      "train loss:0.0075520909042017\n",
      "train loss:0.002915102497098551\n",
      "train loss:0.002600395513283863\n",
      "train loss:0.0025204270110892007\n",
      "train loss:0.006024046351111705\n",
      "train loss:0.005032963323441264\n",
      "train loss:0.0007277211296656797\n",
      "train loss:0.004484603464583601\n",
      "train loss:0.005887113260854926\n",
      "train loss:0.0021894574018750195\n",
      "train loss:0.009554495986413175\n",
      "train loss:0.005015718785067647\n",
      "train loss:0.02233680955127239\n",
      "train loss:0.0021641976302417152\n",
      "train loss:0.010680843131130628\n",
      "train loss:0.001797683303243614\n",
      "train loss:0.002614253391922309\n",
      "train loss:0.003328314589358586\n",
      "train loss:0.0018721801534142394\n",
      "train loss:0.0026935086036114306\n",
      "train loss:0.00016457694643650918\n",
      "train loss:0.0009987217357079708\n",
      "train loss:0.001961057989701611\n",
      "train loss:0.0059581954653480165\n",
      "train loss:0.0021226855361931103\n",
      "train loss:0.006825364904044985\n",
      "train loss:0.0009824204452496303\n",
      "train loss:0.0014134377609622312\n",
      "train loss:0.0023257080628659665\n",
      "train loss:0.000832239928761398\n",
      "train loss:0.002562527101623181\n",
      "train loss:0.00027081750112332363\n",
      "train loss:0.003787828253218747\n",
      "train loss:0.005010061341912991\n",
      "train loss:0.0022444055362425487\n",
      "train loss:0.000874978667109318\n",
      "train loss:0.0018378404012970914\n",
      "train loss:0.00485319937711901\n",
      "train loss:0.0015620931107243482\n",
      "train loss:0.0019856882321575204\n",
      "train loss:0.029438258228705095\n",
      "train loss:0.0007407842685138581\n",
      "train loss:0.003181799932606115\n",
      "train loss:0.0018894020362954045\n",
      "train loss:0.0019026443796214393\n",
      "train loss:0.0018486862748676633\n",
      "train loss:0.0026221658588208674\n",
      "train loss:0.001255011226028127\n",
      "train loss:0.0008467271375787905\n",
      "train loss:0.0003920050640534516\n",
      "train loss:0.002254849095807071\n",
      "train loss:0.0029618383102015923\n",
      "train loss:0.01167989099585207\n",
      "train loss:0.0004854022416588212\n",
      "train loss:0.00036305785992015653\n",
      "train loss:0.004019986210981733\n",
      "train loss:0.0022347790036922545\n",
      "train loss:0.0046037645851753906\n",
      "train loss:0.0007582102034999487\n",
      "train loss:0.003274141855752656\n",
      "train loss:0.0001377714679445895\n",
      "train loss:0.0006744321046248061\n",
      "train loss:0.002217728344376623\n",
      "train loss:0.00016651466852236126\n",
      "train loss:0.0008846045580365149\n",
      "train loss:0.0004429612137131743\n",
      "train loss:0.00023968904343265584\n",
      "train loss:0.005699339229311836\n",
      "train loss:0.0003885715213897756\n",
      "train loss:0.030105725058505523\n",
      "train loss:0.005379471814136712\n",
      "train loss:0.0018965907024337712\n",
      "train loss:0.0008431815551757931\n",
      "train loss:0.0006074679808647763\n",
      "train loss:0.003184967335615661\n",
      "train loss:0.01840005123648308\n",
      "train loss:0.00847668197114438\n",
      "train loss:0.007277777074124553\n",
      "train loss:0.006501643245008241\n",
      "train loss:0.00024749279853794446\n",
      "train loss:0.0024233543859348834\n",
      "train loss:0.0004011629169783511\n",
      "train loss:0.001671101420003333\n",
      "train loss:0.0033315221320533387\n",
      "train loss:0.006684327418155786\n",
      "train loss:0.002944729756276291\n",
      "train loss:0.003856858000637346\n",
      "train loss:0.0037088411702897676\n",
      "train loss:0.0011449725839247824\n",
      "train loss:0.005450165803782594\n",
      "train loss:0.004559230702597952\n",
      "train loss:0.0011450020636165192\n",
      "train loss:0.004724336785653009\n",
      "train loss:0.005448190555283578\n",
      "train loss:0.00029850770102164725\n",
      "train loss:0.0009914141348892006\n",
      "train loss:0.00309285790005032\n",
      "train loss:0.002225911052616431\n",
      "train loss:0.006193398008781912\n",
      "train loss:0.0005551972742418203\n",
      "train loss:0.0008650452408562664\n",
      "train loss:0.0024321519469933587\n",
      "train loss:0.0015923483889899248\n",
      "train loss:0.0012926609126864867\n",
      "train loss:0.0005713597051557465\n",
      "train loss:0.0022395317653236173\n",
      "train loss:0.0017107738294812084\n",
      "train loss:0.0056077561678873665\n",
      "train loss:0.0023587265917990015\n",
      "train loss:0.0011301487733320075\n",
      "train loss:0.004061789703293982\n",
      "train loss:0.0009435469982481158\n",
      "train loss:0.00927135394405382\n",
      "train loss:4.241780027480861e-05\n",
      "train loss:0.0014041531023429997\n",
      "train loss:0.0021926784711128024\n",
      "train loss:0.0006969057389860474\n",
      "train loss:9.638267958729785e-05\n",
      "train loss:0.011617699694031118\n",
      "train loss:0.00034638601849409277\n",
      "train loss:0.0006371020954162596\n",
      "train loss:0.004884867377691537\n",
      "train loss:0.0008519028908422522\n",
      "train loss:0.0008624599463762918\n",
      "train loss:0.0026935385428269354\n",
      "train loss:0.00035779031419161904\n",
      "train loss:0.0003416596765286779\n",
      "train loss:0.0038225856628669856\n",
      "train loss:0.0016226415088941412\n",
      "train loss:0.0006346662587996891\n",
      "train loss:0.00862323692214487\n",
      "train loss:0.0008065140719927443\n",
      "train loss:0.0025239890688436447\n",
      "train loss:0.0023489623012673613\n",
      "train loss:0.0005731306864425729\n",
      "train loss:0.005044788388668349\n",
      "train loss:0.002537486333370755\n",
      "train loss:0.000959430011765844\n",
      "train loss:0.003013154585632759\n",
      "train loss:0.00036700005365079467\n",
      "train loss:0.0005756319623497179\n",
      "train loss:0.0016017199589342113\n",
      "train loss:0.006238489982151286\n",
      "train loss:0.0013422984693913838\n",
      "train loss:0.0007740835963201784\n",
      "train loss:0.0007113376866048969\n",
      "train loss:0.0005211385085825345\n",
      "train loss:0.00013630054653398789\n",
      "train loss:0.001298174951193939\n",
      "train loss:0.0011125083838626935\n",
      "train loss:0.0023948383054749087\n",
      "train loss:0.0011611256795479414\n",
      "train loss:0.007584892240173816\n",
      "train loss:0.001039582691100292\n",
      "train loss:0.003584352565096813\n",
      "train loss:0.00449196476093068\n",
      "train loss:0.004875738995014166\n",
      "train loss:0.0031177300364626415\n",
      "train loss:0.0004852704468604906\n",
      "train loss:0.0012313304348606166\n",
      "train loss:0.0041500695777269\n",
      "train loss:0.0026209665611375997\n",
      "train loss:0.0026168832214907554\n",
      "train loss:0.001943914871716235\n",
      "train loss:0.0021941138524889654\n",
      "train loss:0.009906843562535596\n",
      "train loss:0.0033895509552858733\n",
      "train loss:0.0015531224056014737\n",
      "train loss:0.001953341996886973\n",
      "train loss:0.009078189977697094\n",
      "train loss:0.0005037105879836781\n",
      "train loss:0.0025087202065551474\n",
      "train loss:0.006678238960612804\n",
      "train loss:0.0024755223061804837\n",
      "train loss:0.0013753105043284237\n",
      "train loss:0.0006802388883672584\n",
      "train loss:0.0012684588429482096\n",
      "train loss:0.0008549998942140937\n",
      "train loss:0.0008987308295311165\n",
      "train loss:0.004902747934288552\n",
      "train loss:0.0006418337794389217\n",
      "train loss:0.0004014032292441786\n",
      "train loss:0.0010359547946965798\n",
      "train loss:0.00045055027167693407\n",
      "train loss:0.017696387184093398\n",
      "train loss:0.0015264824567977353\n",
      "train loss:0.002849606831360094\n",
      "train loss:0.0016138551309017731\n",
      "train loss:0.00946846835894057\n",
      "train loss:0.0014346024965634823\n",
      "train loss:0.0011945596625864792\n",
      "train loss:0.0005483264637202997\n",
      "train loss:0.10695855076278869\n",
      "train loss:0.0027414755009372636\n",
      "train loss:0.0015448812677022917\n",
      "train loss:0.017699880699995722\n",
      "train loss:0.0012838508975966212\n",
      "train loss:0.0011526215689322621\n",
      "train loss:0.0007892591537772602\n",
      "train loss:0.002275410662484054\n",
      "train loss:0.004020862004834558\n",
      "train loss:0.000269396623998371\n",
      "train loss:0.00063697017692431\n",
      "train loss:0.0002726711287504556\n",
      "train loss:0.0007177008624625838\n",
      "train loss:0.0074523328422374056\n",
      "train loss:0.0014316772912467684\n",
      "train loss:0.010029221175867443\n",
      "train loss:0.0007568630804747398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.006467470509421762\n",
      "train loss:0.0023775496438315515\n",
      "train loss:0.002197009266852768\n",
      "train loss:0.0007903104848534903\n",
      "train loss:0.0035641506372076207\n",
      "train loss:0.0012921283716291702\n",
      "train loss:0.004860065591548276\n",
      "train loss:0.003642978143919043\n",
      "train loss:0.0055446458882645365\n",
      "train loss:0.00046864883011278217\n",
      "train loss:0.0007799651257243471\n",
      "train loss:0.0007481050869991325\n",
      "train loss:0.0006560597091712838\n",
      "train loss:0.0023390728609364586\n",
      "train loss:0.00878011969053417\n",
      "train loss:0.00017235104479533753\n",
      "train loss:0.007879350467514413\n",
      "train loss:0.0006640314772306365\n",
      "train loss:0.0008326396970457732\n",
      "train loss:0.0029953066967150256\n",
      "train loss:0.003603990329217754\n",
      "train loss:0.002109941850153711\n",
      "train loss:0.0037179250729372686\n",
      "train loss:0.034746288882998744\n",
      "train loss:0.0035995164860075164\n",
      "train loss:0.0010866425027543536\n",
      "train loss:0.022927926516460476\n",
      "train loss:0.003362345852328205\n",
      "train loss:0.0007967236960872897\n",
      "train loss:0.005325371480967068\n",
      "train loss:0.003092032433718159\n",
      "train loss:0.00021920048338734742\n",
      "train loss:0.0014630915427295862\n",
      "train loss:0.008129505486269516\n",
      "train loss:0.001898168667088018\n",
      "train loss:0.013615738963647284\n",
      "train loss:0.0020920351691391115\n",
      "train loss:0.00027951970704672595\n",
      "train loss:0.0064442276852164715\n",
      "train loss:0.005219584809455604\n",
      "train loss:0.0002077686782797672\n",
      "train loss:0.0004926000196919864\n",
      "train loss:0.001604618914550808\n",
      "train loss:0.0026932366863464344\n",
      "train loss:0.0027950194694415643\n",
      "train loss:0.003043636902904347\n",
      "train loss:0.0008558434577546981\n",
      "train loss:0.0050851315990365865\n",
      "train loss:0.0045939511282453716\n",
      "train loss:0.007094652998009712\n",
      "train loss:0.0008242366950360955\n",
      "train loss:0.0006257006448757061\n",
      "train loss:0.0029941122413365785\n",
      "train loss:0.0010737729286437116\n",
      "train loss:0.004710937976930338\n",
      "train loss:0.009860665528381704\n",
      "train loss:0.0016195991927563835\n",
      "train loss:0.004332856160132837\n",
      "train loss:0.0021847922614623705\n",
      "train loss:0.0004147148579502828\n",
      "train loss:0.00089158211947548\n",
      "train loss:0.003389130063028114\n",
      "train loss:0.0002704135782351642\n",
      "train loss:0.00037843195588295296\n",
      "train loss:0.0023930575864824066\n",
      "train loss:0.00046102541848558993\n",
      "train loss:0.0007822953219607006\n",
      "train loss:0.0006247446925825731\n",
      "train loss:0.0036401419462263967\n",
      "train loss:0.003986432659359313\n",
      "train loss:0.010585723987892363\n",
      "train loss:0.0010776216432259087\n",
      "train loss:0.0017892012818829356\n",
      "train loss:0.010455464742300628\n",
      "train loss:0.0003842243598105246\n",
      "train loss:0.002499290188986256\n",
      "train loss:0.00019966860076954364\n",
      "train loss:0.0009019371699438944\n",
      "train loss:0.0006464386638072357\n",
      "train loss:0.001480083945390123\n",
      "train loss:0.009869317192608923\n",
      "train loss:0.004884513944791897\n",
      "train loss:0.0017804384764234641\n",
      "train loss:0.005960143382038449\n",
      "train loss:0.00021186409384972866\n",
      "train loss:0.0040164152271194445\n",
      "train loss:0.013067784452429234\n",
      "train loss:7.794751008885003e-05\n",
      "train loss:0.0004790990814425311\n",
      "train loss:0.004888210371582203\n",
      "train loss:0.0051351390932878336\n",
      "train loss:0.0002340652677011158\n",
      "train loss:0.001061533694207934\n",
      "train loss:0.0010045069440625246\n",
      "train loss:0.014885645308699165\n",
      "train loss:9.333035482925359e-05\n",
      "train loss:0.0008156963014805623\n",
      "train loss:0.005113170766950447\n",
      "train loss:0.06848273571210106\n",
      "train loss:0.00110172635877715\n",
      "train loss:0.0035046149135078597\n",
      "train loss:0.006324022198119549\n",
      "train loss:0.003580364119296668\n",
      "train loss:0.009835163139738808\n",
      "train loss:0.013143843306275447\n",
      "train loss:0.018587217386327605\n",
      "train loss:0.0016094304535008463\n",
      "train loss:0.0013596595433096345\n",
      "train loss:0.002811412188443381\n",
      "train loss:0.0010147078354795333\n",
      "train loss:0.0003040023305417441\n",
      "train loss:0.0015820780866055684\n",
      "train loss:7.2921689265732e-05\n",
      "train loss:0.006088882116801439\n",
      "train loss:0.0014476542231436076\n",
      "train loss:0.0015573538392526724\n",
      "train loss:0.0032361681896598228\n",
      "train loss:0.0016439401875691967\n",
      "train loss:0.0027457102569398368\n",
      "train loss:0.0005775277566081725\n",
      "train loss:0.004056889839615726\n",
      "train loss:0.001396856602896934\n",
      "train loss:0.004208265048646718\n",
      "train loss:0.007026752722290447\n",
      "train loss:0.0010846453045644114\n",
      "train loss:0.004343240570811148\n",
      "train loss:9.430748425060343e-05\n",
      "train loss:0.0016050023400145273\n",
      "train loss:0.0037575406948608912\n",
      "train loss:7.833239355579235e-05\n",
      "train loss:5.8773358819725514e-05\n",
      "train loss:0.030161953672291453\n",
      "train loss:0.0005569017493133855\n",
      "train loss:0.00024791664727310045\n",
      "train loss:0.0017324740822317998\n",
      "train loss:0.001993761739785187\n",
      "train loss:0.006065207638453734\n",
      "train loss:0.0018670579876059674\n",
      "train loss:0.0006203208760187416\n",
      "train loss:0.0009661917194169288\n",
      "train loss:0.0012039417139722243\n",
      "train loss:0.002180948931663885\n",
      "train loss:0.000439519015668157\n",
      "train loss:0.004550941658028229\n",
      "train loss:0.014039915305999991\n",
      "train loss:0.0030835044547730434\n",
      "train loss:0.0017923929850249154\n",
      "train loss:0.0001542656089326881\n",
      "train loss:0.00048165664103911357\n",
      "train loss:0.00015154763689550506\n",
      "train loss:0.0006500143806085833\n",
      "train loss:0.007843884209435843\n",
      "train loss:0.004313354778914709\n",
      "train loss:0.0003272718067787745\n",
      "train loss:0.0017170208738876537\n",
      "train loss:0.004708475620353501\n",
      "train loss:0.0020967217355648228\n",
      "train loss:0.00038365883284353637\n",
      "train loss:0.002135824409033889\n",
      "train loss:0.001474515670750326\n",
      "train loss:0.0017915821012167168\n",
      "train loss:0.04779987849109396\n",
      "train loss:0.0023064771203474073\n",
      "train loss:0.000900385615332846\n",
      "train loss:0.002253719662191415\n",
      "train loss:0.001085353946671748\n",
      "train loss:0.0027104708700983484\n",
      "train loss:0.0026411121993824916\n",
      "train loss:0.003302403906948276\n",
      "train loss:0.0021361420303867267\n",
      "train loss:0.0005609388125256713\n",
      "train loss:0.0025753835205248304\n",
      "train loss:0.0010960484287044405\n",
      "train loss:0.0035602986671642058\n",
      "train loss:0.002268192469790693\n",
      "train loss:0.004054165961319125\n",
      "train loss:0.0023270935523975484\n",
      "train loss:0.0031473727861617657\n",
      "train loss:0.0006635829337770015\n",
      "train loss:0.0007931090968617484\n",
      "train loss:0.0006778913250169696\n",
      "train loss:0.0036913023749648765\n",
      "train loss:0.0001576486587069614\n",
      "train loss:0.001110186385211753\n",
      "train loss:0.0008264427742246748\n",
      "train loss:0.0012086315690164207\n",
      "train loss:0.0004005906058881651\n",
      "train loss:0.0026555165472835324\n",
      "train loss:0.006084428015576639\n",
      "train loss:0.0030286271824753186\n",
      "train loss:0.00046635916462752717\n",
      "train loss:0.0017444864082074032\n",
      "train loss:7.322077356197227e-05\n",
      "train loss:0.004057125236752693\n",
      "train loss:0.0030657114515741718\n",
      "train loss:0.0020913989123321573\n",
      "train loss:0.0019104879510334746\n",
      "train loss:0.002168491895811457\n",
      "train loss:0.001197728272910062\n",
      "train loss:0.01502156392858981\n",
      "train loss:0.00034414457315874627\n",
      "train loss:0.0030897638847935255\n",
      "train loss:0.00020353856608421215\n",
      "train loss:0.0018662527036017265\n",
      "train loss:0.0006233142795019662\n",
      "train loss:0.0015635670682614393\n",
      "train loss:0.0033764680624986543\n",
      "train loss:0.0013133304578617836\n",
      "train loss:0.0022363675573144255\n",
      "train loss:0.003913022503942395\n",
      "train loss:0.005427184738579337\n",
      "train loss:0.0009290127778451407\n",
      "train loss:0.0030813531928920988\n",
      "train loss:0.00020621793297028013\n",
      "train loss:0.0034121011595376945\n",
      "train loss:0.0012339152919795102\n",
      "train loss:0.0013677867038245364\n",
      "train loss:0.001678659928106307\n",
      "train loss:0.0008067973761539512\n",
      "train loss:0.002566002934768012\n",
      "train loss:0.0015246676863083471\n",
      "train loss:0.004865456094311215\n",
      "train loss:0.00041325334007583894\n",
      "train loss:0.019089548328969155\n",
      "train loss:0.0032132135443015113\n",
      "train loss:0.0044381780292937715\n",
      "train loss:0.00856735141825756\n",
      "train loss:0.00845783732286\n",
      "train loss:0.0005578658004499945\n",
      "train loss:0.008814229573656795\n",
      "train loss:0.0040241981817141954\n",
      "train loss:0.00046173285524267623\n",
      "train loss:0.004673013296954709\n",
      "train loss:0.04297939126752496\n",
      "train loss:0.001712378396718606\n",
      "train loss:0.000916088953723298\n",
      "train loss:0.03127704633078284\n",
      "train loss:0.016775891373343316\n",
      "train loss:0.004132445385138427\n",
      "train loss:0.0010761990449758908\n",
      "train loss:0.01698054229825913\n",
      "train loss:0.007728235534702517\n",
      "train loss:0.003271383391819933\n",
      "train loss:0.0017146657348654653\n",
      "train loss:0.002155075024259178\n",
      "train loss:0.0008460948700190366\n",
      "train loss:0.0012154102628952918\n",
      "train loss:0.0010879794906521023\n",
      "=== epoch:16, train acc:0.999, test acc:0.986 ===\n",
      "train loss:0.0008497523818710969\n",
      "train loss:0.0014561442917859966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00462501423158144\n",
      "train loss:0.0006921383640295861\n",
      "train loss:0.002796408307018238\n",
      "train loss:0.0027035401586281787\n",
      "train loss:0.0005133705329501064\n",
      "train loss:0.005823567252389052\n",
      "train loss:0.004345814995520548\n",
      "train loss:0.00219383720494065\n",
      "train loss:0.000693776518991935\n",
      "train loss:8.881053348108147e-05\n",
      "train loss:0.0006263310449554024\n",
      "train loss:0.002951250920234366\n",
      "train loss:0.00042877799106059473\n",
      "train loss:0.0014325240307649814\n",
      "train loss:0.0008358959532765552\n",
      "train loss:0.0012973017425055\n",
      "train loss:0.00016079987864381286\n",
      "train loss:0.00016861789951423757\n",
      "train loss:0.0020007200817478564\n",
      "train loss:0.003996088277705647\n",
      "train loss:0.010518918066906508\n",
      "train loss:0.0029146366161140053\n",
      "train loss:0.0023242227362613678\n",
      "train loss:0.0010843144501066595\n",
      "train loss:0.009801766514636923\n",
      "train loss:0.003911540734972601\n",
      "train loss:0.00048495853840165677\n",
      "train loss:0.00345647541304654\n",
      "train loss:0.0008513440279491183\n",
      "train loss:0.00028456391341083687\n",
      "train loss:0.0032364877967631985\n",
      "train loss:0.0019705755284744465\n",
      "train loss:0.0040812526619696055\n",
      "train loss:0.0034265755746612035\n",
      "train loss:0.0033285373882975984\n",
      "train loss:0.0011791440307182299\n",
      "train loss:0.004634738300267664\n",
      "train loss:0.0005888436045386368\n",
      "train loss:0.004760424601891695\n",
      "train loss:0.008536365635163808\n",
      "train loss:0.008865241638252341\n",
      "train loss:0.0014670250371248733\n",
      "train loss:0.0016912352633332405\n",
      "train loss:0.001582685585346577\n",
      "train loss:0.005793839424892591\n",
      "train loss:0.00015409508072963883\n",
      "train loss:0.005471541865442872\n",
      "train loss:0.002628805706563887\n",
      "train loss:0.00991322623982151\n",
      "train loss:0.002463496567651206\n",
      "train loss:0.0008057641370972624\n",
      "train loss:0.001762339634325991\n",
      "train loss:0.00042291799132179763\n",
      "train loss:0.00012938393759963143\n",
      "train loss:0.0002307505436064261\n",
      "train loss:0.003827424413139665\n",
      "train loss:0.0004489183447140537\n",
      "train loss:0.0019499916708797251\n",
      "train loss:0.0003309755546981639\n",
      "train loss:0.00369030274389386\n",
      "train loss:0.005370502548660444\n",
      "train loss:0.001454271821954541\n",
      "train loss:6.331479626894463e-05\n",
      "train loss:0.0012647746264007637\n",
      "train loss:0.0029427428661550903\n",
      "train loss:0.0009520717465620823\n",
      "train loss:8.979791294401544e-05\n",
      "train loss:0.013599601055805082\n",
      "train loss:0.003308048817911998\n",
      "train loss:0.0011229198239198661\n",
      "train loss:0.0008263964860740622\n",
      "train loss:0.0007173089590216862\n",
      "train loss:0.0015528704131480375\n",
      "train loss:0.0019835097667404516\n",
      "train loss:0.0031487259317118633\n",
      "train loss:0.0015794793764636553\n",
      "train loss:0.0007749063438110647\n",
      "train loss:0.0012042238383212583\n",
      "train loss:0.0017411262387464254\n",
      "train loss:0.004558216535972382\n",
      "train loss:0.0008207487158967214\n",
      "train loss:0.001451310973886255\n",
      "train loss:0.0006253594844062968\n",
      "train loss:0.0024187830711714735\n",
      "train loss:0.0016735807385526663\n",
      "train loss:0.003623686256434749\n",
      "train loss:0.0021564526564974507\n",
      "train loss:0.0013713738890204377\n",
      "train loss:0.001337748180303644\n",
      "train loss:0.003641742602189121\n",
      "train loss:0.0011033019820560052\n",
      "train loss:0.00044622814497627416\n",
      "train loss:0.002251408723757293\n",
      "train loss:0.0004165516754067912\n",
      "train loss:0.0008461477772925681\n",
      "train loss:0.002282605866665014\n",
      "train loss:0.0028278912841629856\n",
      "train loss:0.0009479816565091437\n",
      "train loss:0.008170426424520084\n",
      "train loss:0.00041447965294140834\n",
      "train loss:3.218590817258461e-05\n",
      "train loss:0.0008214481679131641\n",
      "train loss:0.0006093129341834938\n",
      "train loss:0.0003644688853378338\n",
      "train loss:0.0015545634144554631\n",
      "train loss:0.0010464329901006945\n",
      "train loss:0.0002897147240884643\n",
      "train loss:0.00037027186578071934\n",
      "train loss:0.0022350713158281917\n",
      "train loss:0.0002777062878942483\n",
      "train loss:0.0022960159933793287\n",
      "train loss:0.00017200513573897657\n",
      "train loss:0.0020648783966737525\n",
      "train loss:0.0016604932379897348\n",
      "train loss:0.006577815104903276\n",
      "train loss:8.126853296779866e-05\n",
      "train loss:0.002768460161568036\n",
      "train loss:0.006324782096951953\n",
      "train loss:0.0008403229019194512\n",
      "train loss:0.001017573590546256\n",
      "train loss:0.0009731616994019151\n",
      "train loss:0.0011955346707313939\n",
      "train loss:0.0020011055770022294\n",
      "train loss:0.0015317360454400566\n",
      "train loss:0.0021769786060483612\n",
      "train loss:0.003453941086247152\n",
      "train loss:0.0015555978677856042\n",
      "train loss:0.0009155516282907651\n",
      "train loss:0.0007532553583378563\n",
      "train loss:0.004697254337397298\n",
      "train loss:0.0021114947004842862\n",
      "train loss:0.002475560944301582\n",
      "train loss:0.0008063983705881097\n",
      "train loss:0.00036782069237628986\n",
      "train loss:0.00021810149535234072\n",
      "train loss:0.0016653171542920558\n",
      "train loss:0.00023655357805189145\n",
      "train loss:0.00014909043121483435\n",
      "train loss:0.0009323713303689226\n",
      "train loss:0.0012055865090005481\n",
      "train loss:0.00010143512053973326\n",
      "train loss:0.003141926233256608\n",
      "train loss:0.00011742186699946873\n",
      "train loss:0.02647319762813029\n",
      "train loss:0.0001112961058650452\n",
      "train loss:0.00023476412765717613\n",
      "train loss:0.007335368074905748\n",
      "train loss:0.0002324350547644281\n",
      "train loss:0.0037261215920845548\n",
      "train loss:0.002134492009811818\n",
      "train loss:0.0007753888157952478\n",
      "train loss:0.00045959739033158553\n",
      "train loss:0.004090179682285005\n",
      "train loss:0.00013625273062240433\n",
      "train loss:0.0031814820961087813\n",
      "train loss:0.0034524039278546696\n",
      "train loss:0.0020861135020332025\n",
      "train loss:0.015683328042837386\n",
      "train loss:3.906796045550709e-05\n",
      "train loss:0.00014786801173534628\n",
      "train loss:0.0003621925210166577\n",
      "train loss:0.005442085125552814\n",
      "train loss:0.0007474552899458736\n",
      "train loss:0.0002037964792806342\n",
      "train loss:0.001379189611597435\n",
      "train loss:0.002996521660434667\n",
      "train loss:0.008453299354536687\n",
      "train loss:0.0015219469704652916\n",
      "train loss:0.0008929948891316495\n",
      "train loss:0.003582636548820911\n",
      "train loss:0.0015902214393178496\n",
      "train loss:0.005818564958600786\n",
      "train loss:0.0013252017031282935\n",
      "train loss:0.002886573930919528\n",
      "train loss:0.0018778778319001124\n",
      "train loss:0.0003060090304500367\n",
      "train loss:0.00017120792240898192\n",
      "train loss:0.0005840925686323903\n",
      "train loss:0.0005152529266047635\n",
      "train loss:0.0007471266359176331\n",
      "train loss:0.0014933665756790447\n",
      "train loss:0.0006961297221181892\n",
      "train loss:0.0010396779781175192\n",
      "train loss:0.00043098924663756313\n",
      "train loss:0.0028466332825918604\n",
      "train loss:0.001915625020286341\n",
      "train loss:0.0018286092293507308\n",
      "train loss:0.0026382342767443806\n",
      "train loss:7.793384567056164e-05\n",
      "train loss:0.0009486966965504709\n",
      "train loss:0.0006289422352524918\n",
      "train loss:0.0013361832374895449\n",
      "train loss:0.001366699905782487\n",
      "train loss:0.00039962211316288014\n",
      "train loss:0.00013854007637473828\n",
      "train loss:0.0010454167250230845\n",
      "train loss:0.0009716515182698562\n",
      "train loss:0.0003197068302714923\n",
      "train loss:0.0012572199279621953\n",
      "train loss:0.0018932373237054564\n",
      "train loss:0.0028171546771948376\n",
      "train loss:0.0013852418491623426\n",
      "train loss:0.0022150709389741445\n",
      "train loss:0.0014883650780054295\n",
      "train loss:0.0008817967091823818\n",
      "train loss:0.0020725818106865886\n",
      "train loss:3.2032346522569314e-05\n",
      "train loss:0.009001146448515745\n",
      "train loss:0.0022767697641193287\n",
      "train loss:0.007055605283796248\n",
      "train loss:0.002466554233953978\n",
      "train loss:9.090002791731223e-05\n",
      "train loss:0.0005442630227760251\n",
      "train loss:0.00020385740420757463\n",
      "train loss:0.0017745529545133898\n",
      "train loss:0.0010360329873453688\n",
      "train loss:0.0017292971809823297\n",
      "train loss:0.000975279799436986\n",
      "train loss:0.0033482534526981063\n",
      "train loss:0.0007905511010394694\n",
      "train loss:0.0006531813609116193\n",
      "train loss:0.0029702155896566985\n",
      "train loss:0.007654385723913897\n",
      "train loss:0.00041902851441336553\n",
      "train loss:0.00207062434239926\n",
      "train loss:0.0031070256089465328\n",
      "train loss:0.0033642514753208543\n",
      "train loss:0.0006951273788010485\n",
      "train loss:0.00017022199142285331\n",
      "train loss:0.0005279513481943651\n",
      "train loss:0.0013783696692064112\n",
      "train loss:0.0017119210013235757\n",
      "train loss:0.00013461842086334274\n",
      "train loss:0.0001479905810888712\n",
      "train loss:0.0016319423647594763\n",
      "train loss:0.000637647423280038\n",
      "train loss:0.018653111117488862\n",
      "train loss:0.0007879961698648863\n",
      "train loss:0.0011380927010011704\n",
      "train loss:0.0006149201512142942\n",
      "train loss:0.0005651055611388804\n",
      "train loss:0.0026148830921555654\n",
      "train loss:0.0021759566224236835\n",
      "train loss:0.0019475901610053646\n",
      "train loss:0.0032781103347127504\n",
      "train loss:0.001442886120362138\n",
      "train loss:0.0001755005947477842\n",
      "train loss:0.002278408263914162\n",
      "train loss:0.00018286190168722446\n",
      "train loss:0.00027167609640568703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:9.88149602354058e-05\n",
      "train loss:0.0004530852913435912\n",
      "train loss:0.0017662407351134587\n",
      "train loss:0.00044572613163190223\n",
      "train loss:9.477130355124869e-05\n",
      "train loss:0.000837186528241042\n",
      "train loss:0.0026850789474485355\n",
      "train loss:0.0008526335655175624\n",
      "train loss:0.0022449204692167398\n",
      "train loss:0.0007244740052417671\n",
      "train loss:0.0030940232118811806\n",
      "train loss:0.0037530764141138857\n",
      "train loss:0.0011935549161762595\n",
      "train loss:0.013266074741275821\n",
      "train loss:0.018551229420130336\n",
      "train loss:0.0015133997883785121\n",
      "train loss:0.000509595942016453\n",
      "train loss:0.0031739978963426976\n",
      "train loss:0.0019293972386539562\n",
      "train loss:0.0001669647808960742\n",
      "train loss:0.003516061300134597\n",
      "train loss:0.018821697250324974\n",
      "train loss:0.00040201862101202373\n",
      "train loss:0.001403149378553301\n",
      "train loss:0.0029104102441194772\n",
      "train loss:0.0009746056813358864\n",
      "train loss:0.00419994593217634\n",
      "train loss:0.008127512633793112\n",
      "train loss:0.0003744952099219901\n",
      "train loss:0.001054060565497063\n",
      "train loss:0.05611741924072261\n",
      "train loss:0.0012427293728991553\n",
      "train loss:0.001254209225855087\n",
      "train loss:0.0021369823106761735\n",
      "train loss:0.0010880411478594951\n",
      "train loss:0.0036251966839188736\n",
      "train loss:0.00015314439257494374\n",
      "train loss:0.001575735302624252\n",
      "train loss:0.0003157517345963481\n",
      "train loss:0.00013943751028906669\n",
      "train loss:0.006269820077086522\n",
      "train loss:0.01043849719355674\n",
      "train loss:0.0004788286311690319\n",
      "train loss:0.00015427398947098477\n",
      "train loss:0.004760331576403335\n",
      "train loss:0.007417365020366289\n",
      "train loss:0.0003005253681714519\n",
      "train loss:0.0015739064900796363\n",
      "train loss:0.0031466812611916912\n",
      "train loss:0.0010256992981831766\n",
      "train loss:0.0029692626756987234\n",
      "train loss:0.007665534932467455\n",
      "train loss:0.0009553375325750639\n",
      "train loss:0.004570223640857377\n",
      "train loss:0.0004969137294864984\n",
      "train loss:0.017670485372624396\n",
      "train loss:0.0017652837312720797\n",
      "train loss:6.663346976181149e-05\n",
      "train loss:0.0016131851785220633\n",
      "train loss:0.0003736003280101326\n",
      "train loss:0.00303056788142406\n",
      "train loss:0.0014598378777927776\n",
      "train loss:0.0009807503190988737\n",
      "train loss:0.002536095181593734\n",
      "train loss:0.001729767874208198\n",
      "train loss:8.924455843623306e-05\n",
      "train loss:0.003171105825956616\n",
      "train loss:0.0028665659426973704\n",
      "train loss:0.0006683310211241335\n",
      "train loss:0.0011395689899056215\n",
      "train loss:0.002649711323925245\n",
      "train loss:0.0026397180989912255\n",
      "train loss:0.0007110732956642903\n",
      "train loss:0.0004096087589081449\n",
      "train loss:0.00096559905958774\n",
      "train loss:0.00019143590723407308\n",
      "train loss:0.0022207645886405856\n",
      "train loss:0.0037467323240210964\n",
      "train loss:0.0048075026802773795\n",
      "train loss:0.0003214169279887883\n",
      "train loss:0.00025437895243794555\n",
      "train loss:0.0016758854247609497\n",
      "train loss:0.003233153843691472\n",
      "train loss:0.0009621197493570733\n",
      "train loss:0.0014218763553704905\n",
      "train loss:0.0025577776970798784\n",
      "train loss:0.0024259426116293114\n",
      "train loss:0.0042341603537763015\n",
      "train loss:0.00023381845816595906\n",
      "train loss:0.0026458644991854143\n",
      "train loss:0.0036878774394003217\n",
      "train loss:0.0006010962552850431\n",
      "train loss:0.005962564883415924\n",
      "train loss:9.971105123424709e-05\n",
      "train loss:0.0025750005624763234\n",
      "train loss:0.006872034844412677\n",
      "train loss:0.0011135486296857408\n",
      "train loss:0.001335488790964941\n",
      "train loss:0.0007270648429464144\n",
      "train loss:0.0001068177226775703\n",
      "train loss:0.000436818284872025\n",
      "train loss:0.023327029741069694\n",
      "train loss:0.00670417676279921\n",
      "train loss:0.0072914993243389115\n",
      "train loss:0.002543847968671454\n",
      "train loss:0.0019136261282122074\n",
      "train loss:0.001252845189514357\n",
      "train loss:0.0005324992832239313\n",
      "train loss:0.0017916292498366174\n",
      "train loss:0.0019203657800006399\n",
      "train loss:0.0008792177757610566\n",
      "train loss:0.0032126872632293395\n",
      "train loss:0.0010764077726919982\n",
      "train loss:0.003945630908112842\n",
      "train loss:0.003118541616480806\n",
      "train loss:0.0002259796375914416\n",
      "train loss:0.007629913508669739\n",
      "train loss:0.0015435673333543134\n",
      "train loss:0.0005393413837839981\n",
      "train loss:7.339354534843731e-05\n",
      "train loss:0.0024127079588215495\n",
      "train loss:8.12899977935293e-05\n",
      "train loss:0.0003227114062622611\n",
      "train loss:0.0009244328078813417\n",
      "train loss:0.00046167305401441144\n",
      "train loss:0.0012134594040744226\n",
      "train loss:0.0021068787895275032\n",
      "train loss:0.007513707914937744\n",
      "train loss:0.007377373631047026\n",
      "train loss:0.0019425541403017236\n",
      "train loss:0.005605156729847029\n",
      "train loss:0.00045303624206801833\n",
      "train loss:0.0009028199359750249\n",
      "train loss:0.00037113296988761617\n",
      "train loss:0.000714395198841422\n",
      "train loss:0.0002196550371569599\n",
      "train loss:0.0003218092384619316\n",
      "train loss:0.0005024087685952767\n",
      "train loss:0.00012427763650194786\n",
      "train loss:0.0011489569776690165\n",
      "train loss:0.00114544156113802\n",
      "train loss:0.002724995209985222\n",
      "train loss:0.00020662269275875924\n",
      "train loss:0.00015584478619250236\n",
      "train loss:0.0005041207701322287\n",
      "train loss:0.0022111504205577803\n",
      "train loss:0.0003524268655195652\n",
      "train loss:0.0018976246249402823\n",
      "train loss:0.003619455901883458\n",
      "train loss:0.005876501514076404\n",
      "train loss:0.0016771522299037984\n",
      "train loss:0.002608409066703872\n",
      "train loss:0.002304965107396038\n",
      "train loss:0.0036537223893973168\n",
      "train loss:0.003763991740068439\n",
      "train loss:0.00028553261337194895\n",
      "train loss:0.0013424627642060639\n",
      "train loss:0.0004603430039390826\n",
      "train loss:0.0027245333734529026\n",
      "train loss:0.0027218920277119747\n",
      "train loss:0.0021729408477380546\n",
      "train loss:0.0010868068367552097\n",
      "train loss:0.0002200044761505567\n",
      "train loss:0.0011327216550934432\n",
      "train loss:0.007375541775155464\n",
      "train loss:0.02209912701552561\n",
      "train loss:0.0008125356051049098\n",
      "train loss:0.00012899344175989493\n",
      "train loss:0.001632522785553318\n",
      "train loss:0.0012855425242540902\n",
      "train loss:0.0020067946181774525\n",
      "train loss:0.002000894729198244\n",
      "train loss:9.60316457525223e-05\n",
      "train loss:0.004136432582631392\n",
      "train loss:0.0011228655055427561\n",
      "train loss:0.00018259818685956384\n",
      "train loss:0.00922115957236134\n",
      "train loss:0.0012000020760342903\n",
      "train loss:0.002202498970466864\n",
      "train loss:0.00045395869091686394\n",
      "train loss:0.000414936186404798\n",
      "train loss:0.0018377776085049175\n",
      "train loss:0.001084533587662707\n",
      "train loss:0.0009236477585998765\n",
      "train loss:0.0014741950587920712\n",
      "train loss:0.0006543725764055371\n",
      "train loss:0.001407892168230166\n",
      "train loss:0.0009130302139193796\n",
      "train loss:0.0004405185594173471\n",
      "train loss:0.00014149891360015142\n",
      "train loss:0.003714872393861987\n",
      "train loss:0.00020789352534999138\n",
      "train loss:0.0027757121805359417\n",
      "train loss:6.293621089249621e-05\n",
      "train loss:0.0006609581363467276\n",
      "train loss:0.00011454439907235625\n",
      "train loss:0.0038905546091802462\n",
      "train loss:0.00020887345272834268\n",
      "train loss:0.0047696253583387645\n",
      "train loss:0.0032351447684376465\n",
      "train loss:0.0004509158742363757\n",
      "train loss:0.00011565466278391285\n",
      "train loss:0.0008539155076964299\n",
      "train loss:0.0001355419133989864\n",
      "train loss:0.0011613086827809965\n",
      "train loss:0.00040857000433829115\n",
      "train loss:0.0020629131256410613\n",
      "train loss:0.0015352379981113829\n",
      "train loss:0.0021002459302899407\n",
      "train loss:0.00040081646938482595\n",
      "train loss:0.0004133715695199995\n",
      "train loss:0.00012107074398745453\n",
      "train loss:0.0032715365245926937\n",
      "train loss:0.004369695507485718\n",
      "train loss:0.00026439961616674476\n",
      "train loss:0.0005136406830798158\n",
      "train loss:0.0006159512954600221\n",
      "train loss:0.00012332592458279574\n",
      "train loss:0.025817171353899847\n",
      "train loss:0.0038556608065871425\n",
      "train loss:0.0005987790050993734\n",
      "train loss:0.00014380866232304443\n",
      "train loss:0.0027532377414312527\n",
      "train loss:0.0074693292889400145\n",
      "train loss:0.002374421844852875\n",
      "train loss:0.011945122513138139\n",
      "train loss:0.003701152284694739\n",
      "train loss:0.0012070695693893686\n",
      "train loss:0.006779120402450444\n",
      "train loss:0.0021943267090688955\n",
      "train loss:0.0005190716838513718\n",
      "train loss:0.002166712094985262\n",
      "train loss:0.025860111580891885\n",
      "train loss:0.0010028062115841306\n",
      "train loss:0.00420064573181886\n",
      "train loss:0.0005399109977398197\n",
      "train loss:0.0034128417108843685\n",
      "train loss:0.01102894648471794\n",
      "train loss:0.0035275446188556166\n",
      "train loss:0.001173932296795004\n",
      "train loss:0.012026018735744664\n",
      "train loss:0.0003062636792904053\n",
      "train loss:0.002240789929131202\n",
      "train loss:0.00046058683079648133\n",
      "train loss:0.0006546264744596755\n",
      "train loss:0.0002980827589067212\n",
      "train loss:0.00046410161072521874\n",
      "train loss:0.0016556676355896542\n",
      "train loss:0.0014507513005345577\n",
      "train loss:0.03774405209568099\n",
      "train loss:0.0014156462833734274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.007054594510625683\n",
      "train loss:0.008575805677002672\n",
      "train loss:0.0025677265694536355\n",
      "train loss:0.0007892840499818676\n",
      "train loss:0.0009885423551628254\n",
      "train loss:0.005528788215044286\n",
      "train loss:0.0007974477916968892\n",
      "train loss:0.003255581718792917\n",
      "train loss:8.765147367261442e-05\n",
      "train loss:0.0002118176282965198\n",
      "train loss:7.35914007187873e-05\n",
      "train loss:0.004465821325752657\n",
      "train loss:0.0017618895454070008\n",
      "train loss:0.002329914823094254\n",
      "train loss:0.0031274485370837994\n",
      "train loss:0.00299647236209286\n",
      "train loss:0.0015748858004822398\n",
      "train loss:3.793724857327513e-05\n",
      "train loss:0.0020474171457393556\n",
      "train loss:0.0018063917816459817\n",
      "train loss:0.0010543648738515006\n",
      "train loss:0.0032987906483827713\n",
      "train loss:0.0013720948355096239\n",
      "train loss:0.000140934730091149\n",
      "train loss:0.0015272496601083214\n",
      "train loss:0.0032015480855745937\n",
      "train loss:0.00014629646861673176\n",
      "train loss:0.0016203775240895251\n",
      "train loss:0.0005682967981434357\n",
      "train loss:0.0015106297177490307\n",
      "train loss:0.015072451404074422\n",
      "train loss:0.004521459471339668\n",
      "train loss:0.0013311863055973949\n",
      "train loss:0.0009292290993839809\n",
      "train loss:0.0039134227578187\n",
      "train loss:0.00015571870234649867\n",
      "train loss:0.0005762602068874251\n",
      "train loss:0.0001381601540615586\n",
      "train loss:0.006493763653405501\n",
      "train loss:0.0005820374374058254\n",
      "train loss:0.004782477125377586\n",
      "train loss:0.010945846629599583\n",
      "train loss:0.0011772983977848231\n",
      "train loss:0.0017524754830245883\n",
      "train loss:0.002211146459859606\n",
      "train loss:0.0028705491175738122\n",
      "train loss:0.0010338513566819185\n",
      "train loss:0.00017535984742213102\n",
      "train loss:0.0035166862431958053\n",
      "train loss:0.0008147384977789641\n",
      "train loss:0.0017933679328401059\n",
      "train loss:0.0021330340728195254\n",
      "train loss:0.0014399376002876033\n",
      "train loss:0.00024198626558419618\n",
      "train loss:0.0031286427669605056\n",
      "train loss:4.447658221143554e-05\n",
      "train loss:0.0058384703285722485\n",
      "train loss:0.0003554330354238061\n",
      "train loss:0.004698436901769017\n",
      "train loss:0.00011228061307542645\n",
      "train loss:0.0028019014942500726\n",
      "train loss:0.00011970194438293611\n",
      "train loss:0.001411655362064512\n",
      "train loss:9.791295846283352e-05\n",
      "train loss:0.0014208436314446732\n",
      "train loss:0.0006548025079094634\n",
      "train loss:0.00059877259575767\n",
      "train loss:0.0011934524552336596\n",
      "train loss:0.0016992355061735817\n",
      "train loss:0.0032230806210169845\n",
      "train loss:0.002765250390702203\n",
      "train loss:0.0005612836925616048\n",
      "train loss:0.0014242817162770012\n",
      "train loss:0.0007697658072013205\n",
      "train loss:0.00035135084861342676\n",
      "train loss:0.00014485588057162478\n",
      "train loss:0.005247026122009297\n",
      "train loss:6.935678256384041e-05\n",
      "train loss:0.002865160307813162\n",
      "train loss:0.0011951192563121142\n",
      "train loss:0.002191382509257944\n",
      "train loss:0.0019449156226168706\n",
      "train loss:0.002074422112720786\n",
      "train loss:0.0009681751948330188\n",
      "train loss:0.002837522813545411\n",
      "train loss:0.0039020000062818137\n",
      "train loss:0.00018792233791123207\n",
      "train loss:0.0018646803197343656\n",
      "train loss:0.00032562675545749683\n",
      "train loss:0.00865975783026234\n",
      "train loss:0.0012681135775377726\n",
      "train loss:0.0012871440780541931\n",
      "train loss:0.0002690022421231501\n",
      "train loss:0.0016639708759521204\n",
      "train loss:0.0013067789604258992\n",
      "train loss:0.0012927444857462138\n",
      "train loss:0.00030406888081165945\n",
      "=== epoch:17, train acc:0.996, test acc:0.986 ===\n",
      "train loss:0.0018457310851069922\n",
      "train loss:0.005000471087198452\n",
      "train loss:0.0006270871636799912\n",
      "train loss:0.00047374806299113907\n",
      "train loss:0.003578770837612969\n",
      "train loss:0.00016647654842908568\n",
      "train loss:0.0007586935890767646\n",
      "train loss:0.00025843112758548676\n",
      "train loss:0.002770233672362068\n",
      "train loss:0.0006584024062819421\n",
      "train loss:0.0030659437270198126\n",
      "train loss:0.0014731526077436782\n",
      "train loss:0.00038911400188683577\n",
      "train loss:0.002939966764975729\n",
      "train loss:0.0012269013142095881\n",
      "train loss:0.0015051306931905496\n",
      "train loss:0.0020557716465401743\n",
      "train loss:0.0010205257302546124\n",
      "train loss:0.013085101616855688\n",
      "train loss:0.00022356451639804335\n",
      "train loss:0.0038006372172308574\n",
      "train loss:0.0005640011680542538\n",
      "train loss:0.001807108164048834\n",
      "train loss:0.0002781151575642057\n",
      "train loss:0.0006867890522621451\n",
      "train loss:0.003631164273501024\n",
      "train loss:0.0006256671793840227\n",
      "train loss:0.00034209096270106814\n",
      "train loss:0.0005388875664774936\n",
      "train loss:0.0020638846173107626\n",
      "train loss:8.032179742381751e-05\n",
      "train loss:0.00035141401625533674\n",
      "train loss:0.0007560123837482041\n",
      "train loss:0.0002328244419154442\n",
      "train loss:0.0018345014162686303\n",
      "train loss:0.001854226375586896\n",
      "train loss:0.0024041426364419215\n",
      "train loss:0.00032544409358111\n",
      "train loss:0.0007051960920281844\n",
      "train loss:0.0005434314127388537\n",
      "train loss:7.682854160317076e-05\n",
      "train loss:0.0007643302355189001\n",
      "train loss:0.0003323874177464764\n",
      "train loss:0.004928797403086322\n",
      "train loss:0.000548441179644168\n",
      "train loss:0.0002534404753468873\n",
      "train loss:0.0002253244260521268\n",
      "train loss:0.0020800186027873134\n",
      "train loss:0.0016230614022257619\n",
      "train loss:0.00016945853811855597\n",
      "train loss:0.0013281760316302016\n",
      "train loss:0.0007419219893150653\n",
      "train loss:0.0021254835673657334\n",
      "train loss:0.0006334377378531948\n",
      "train loss:0.0002460701846605814\n",
      "train loss:0.002607546877237705\n",
      "train loss:0.0009900719647459844\n",
      "train loss:0.0020606558670200046\n",
      "train loss:0.00226699809919458\n",
      "train loss:0.0004979109786596113\n",
      "train loss:0.001451132305700923\n",
      "train loss:0.00017088375449686197\n",
      "train loss:0.0008145976441054823\n",
      "train loss:0.0016223048797586986\n",
      "train loss:0.0142480165308014\n",
      "train loss:0.002503198918900408\n",
      "train loss:0.0003913146967664292\n",
      "train loss:0.0008218667510204681\n",
      "train loss:0.0003349636175870576\n",
      "train loss:0.0017783029093200286\n",
      "train loss:0.0017002104834162137\n",
      "train loss:0.0008740601196336443\n",
      "train loss:7.757708979692576e-05\n",
      "train loss:0.00037059769356468465\n",
      "train loss:0.0012250632227254433\n",
      "train loss:0.0018943855485623656\n",
      "train loss:0.001925903149941902\n",
      "train loss:8.857192295113436e-05\n",
      "train loss:2.539115748240047e-05\n",
      "train loss:0.0002772880921780244\n",
      "train loss:0.00032155942303014793\n",
      "train loss:0.000564127871317556\n",
      "train loss:0.0003701922070235286\n",
      "train loss:0.0002893849100095818\n",
      "train loss:0.0009776509407968628\n",
      "train loss:0.002348972846741443\n",
      "train loss:0.0025486811541473747\n",
      "train loss:0.0024705892225416973\n",
      "train loss:0.001540153902765932\n",
      "train loss:0.003886847626725838\n",
      "train loss:0.0014769120082969156\n",
      "train loss:0.002794751276641811\n",
      "train loss:0.005123491071863607\n",
      "train loss:0.00018929900829531775\n",
      "train loss:0.00030755173046265167\n",
      "train loss:5.4938425556361154e-05\n",
      "train loss:0.001061895596242637\n",
      "train loss:5.441236559873815e-06\n",
      "train loss:0.003077962436020604\n",
      "train loss:0.00018395670350761746\n",
      "train loss:0.00010069117105168803\n",
      "train loss:0.00029948416935931524\n",
      "train loss:0.0007352607713112454\n",
      "train loss:0.001093591114752085\n",
      "train loss:4.513439766438679e-05\n",
      "train loss:0.00017658229879226816\n",
      "train loss:0.0011815616255434654\n",
      "train loss:0.004964887799325285\n",
      "train loss:0.00035781631770380343\n",
      "train loss:0.004135514098652412\n",
      "train loss:0.001656750559267015\n",
      "train loss:0.0018410633851089553\n",
      "train loss:0.0007112877475892088\n",
      "train loss:0.0013576856531796245\n",
      "train loss:0.0017108670316629418\n",
      "train loss:9.92182707818505e-05\n",
      "train loss:0.000386636169137405\n",
      "train loss:4.275350045899787e-05\n",
      "train loss:0.0035291195933343862\n",
      "train loss:0.001440148219120049\n",
      "train loss:0.00034515670246677876\n",
      "train loss:0.0019096280748495044\n",
      "train loss:0.002049237775543573\n",
      "train loss:0.0029357467819567887\n",
      "train loss:0.0007584123524290312\n",
      "train loss:0.001611434042744079\n",
      "train loss:0.0037701982551301967\n",
      "train loss:0.0009134923520214849\n",
      "train loss:0.0015823045199201658\n",
      "train loss:0.0015668728642375352\n",
      "train loss:0.0029947980158621518\n",
      "train loss:0.0057609600804200255\n",
      "train loss:0.0017417674069214342\n",
      "train loss:0.0005750391895194855\n",
      "train loss:0.009124158905139415\n",
      "train loss:0.0013502447512559687\n",
      "train loss:0.003405657636684178\n",
      "train loss:0.0018185497976668475\n",
      "train loss:0.0038479971740130875\n",
      "train loss:0.00020502197492104624\n",
      "train loss:0.010112498328954642\n",
      "train loss:0.000709711844083478\n",
      "train loss:0.0006331180769579327\n",
      "train loss:0.001208670713841999\n",
      "train loss:0.0005787659781682365\n",
      "train loss:0.0008732479173947258\n",
      "train loss:0.0013792187867043332\n",
      "train loss:0.00253795925107545\n",
      "train loss:0.0007726133248850606\n",
      "train loss:0.0019869871317456903\n",
      "train loss:0.006875428350652623\n",
      "train loss:0.0007021954164023295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0014457872318561639\n",
      "train loss:0.019401988268975094\n",
      "train loss:0.003587559859413653\n",
      "train loss:0.000626323184177429\n",
      "train loss:4.157266578524552e-05\n",
      "train loss:0.00033987064770620923\n",
      "train loss:0.0015759864021240647\n",
      "train loss:0.0006081324062655604\n",
      "train loss:0.002321107548570138\n",
      "train loss:0.0023281049434250496\n",
      "train loss:0.000685733116607838\n",
      "train loss:0.00010430041867374556\n",
      "train loss:0.0033509896691185314\n",
      "train loss:0.0048415928075058005\n",
      "train loss:0.00910035888247824\n",
      "train loss:0.003828859793405454\n",
      "train loss:0.001965607028296215\n",
      "train loss:0.0029055607075257465\n",
      "train loss:0.00045211319108640546\n",
      "train loss:0.0003666120884280233\n",
      "train loss:0.003788844102879508\n",
      "train loss:0.0003107736603185389\n",
      "train loss:0.0001854030979968312\n",
      "train loss:0.0020749728558923015\n",
      "train loss:0.0073849714596902994\n",
      "train loss:0.0006677668206929621\n",
      "train loss:0.005736279810886818\n",
      "train loss:0.001653218121330854\n",
      "train loss:0.00011398936852087517\n",
      "train loss:0.0040901056845644365\n",
      "train loss:0.0010916848951600423\n",
      "train loss:0.000552069341373453\n",
      "train loss:0.000126130617988873\n",
      "train loss:0.006677646588573442\n",
      "train loss:0.00441239480404792\n",
      "train loss:0.0056191864222534926\n",
      "train loss:0.000724106413363993\n",
      "train loss:0.002673680799490838\n",
      "train loss:0.0005444998433180759\n",
      "train loss:0.0015783008613794813\n",
      "train loss:0.0010677462767000605\n",
      "train loss:0.005461534599351194\n",
      "train loss:0.0012859256745736862\n",
      "train loss:0.0008077277521030894\n",
      "train loss:0.0011885195758315167\n",
      "train loss:0.0015816547997817487\n",
      "train loss:0.000592721940560486\n",
      "train loss:0.0027453779873406964\n",
      "train loss:0.003130127856979117\n",
      "train loss:0.0008810415810417102\n",
      "train loss:0.0012067389665945596\n",
      "train loss:0.0007449988804184911\n",
      "train loss:0.0023509771471143946\n",
      "train loss:0.0009786980562735532\n",
      "train loss:0.0006906120171528982\n",
      "train loss:0.0010948843707763935\n",
      "train loss:0.00013896074191522965\n",
      "train loss:0.0009079916522688983\n",
      "train loss:0.0033861893087028722\n",
      "train loss:0.00027033792107241213\n",
      "train loss:0.002086660636640175\n",
      "train loss:0.0008328850565376574\n",
      "train loss:0.0010095681977469705\n",
      "train loss:0.0024456974046607426\n",
      "train loss:0.0001431782921050671\n",
      "train loss:0.00024754447546204076\n",
      "train loss:0.0004238107049689673\n",
      "train loss:0.0009008070984877218\n",
      "train loss:0.0026142229611516104\n",
      "train loss:0.00016837526479405844\n",
      "train loss:0.0012117565804177985\n",
      "train loss:0.00033476605074181555\n",
      "train loss:0.0014954871291634416\n",
      "train loss:0.003171725351493656\n",
      "train loss:0.0002090512998589488\n",
      "train loss:0.0035767378351305172\n",
      "train loss:0.009202684064218584\n",
      "train loss:0.00022469490926624653\n",
      "train loss:0.0017262134797698088\n",
      "train loss:0.004124011334473203\n",
      "train loss:0.0031187401537903807\n",
      "train loss:0.003783196528920646\n",
      "train loss:0.0028844292086488256\n",
      "train loss:0.00020016465523259045\n",
      "train loss:0.0007163395212400437\n",
      "train loss:0.001650947043651651\n",
      "train loss:0.0023604433812175717\n",
      "train loss:0.0011601737487369813\n",
      "train loss:0.0275514136952579\n",
      "train loss:0.0008055808337245656\n",
      "train loss:0.007586179742868341\n",
      "train loss:0.004478770020878597\n",
      "train loss:0.011595320732680376\n",
      "train loss:0.0007875321281947843\n",
      "train loss:0.017365976834647565\n",
      "train loss:0.00509390095517199\n",
      "train loss:0.004733029123930777\n",
      "train loss:0.00042732656999327443\n",
      "train loss:0.0032518982701262235\n",
      "train loss:0.0012424204687824416\n",
      "train loss:0.0006854873712612458\n",
      "train loss:0.004877769307613584\n",
      "train loss:0.00042404139752585425\n",
      "train loss:0.002462740187378582\n",
      "train loss:0.0010698883718283953\n",
      "train loss:0.007018988587280967\n",
      "train loss:0.0018862247891951204\n",
      "train loss:0.0011287362309716552\n",
      "train loss:0.0009745244531193469\n",
      "train loss:4.579488778031535e-05\n",
      "train loss:0.0012137494517308837\n",
      "train loss:0.0008688843572647851\n",
      "train loss:0.0004749806398025299\n",
      "train loss:0.0001469242198633931\n",
      "train loss:0.0003501309624963248\n",
      "train loss:0.00012997839717256897\n",
      "train loss:0.0004650135206954245\n",
      "train loss:0.0017925172982659104\n",
      "train loss:0.003137054239623305\n",
      "train loss:0.004785113680043876\n",
      "train loss:0.025915454612497456\n",
      "train loss:0.0014676777466545105\n",
      "train loss:0.0033861571742086535\n",
      "train loss:0.00015228417226395853\n",
      "train loss:0.002410882664772279\n",
      "train loss:0.0007455484946678282\n",
      "train loss:0.00048808829525384537\n",
      "train loss:0.0015342839235557642\n",
      "train loss:0.0008335549429317929\n",
      "train loss:0.00025941379158187964\n",
      "train loss:0.0031934570428486546\n",
      "train loss:0.0008036053783622954\n",
      "train loss:0.0008579944490392355\n",
      "train loss:0.002218730539006373\n",
      "train loss:0.002747546883406461\n",
      "train loss:0.002561786806779455\n",
      "train loss:0.002115763929658551\n",
      "train loss:0.007716457044612147\n",
      "train loss:0.0024121728864514\n",
      "train loss:0.012830636144521517\n",
      "train loss:0.0003879246252214414\n",
      "train loss:0.0022086288379113074\n",
      "train loss:0.0030706510115496356\n",
      "train loss:0.0021552754673695358\n",
      "train loss:3.513567967208669e-05\n",
      "train loss:0.0036456550107170057\n",
      "train loss:0.0018870240067254715\n",
      "train loss:0.0008669840341384363\n",
      "train loss:0.0028122049666508713\n",
      "train loss:0.0037860438245869836\n",
      "train loss:0.003789688673651291\n",
      "train loss:0.0010558739799441457\n",
      "train loss:0.005470842426287663\n",
      "train loss:0.0054178136778972145\n",
      "train loss:0.0011531951858595652\n",
      "train loss:0.00014538764547716558\n",
      "train loss:0.0002678150261772521\n",
      "train loss:0.00407078669724932\n",
      "train loss:0.0011213619671083504\n",
      "train loss:0.0014770685556655633\n",
      "train loss:0.0003494470247896768\n",
      "train loss:0.000842596855350983\n",
      "train loss:0.001627202961549135\n",
      "train loss:0.003799502098541735\n",
      "train loss:0.006562484453297312\n",
      "train loss:0.0003856286477776142\n",
      "train loss:0.0007980641029637056\n",
      "train loss:0.0027131342303196495\n",
      "train loss:0.00343357270143649\n",
      "train loss:0.0015108885507389789\n",
      "train loss:0.0014110855188903845\n",
      "train loss:0.00045542571508782226\n",
      "train loss:0.0010284931020632187\n",
      "train loss:0.0019182945276660954\n",
      "train loss:0.002273115745640186\n",
      "train loss:0.0001985248524148458\n",
      "train loss:0.00524160718680779\n",
      "train loss:0.0010231493542267463\n",
      "train loss:0.00035527728266086485\n",
      "train loss:0.0032308818591471494\n",
      "train loss:3.6083390031446796e-05\n",
      "train loss:3.5966931442623844e-05\n",
      "train loss:0.0028005602497900408\n",
      "train loss:0.0013190710450575527\n",
      "train loss:0.00035139254659459826\n",
      "train loss:0.002664302943952354\n",
      "train loss:0.0031472608815546416\n",
      "train loss:0.00122862229266993\n",
      "train loss:0.0009446116152314318\n",
      "train loss:0.0009077004650846384\n",
      "train loss:0.006861381785715596\n",
      "train loss:0.0009153569593612616\n",
      "train loss:0.00010729521900415572\n",
      "train loss:0.0013961809375817719\n",
      "train loss:0.0028354729208900863\n",
      "train loss:0.00013858730993457556\n",
      "train loss:0.0008381445224332399\n",
      "train loss:0.003522332166161023\n",
      "train loss:0.00012886477088608795\n",
      "train loss:0.005290014824072874\n",
      "train loss:0.00022495620648321633\n",
      "train loss:0.0008080283056063976\n",
      "train loss:0.0006088260138229234\n",
      "train loss:0.0006658718058538851\n",
      "train loss:0.0012686880759640374\n",
      "train loss:2.9119534752287624e-05\n",
      "train loss:0.0022102705825497995\n",
      "train loss:0.0010262068007644504\n",
      "train loss:0.00037031819984209677\n",
      "train loss:0.0016219756171071645\n",
      "train loss:0.0073878493828375335\n",
      "train loss:0.0003494951503380857\n",
      "train loss:0.0008407672585841682\n",
      "train loss:0.000662518770626484\n",
      "train loss:0.00011101262461483722\n",
      "train loss:0.001244820482116809\n",
      "train loss:8.889374642984921e-05\n",
      "train loss:0.005298382288299918\n",
      "train loss:0.0037341643167781097\n",
      "train loss:0.002537673436868553\n",
      "train loss:0.0005078063392652717\n",
      "train loss:0.0017012744603703775\n",
      "train loss:0.0010264831727053335\n",
      "train loss:0.0030621265365929485\n",
      "train loss:0.001993547163651457\n",
      "train loss:0.0007113568643820796\n",
      "train loss:0.0021443115802310597\n",
      "train loss:7.565236224429755e-05\n",
      "train loss:0.000709264450175768\n",
      "train loss:0.00010969531913033452\n",
      "train loss:0.0013598664791532949\n",
      "train loss:0.0033915803215223018\n",
      "train loss:0.0009808692992384124\n",
      "train loss:0.013391067797141647\n",
      "train loss:0.001298144112903265\n",
      "train loss:0.00010464070968613157\n",
      "train loss:0.0005679923643098748\n",
      "train loss:0.0002987118087194651\n",
      "train loss:0.0006720881100036115\n",
      "train loss:0.0006635044818114403\n",
      "train loss:0.0009549994414315721\n",
      "train loss:0.0009775874211699368\n",
      "train loss:0.002128974482879411\n",
      "train loss:0.0028329241940331074\n",
      "train loss:0.0013364668794721198\n",
      "train loss:0.0033921935571986513\n",
      "train loss:0.0004602057141549784\n",
      "train loss:0.0020306882527541424\n",
      "train loss:0.0024642203610447315\n",
      "train loss:0.00038861016809633975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00012444719183482032\n",
      "train loss:3.257889807144597e-05\n",
      "train loss:0.0020400582427752487\n",
      "train loss:0.00019811102763016208\n",
      "train loss:0.0017657026582272156\n",
      "train loss:0.0018138712386591017\n",
      "train loss:0.0001400069901671326\n",
      "train loss:8.068821433214201e-05\n",
      "train loss:0.014220227264055817\n",
      "train loss:0.0013102887879080272\n",
      "train loss:0.0015431246435677092\n",
      "train loss:8.852577969436286e-05\n",
      "train loss:0.00247022238845158\n",
      "train loss:0.0011465170729721644\n",
      "train loss:0.01296491455152343\n",
      "train loss:0.00517260761542045\n",
      "train loss:0.002935567673166081\n",
      "train loss:0.0012667310905716794\n",
      "train loss:0.00014693863689749454\n",
      "train loss:0.00042092976731644043\n",
      "train loss:0.0009264562059800673\n",
      "train loss:0.004745295495742902\n",
      "train loss:6.84404266612592e-05\n",
      "train loss:0.0002590408546711762\n",
      "train loss:0.0034814397858060364\n",
      "train loss:4.635697144536791e-05\n",
      "train loss:0.0003665540904421833\n",
      "train loss:0.00010715182407755589\n",
      "train loss:0.001077809408887271\n",
      "train loss:0.00031453322007870166\n",
      "train loss:0.0002920537351861511\n",
      "train loss:0.0013508146704510795\n",
      "train loss:4.4181764097943144e-05\n",
      "train loss:0.0008562030112291213\n",
      "train loss:0.001226191889602092\n",
      "train loss:0.006889600558458195\n",
      "train loss:0.00014053781099479184\n",
      "train loss:0.006644679244547155\n",
      "train loss:0.000413121681567021\n",
      "train loss:0.0001391089727725046\n",
      "train loss:0.0020803966818126814\n",
      "train loss:0.0002924190556055845\n",
      "train loss:0.002161161889502208\n",
      "train loss:0.0025285422925367964\n",
      "train loss:0.0014277445448618695\n",
      "train loss:0.002010506350852615\n",
      "train loss:0.0013492839488856339\n",
      "train loss:0.002317500072260968\n",
      "train loss:0.0006003152505715547\n",
      "train loss:0.0017529847703415796\n",
      "train loss:0.046394565208159946\n",
      "train loss:0.000974347755602651\n",
      "train loss:0.004313950806781581\n",
      "train loss:0.0009116299877447815\n",
      "train loss:0.0006036537436748761\n",
      "train loss:0.0013797553495555057\n",
      "train loss:0.0006669040072489077\n",
      "train loss:0.0006066889119490393\n",
      "train loss:0.001538833940116593\n",
      "train loss:0.0002883180629090598\n",
      "train loss:0.0009978323156369128\n",
      "train loss:0.0004025210657675107\n",
      "train loss:0.0014580066305929613\n",
      "train loss:0.0010426682959573776\n",
      "train loss:0.00012902161003272268\n",
      "train loss:0.0021811555285092096\n",
      "train loss:0.00016515348026677407\n",
      "train loss:0.0009512503871528847\n",
      "train loss:0.0010623727483423434\n",
      "train loss:0.002037957000628544\n",
      "train loss:0.00032369689315959647\n",
      "train loss:0.0017428338212327834\n",
      "train loss:0.0005506818103374433\n",
      "train loss:0.0009069560041814493\n",
      "train loss:0.005238830812812862\n",
      "train loss:0.001645783737039434\n",
      "train loss:0.0009373305937934548\n",
      "train loss:0.0010852305644609096\n",
      "train loss:0.001277550690380044\n",
      "train loss:4.2945699674362084e-05\n",
      "train loss:0.0006407871752839124\n",
      "train loss:0.001695066242763266\n",
      "train loss:0.0009541205121747889\n",
      "train loss:0.0008896576526655291\n",
      "train loss:0.003584848551267528\n",
      "train loss:0.00038092641586766297\n",
      "train loss:0.004243204698200787\n",
      "train loss:0.00033731121120485354\n",
      "train loss:0.0014785564388219725\n",
      "train loss:0.0032095066632775978\n",
      "train loss:0.003955971707474886\n",
      "train loss:0.0002512711721231468\n",
      "train loss:0.00018048171569168603\n",
      "train loss:0.0034532100044078183\n",
      "train loss:0.0002426014025710538\n",
      "train loss:0.0003517333592969515\n",
      "train loss:0.00029156299286226434\n",
      "train loss:0.006372153769963256\n",
      "train loss:0.00024702360408921113\n",
      "train loss:0.0032497110815684666\n",
      "train loss:0.0010365548713752218\n",
      "train loss:0.0018861489499261996\n",
      "train loss:0.00011382732952360974\n",
      "train loss:0.0004586366206330301\n",
      "train loss:0.00403048799483335\n",
      "train loss:0.0005766097166575146\n",
      "train loss:0.0006314933634338078\n",
      "train loss:0.0007119979947430052\n",
      "train loss:0.0013979069250566619\n",
      "train loss:0.0009162058972891908\n",
      "train loss:0.0011323417377545409\n",
      "train loss:0.028023662642686326\n",
      "train loss:0.009352892406987019\n",
      "train loss:0.008360950812162279\n",
      "train loss:0.0003548589195855412\n",
      "train loss:0.0003853185780467514\n",
      "train loss:0.00507226995314744\n",
      "train loss:0.0008492752868634813\n",
      "train loss:0.0032664832342654475\n",
      "train loss:0.0025116637978890915\n",
      "train loss:0.0032375783626858983\n",
      "train loss:0.0007668953942631233\n",
      "train loss:0.0010909964416332006\n",
      "train loss:0.0023547069564913963\n",
      "train loss:0.0002174130265560537\n",
      "train loss:0.0002628962615074794\n",
      "train loss:0.007281984658392443\n",
      "train loss:0.0016908695126854228\n",
      "train loss:0.003486935751670287\n",
      "train loss:0.0027642702180937424\n",
      "train loss:0.0012883840466952413\n",
      "train loss:0.00023851944010310513\n",
      "train loss:0.0019760483874624642\n",
      "train loss:0.00032407732201421687\n",
      "train loss:0.00013922225054417562\n",
      "train loss:0.0015135657037990663\n",
      "train loss:0.0017402179482574123\n",
      "train loss:0.001898816234264421\n",
      "train loss:4.5375401264675524e-05\n",
      "train loss:0.0005546599680669222\n",
      "train loss:0.0028762712929963625\n",
      "train loss:0.0034698457601766174\n",
      "train loss:0.0014690470608570395\n",
      "train loss:0.00015442977793921279\n",
      "train loss:0.0029588986764070555\n",
      "train loss:0.0020060520736541114\n",
      "train loss:0.000996134812179078\n",
      "train loss:9.15889285377572e-05\n",
      "train loss:0.0027558371469344396\n",
      "train loss:0.000669952918266002\n",
      "train loss:0.0013382656404205137\n",
      "train loss:0.00038888688617649776\n",
      "train loss:0.002215567719903142\n",
      "train loss:0.002418213602407005\n",
      "train loss:0.0021832398483573154\n",
      "train loss:0.0011976709600526076\n",
      "train loss:0.00023166248390398458\n",
      "train loss:2.9833617321322672e-05\n",
      "train loss:0.0005547869526069575\n",
      "train loss:0.00015180038110807452\n",
      "train loss:0.001708439502423801\n",
      "train loss:0.00038672200490853515\n",
      "train loss:0.0018449112156409238\n",
      "train loss:0.0007166840197739941\n",
      "train loss:0.00033799590903876224\n",
      "train loss:4.176584831009681e-05\n",
      "train loss:0.0008251022712782565\n",
      "train loss:0.0007934868475193537\n",
      "train loss:0.0008978879477482101\n",
      "train loss:2.194854770160182e-05\n",
      "train loss:0.002973231622944177\n",
      "train loss:0.0023602334204432564\n",
      "train loss:0.000675979093692756\n",
      "train loss:0.00041697844237981066\n",
      "train loss:0.00025911970506171445\n",
      "train loss:0.00017413930660429238\n",
      "train loss:0.0009687630539904052\n",
      "train loss:0.0011347677949316128\n",
      "train loss:0.009106616627407905\n",
      "train loss:0.005451944665427841\n",
      "train loss:0.0005163874077244218\n",
      "train loss:0.00024801162788874937\n",
      "train loss:0.0016765680634333816\n",
      "train loss:0.0002350397448780369\n",
      "train loss:0.0017552407262611286\n",
      "train loss:0.005744537318981101\n",
      "train loss:0.017852111392148987\n",
      "train loss:0.004031514894385028\n",
      "train loss:0.004174592532258376\n",
      "train loss:0.0007933526930817069\n",
      "train loss:0.0018764403351626943\n",
      "train loss:0.0024948389148379403\n",
      "train loss:0.0026397364014713954\n",
      "train loss:0.0011209957054243202\n",
      "train loss:0.0054131039595182225\n",
      "train loss:0.0006693141991550949\n",
      "train loss:0.009214610791803057\n",
      "train loss:0.00016787209895392536\n",
      "=== epoch:18, train acc:0.998, test acc:0.986 ===\n",
      "train loss:0.0004356087280697966\n",
      "train loss:0.0005432877521988912\n",
      "train loss:0.0009117056610411863\n",
      "train loss:0.003734189952542\n",
      "train loss:0.014595508415316562\n",
      "train loss:0.0006991136704945951\n",
      "train loss:0.003399417855472597\n",
      "train loss:0.001124697457759054\n",
      "train loss:0.000731420299226771\n",
      "train loss:0.00011698387941990073\n",
      "train loss:0.0008809150858436088\n",
      "train loss:0.0022098814797186705\n",
      "train loss:0.004279744271632847\n",
      "train loss:0.001999046941693883\n",
      "train loss:0.00045499035039899124\n",
      "train loss:0.0032729516344778015\n",
      "train loss:0.00046500146177656137\n",
      "train loss:0.0011380669430556384\n",
      "train loss:0.0003909848975608009\n",
      "train loss:0.006916410642626991\n",
      "train loss:0.0034945498586739067\n",
      "train loss:0.0004834403319490637\n",
      "train loss:0.001458562500914455\n",
      "train loss:0.001981089668991149\n",
      "train loss:0.0008018144674756612\n",
      "train loss:0.0028927998829992737\n",
      "train loss:0.02486088390314696\n",
      "train loss:0.0037353777513247865\n",
      "train loss:0.0015286925895298276\n",
      "train loss:0.0007558221067268653\n",
      "train loss:0.0014907103699515728\n",
      "train loss:0.0052024564904258296\n",
      "train loss:0.0013135348107909963\n",
      "train loss:0.00022083747110678142\n",
      "train loss:0.0003404066481967755\n",
      "train loss:0.0009481157588079706\n",
      "train loss:0.0012962436466560684\n",
      "train loss:0.0022383166478883694\n",
      "train loss:0.0005640606093332228\n",
      "train loss:0.0017882350235525922\n",
      "train loss:0.0005295612030839673\n",
      "train loss:0.00013714930516608428\n",
      "train loss:0.001818053883478359\n",
      "train loss:0.0039027405599745334\n",
      "train loss:0.025685279243005992\n",
      "train loss:0.000668548812250444\n",
      "train loss:0.00040915776876141694\n",
      "train loss:0.000249410916044053\n",
      "train loss:0.001107208232678578\n",
      "train loss:0.0005198300669334211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0006056213141083185\n",
      "train loss:0.015059469399518726\n",
      "train loss:0.003137384115973502\n",
      "train loss:3.998588940997319e-05\n",
      "train loss:0.004145480913443198\n",
      "train loss:0.02687980421385575\n",
      "train loss:0.0019774051388995557\n",
      "train loss:0.0008267524898150761\n",
      "train loss:0.0001255249451757111\n",
      "train loss:0.001409203923391483\n",
      "train loss:0.0006833198673837336\n",
      "train loss:0.0026326492478380083\n",
      "train loss:0.004968455612171994\n",
      "train loss:0.0030540958444131975\n",
      "train loss:0.002082804522050575\n",
      "train loss:0.002920337701770706\n",
      "train loss:0.0011536674985180683\n",
      "train loss:0.006400518676752779\n",
      "train loss:0.008174932295127873\n",
      "train loss:0.0012492019218743754\n",
      "train loss:0.011217613640788437\n",
      "train loss:0.0011134632526936213\n",
      "train loss:0.00022580064149048225\n",
      "train loss:0.0007121205324327865\n",
      "train loss:0.0007471870591233282\n",
      "train loss:0.0003428981536437887\n",
      "train loss:0.01341022939131465\n",
      "train loss:0.01831547610082856\n",
      "train loss:0.003585679392925855\n",
      "train loss:0.001183676676430697\n",
      "train loss:0.00016415951011942685\n",
      "train loss:0.000697406487185334\n",
      "train loss:0.001085800937996551\n",
      "train loss:0.0011710427704513875\n",
      "train loss:0.0018566178982780067\n",
      "train loss:5.0047792130052826e-05\n",
      "train loss:0.002078004805591311\n",
      "train loss:0.004511552947253625\n",
      "train loss:0.00027591368025627056\n",
      "train loss:0.00014524686732238592\n",
      "train loss:0.001867496033327746\n",
      "train loss:0.0016424087605248468\n",
      "train loss:0.0005374399077880839\n",
      "train loss:0.00029286425273592024\n",
      "train loss:0.0009630153817064059\n",
      "train loss:0.0003640335482074258\n",
      "train loss:0.00027302604943867814\n",
      "train loss:0.00737052841544163\n",
      "train loss:0.0028363246354385706\n",
      "train loss:0.0036197165521038594\n",
      "train loss:0.0001451615131605124\n",
      "train loss:0.001518184382709926\n",
      "train loss:0.0040833241156235335\n",
      "train loss:0.001719637869646426\n",
      "train loss:0.0011433213454235397\n",
      "train loss:0.0006089714049658659\n",
      "train loss:7.626898843676459e-05\n",
      "train loss:0.0027282423019842376\n",
      "train loss:0.0025808633639164565\n",
      "train loss:0.0002018647430042107\n",
      "train loss:0.00020528705527095338\n",
      "train loss:0.00045255268667451754\n",
      "train loss:0.0035195612767944255\n",
      "train loss:0.0003769945469636995\n",
      "train loss:0.0015499134036220444\n",
      "train loss:0.0007229177621498332\n",
      "train loss:0.00021815311527944607\n",
      "train loss:0.0024365516569436383\n",
      "train loss:0.0009615829475806084\n",
      "train loss:0.0009170752472233269\n",
      "train loss:0.0007711152094373086\n",
      "train loss:0.0011039529595085423\n",
      "train loss:0.02316832425638546\n",
      "train loss:0.0003336501074426146\n",
      "train loss:0.003088527951920616\n",
      "train loss:0.0007010472499013938\n",
      "train loss:0.0022542368743467046\n",
      "train loss:0.0005180466295092644\n",
      "train loss:0.002072194931470339\n",
      "train loss:0.001862997082812294\n",
      "train loss:0.010016975918315291\n",
      "train loss:0.008716315696691462\n",
      "train loss:0.008376933472475763\n",
      "train loss:0.0004662340231831148\n",
      "train loss:0.0024561287403939134\n",
      "train loss:0.01407977658494314\n",
      "train loss:0.011464933621081308\n",
      "train loss:0.009055256861352699\n",
      "train loss:0.0003089745027668674\n",
      "train loss:0.0015337056510334873\n",
      "train loss:0.0005791881865879893\n",
      "train loss:0.0034743982219574403\n",
      "train loss:0.005280363635332554\n",
      "train loss:0.004601520893294305\n",
      "train loss:0.0017183211094424513\n",
      "train loss:0.0037259295189343363\n",
      "train loss:0.0028857526257462305\n",
      "train loss:0.00013260027394781322\n",
      "train loss:0.0003627333046048967\n",
      "train loss:0.0039022124799170505\n",
      "train loss:0.003166538225477113\n",
      "train loss:0.0016458308204104321\n",
      "train loss:0.01038631687753329\n",
      "train loss:0.0007443539742931039\n",
      "train loss:6.697840965497781e-05\n",
      "train loss:0.0013072079033588585\n",
      "train loss:0.0023813611320121124\n",
      "train loss:0.0011466337677781416\n",
      "train loss:0.0007457499489643114\n",
      "train loss:0.0007710241606587766\n",
      "train loss:0.00433532029158333\n",
      "train loss:0.002443270511007071\n",
      "train loss:0.0012787445794699565\n",
      "train loss:0.00010927594656944846\n",
      "train loss:0.0012266803454927047\n",
      "train loss:0.003317959295018863\n",
      "train loss:0.007382173400350479\n",
      "train loss:0.0006030287718442798\n",
      "train loss:0.0005038975883842556\n",
      "train loss:8.515455551474008e-05\n",
      "train loss:0.0029226726967259875\n",
      "train loss:0.0007684240425399973\n",
      "train loss:0.0012349965300473109\n",
      "train loss:0.00010342194062765889\n",
      "train loss:0.00019763185324572004\n",
      "train loss:0.0008058620219912881\n",
      "train loss:0.0020539580426811414\n",
      "train loss:0.002561582075405788\n",
      "train loss:9.483651044614385e-06\n",
      "train loss:0.0019271392972969334\n",
      "train loss:0.0017109340784340916\n",
      "train loss:0.0003954241500264024\n",
      "train loss:0.0007312602706712245\n",
      "train loss:0.003658424371643455\n",
      "train loss:0.00021103437742153708\n",
      "train loss:0.0004038843383216807\n",
      "train loss:0.0005045052257185108\n",
      "train loss:0.0011075349670372067\n",
      "train loss:0.005224652415398288\n",
      "train loss:0.00043422799624577785\n",
      "train loss:0.00046249287076430176\n",
      "train loss:0.0008250468566279831\n",
      "train loss:0.0004932047225926719\n",
      "train loss:0.0001950023977026526\n",
      "train loss:0.00010596318801281415\n",
      "train loss:0.0010708825766242206\n",
      "train loss:0.0025786887059068946\n",
      "train loss:0.000394005720566176\n",
      "train loss:4.2892701437056146e-05\n",
      "train loss:0.005658528569800877\n",
      "train loss:0.0007227768120327893\n",
      "train loss:0.00020875507107285493\n",
      "train loss:0.0003712523271600185\n",
      "train loss:0.003914185017812595\n",
      "train loss:0.0038270056767412586\n",
      "train loss:0.0011801031676236555\n",
      "train loss:0.001932475854980026\n",
      "train loss:0.00020171564963251156\n",
      "train loss:0.016676851320072232\n",
      "train loss:0.00020869526906621777\n",
      "train loss:0.0007291164969119266\n",
      "train loss:2.3080039133279705e-05\n",
      "train loss:0.0034314382024975216\n",
      "train loss:0.0004894287379625021\n",
      "train loss:0.002833716445901354\n",
      "train loss:0.0010349070664122544\n",
      "train loss:0.00010943536128599043\n",
      "train loss:0.000873006707438969\n",
      "train loss:0.001599036774798043\n",
      "train loss:0.0001438279000164736\n",
      "train loss:0.0004704044869883115\n",
      "train loss:0.004720702531020996\n",
      "train loss:0.001676970627880511\n",
      "train loss:0.0017865262845934715\n",
      "train loss:0.010777166000183613\n",
      "train loss:0.005114164878616322\n",
      "train loss:0.0006560731635374877\n",
      "train loss:3.239547921545443e-05\n",
      "train loss:0.001183575226740665\n",
      "train loss:0.0017047495017310102\n",
      "train loss:3.520524965301055e-05\n",
      "train loss:0.0004767335791373301\n",
      "train loss:0.003240283708312364\n",
      "train loss:0.00014375706840966126\n",
      "train loss:0.00880654082996634\n",
      "train loss:0.00018282304344107973\n",
      "train loss:0.00022411656510133514\n",
      "train loss:0.0009583806210409472\n",
      "train loss:0.00037140003164598203\n",
      "train loss:0.00012724438279431802\n",
      "train loss:0.013426815441078342\n",
      "train loss:0.0011419103219294541\n",
      "train loss:6.398042873632935e-05\n",
      "train loss:0.0005234158195286281\n",
      "train loss:0.009341820059115095\n",
      "train loss:0.0014585628706565734\n",
      "train loss:0.0019471756440725982\n",
      "train loss:0.0016461895690075249\n",
      "train loss:0.005469845336749669\n",
      "train loss:0.006835635540683397\n",
      "train loss:0.002379795455133847\n",
      "train loss:0.0027535825431825476\n",
      "train loss:0.0008407301860741065\n",
      "train loss:0.0008442265325127309\n",
      "train loss:0.004052642246711436\n",
      "train loss:0.0054343808935220506\n",
      "train loss:0.0003859705831576623\n",
      "train loss:0.0010053682381638634\n",
      "train loss:0.0020522199377254317\n",
      "train loss:0.0005490512490107465\n",
      "train loss:0.0007103736119216342\n",
      "train loss:0.0005540225838092669\n",
      "train loss:0.0008059490795035182\n",
      "train loss:0.004825155395690921\n",
      "train loss:3.885140794421824e-05\n",
      "train loss:0.001080354154098544\n",
      "train loss:0.0013154662620001249\n",
      "train loss:0.004511945858870256\n",
      "train loss:0.002036790507802303\n",
      "train loss:0.002739074151693249\n",
      "train loss:0.00010913652397606961\n",
      "train loss:0.0011024232466974784\n",
      "train loss:0.0003324605329639711\n",
      "train loss:0.00872207062223821\n",
      "train loss:0.017388444142846318\n",
      "train loss:4.38954030451268e-05\n",
      "train loss:0.0001337141058543302\n",
      "train loss:0.0034759477983683233\n",
      "train loss:0.0031680402826900923\n",
      "train loss:0.0007035937958821009\n",
      "train loss:0.0006389208083018612\n",
      "train loss:0.0011603348854056365\n",
      "train loss:0.0010672058699988999\n",
      "train loss:0.00030059944243032054\n",
      "train loss:0.004021724341270326\n",
      "train loss:0.0019394761269427344\n",
      "train loss:0.0008853016963256595\n",
      "train loss:0.006423497725613632\n",
      "train loss:0.00013995833905306135\n",
      "train loss:0.0006088660465879037\n",
      "train loss:6.488906829076754e-05\n",
      "train loss:0.0007811897401400158\n",
      "train loss:0.002467945130368077\n",
      "train loss:0.001380880864397229\n",
      "train loss:0.00012509529077360542\n",
      "train loss:0.000343222957227328\n",
      "train loss:0.004836201958359217\n",
      "train loss:0.001256185033325481\n",
      "train loss:0.0006370102322248698\n",
      "train loss:0.0029915136027600965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.001039751041331276\n",
      "train loss:0.00242143899039417\n",
      "train loss:0.0053475933363259665\n",
      "train loss:0.001603325680613595\n",
      "train loss:0.0027099795142117218\n",
      "train loss:0.0003752030467426813\n",
      "train loss:0.0003065369643372507\n",
      "train loss:0.00016246153093517506\n",
      "train loss:0.001690409645107145\n",
      "train loss:0.0015954541728145197\n",
      "train loss:7.218984193464464e-05\n",
      "train loss:0.00017268874059574033\n",
      "train loss:0.0005824678985234\n",
      "train loss:0.0003701843163894435\n",
      "train loss:0.0007186356295084748\n",
      "train loss:0.001019235960210029\n",
      "train loss:0.0031104444535436752\n",
      "train loss:0.007061316392012876\n",
      "train loss:1.8732541080511104e-05\n",
      "train loss:0.0020506960622200744\n",
      "train loss:0.0005362317630516782\n",
      "train loss:0.0011178856391454695\n",
      "train loss:0.0013941020512964392\n",
      "train loss:0.0006424293001628414\n",
      "train loss:0.0006887310819418158\n",
      "train loss:9.283788423621271e-05\n",
      "train loss:0.0002502826221063367\n",
      "train loss:0.0010748844877732648\n",
      "train loss:6.856260868440915e-05\n",
      "train loss:0.002027731352424248\n",
      "train loss:0.0004815447952473414\n",
      "train loss:0.0001993524446941715\n",
      "train loss:0.001889750111879779\n",
      "train loss:0.0003141244951665261\n",
      "train loss:8.164409221160847e-05\n",
      "train loss:0.00042331710087335897\n",
      "train loss:0.0017685172011755728\n",
      "train loss:0.002382224790353084\n",
      "train loss:0.0023595666950453936\n",
      "train loss:0.0001690489231564435\n",
      "train loss:0.00027303797114047935\n",
      "train loss:0.00025711598177673975\n",
      "train loss:0.001965825069841708\n",
      "train loss:0.00015372937502618338\n",
      "train loss:0.002321247160169637\n",
      "train loss:0.002065628452912226\n",
      "train loss:0.00013095113821239173\n",
      "train loss:2.249128324176271e-05\n",
      "train loss:1.682524084620789e-05\n",
      "train loss:0.016112879573743032\n",
      "train loss:0.0026081855436306868\n",
      "train loss:0.00023365504756328798\n",
      "train loss:0.002633828624816212\n",
      "train loss:0.00042618547301202076\n",
      "train loss:0.00929382600202564\n",
      "train loss:7.888906434441698e-05\n",
      "train loss:0.0055574640989408085\n",
      "train loss:0.00022319247847223545\n",
      "train loss:8.199646529473265e-05\n",
      "train loss:2.9518148993292873e-05\n",
      "train loss:7.694116001270622e-05\n",
      "train loss:0.004242851909332342\n",
      "train loss:0.0009137723748828328\n",
      "train loss:0.0009406512262496983\n",
      "train loss:0.0003762474560537763\n",
      "train loss:0.002047471813404819\n",
      "train loss:0.0011858137631259526\n",
      "train loss:0.0010769130209046945\n",
      "train loss:0.0002719045513687156\n",
      "train loss:0.001017892363656674\n",
      "train loss:0.0007071820704954344\n",
      "train loss:0.00018625639591693174\n",
      "train loss:0.0012096687194697664\n",
      "train loss:0.002780016031131199\n",
      "train loss:0.001682337002313234\n",
      "train loss:0.0009682318179970871\n",
      "train loss:0.001894609120836008\n",
      "train loss:0.000288177370134865\n",
      "train loss:0.004808407269851087\n",
      "train loss:0.0028078876486543215\n",
      "train loss:0.0002657128998772975\n",
      "train loss:0.000664778745252738\n",
      "train loss:0.0010342357236109753\n",
      "train loss:0.0020305956286194504\n",
      "train loss:0.003017124807172896\n",
      "train loss:0.0014877235427773808\n",
      "train loss:0.0003006170088540712\n",
      "train loss:0.0007667111705723441\n",
      "train loss:0.0015734824339526177\n",
      "train loss:0.004353898527221457\n",
      "train loss:0.0012367448295821436\n",
      "train loss:0.0009932949393155186\n",
      "train loss:0.0008665245863658145\n",
      "train loss:0.00021710914615327554\n",
      "train loss:0.004369808599456097\n",
      "train loss:4.2150308636335376e-05\n",
      "train loss:0.00025468173629036693\n",
      "train loss:0.000315922035342392\n",
      "train loss:0.0016028420336544871\n",
      "train loss:0.0008349543743034208\n",
      "train loss:0.0008301305266176576\n",
      "train loss:0.0003551832325504997\n",
      "train loss:0.0015239813615986\n",
      "train loss:0.0009586841134102076\n",
      "train loss:0.00030760906700694044\n",
      "train loss:0.0007484042368433059\n",
      "train loss:0.0019836056803817837\n",
      "train loss:0.0007646879750710986\n",
      "train loss:0.001281101790950284\n",
      "train loss:0.00027671409152530953\n",
      "train loss:0.0012677695005074814\n",
      "train loss:0.0013431194145895116\n",
      "train loss:0.0004115559055043282\n",
      "train loss:0.00044944165437580855\n",
      "train loss:0.0014129487631379352\n",
      "train loss:0.003198979573369133\n",
      "train loss:0.0006577779187437214\n",
      "train loss:0.0005337382299561503\n",
      "train loss:0.001045354193125735\n",
      "train loss:0.002372765414829345\n",
      "train loss:9.08564795059596e-05\n",
      "train loss:0.0007268893235281333\n",
      "train loss:9.229677257280914e-05\n",
      "train loss:0.00018334871776748638\n",
      "train loss:0.00127602886933011\n",
      "train loss:0.00026707116686544964\n",
      "train loss:2.106842421377301e-05\n",
      "train loss:2.3635969310426317e-05\n",
      "train loss:0.0006790671870620963\n",
      "train loss:0.003512107421303503\n",
      "train loss:0.0005644455519098876\n",
      "train loss:0.0025934446719208092\n",
      "train loss:0.000785398520276237\n",
      "train loss:0.0006527363117700398\n",
      "train loss:0.00023324701218083876\n",
      "train loss:0.001115898941070502\n",
      "train loss:0.002581949026727838\n",
      "train loss:0.00017188262772587642\n",
      "train loss:0.00011472463894069818\n",
      "train loss:0.0008192292541156222\n",
      "train loss:0.00022807335238862983\n",
      "train loss:4.4177202527646937e-05\n",
      "train loss:0.0002861601716447211\n",
      "train loss:0.0015017449607731992\n",
      "train loss:0.0007719922002580748\n",
      "train loss:0.0014062641674118636\n",
      "train loss:0.0005001822448022924\n",
      "train loss:0.00013738628104321228\n",
      "train loss:4.916281622058636e-05\n",
      "train loss:0.00019774674728754123\n",
      "train loss:0.00026098260003922614\n",
      "train loss:0.0007203578810076183\n",
      "train loss:0.0015983346500186846\n",
      "train loss:0.00010500094906425725\n",
      "train loss:0.0018138203956623619\n",
      "train loss:0.0005141989928553883\n",
      "train loss:0.02397526990444672\n",
      "train loss:0.007830033510844357\n",
      "train loss:0.004678558508945432\n",
      "train loss:0.0001255245059524137\n",
      "train loss:0.000182345682270746\n",
      "train loss:0.001160456794787664\n",
      "train loss:9.058322793674233e-05\n",
      "train loss:0.00028484210128376826\n",
      "train loss:0.0008830484036619974\n",
      "train loss:9.67045381185918e-05\n",
      "train loss:0.001678915546676083\n",
      "train loss:0.0012398570421976558\n",
      "train loss:0.00205979840118129\n",
      "train loss:0.00068326623507694\n",
      "train loss:0.0018696264713728087\n",
      "train loss:0.0008152253730681448\n",
      "train loss:1.1758673044160487e-05\n",
      "train loss:2.678962168054809e-05\n",
      "train loss:0.005457490972594924\n",
      "train loss:0.0013232302760546573\n",
      "train loss:0.00021283969755749244\n",
      "train loss:0.0013327243236435917\n",
      "train loss:0.007478348614996303\n",
      "train loss:9.550319333309905e-05\n",
      "train loss:0.0011347107219047844\n",
      "train loss:0.001080123004853631\n",
      "train loss:0.016825069525037845\n",
      "train loss:0.003907519545577223\n",
      "train loss:0.00026946793536624877\n",
      "train loss:0.0004194208017221009\n",
      "train loss:0.00017925706654242274\n",
      "train loss:0.0005355374747680497\n",
      "train loss:0.0006368505911339372\n",
      "train loss:0.0012390472567689883\n",
      "train loss:0.00017223194645386625\n",
      "train loss:0.0007990463466439355\n",
      "train loss:0.00032146721205461506\n",
      "train loss:7.126595454814992e-05\n",
      "train loss:0.00018530420081363773\n",
      "train loss:7.925631510032276e-05\n",
      "train loss:0.0013148638755194329\n",
      "train loss:0.0002646233860969203\n",
      "train loss:0.0002051780066563717\n",
      "train loss:0.00015048139176474702\n",
      "train loss:0.0009299301695638107\n",
      "train loss:0.00028807947566853137\n",
      "train loss:0.0002628776656197047\n",
      "train loss:0.00019477530455639047\n",
      "train loss:0.011992896317268005\n",
      "train loss:5.530438498519261e-05\n",
      "train loss:0.00011968666746179215\n",
      "train loss:0.0005930394509441852\n",
      "train loss:0.0009045721298538783\n",
      "train loss:0.002600573401815253\n",
      "train loss:0.0008653465506934351\n",
      "train loss:0.0004361878835084163\n",
      "train loss:0.0021189272692163953\n",
      "train loss:0.0010048887141133574\n",
      "train loss:3.740310705003857e-05\n",
      "train loss:0.0014737511719655693\n",
      "train loss:0.00047032086117940164\n",
      "train loss:0.0004796708247161103\n",
      "train loss:0.0016757832713169283\n",
      "train loss:0.00019606621945251064\n",
      "train loss:0.0034390693563774006\n",
      "train loss:0.00012259726901437353\n",
      "train loss:0.00035542646270852665\n",
      "train loss:0.0009439085397840844\n",
      "train loss:0.00044591679282156245\n",
      "train loss:0.00017948652402762337\n",
      "train loss:0.0007950120755253342\n",
      "train loss:6.815578924244518e-05\n",
      "train loss:0.0012228000208803196\n",
      "train loss:0.0013951832890482505\n",
      "train loss:0.004085017301876013\n",
      "train loss:0.0009006158781117287\n",
      "train loss:8.459296977928982e-05\n",
      "train loss:0.0014110801964618992\n",
      "train loss:0.006124217345517332\n",
      "train loss:0.0012443161878403558\n",
      "train loss:0.0037485199904635203\n",
      "train loss:2.550228054826971e-05\n",
      "train loss:0.001473688911906857\n",
      "train loss:0.0011818844476083618\n",
      "train loss:0.0004737077749895419\n",
      "train loss:0.0009382609731034716\n",
      "train loss:0.004418148926658046\n",
      "train loss:0.00010554985855625195\n",
      "train loss:0.0003464144319969457\n",
      "train loss:0.0006395265025026109\n",
      "train loss:0.00011959559010146828\n",
      "train loss:0.00033106203382141666\n",
      "train loss:0.0013431846485654547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:9.303096432922189e-05\n",
      "train loss:0.0005113155782076731\n",
      "train loss:0.00016655357502627928\n",
      "train loss:0.00023104664911615947\n",
      "train loss:0.0015717767846361794\n",
      "train loss:0.0014329648654654989\n",
      "train loss:0.00012866655288541672\n",
      "train loss:0.0002211887136956668\n",
      "train loss:0.013923739749139873\n",
      "train loss:0.0011211576099968085\n",
      "train loss:1.1702929754746565e-05\n",
      "train loss:0.007037485103746044\n",
      "train loss:4.498559436600925e-05\n",
      "train loss:7.591294913223989e-05\n",
      "train loss:0.0030834125382144233\n",
      "train loss:0.0003004492123971058\n",
      "train loss:0.000658871497439053\n",
      "train loss:0.0003448219074038026\n",
      "train loss:0.0005740911487365945\n",
      "train loss:0.005311646926736144\n",
      "train loss:0.002367495068689351\n",
      "train loss:0.0006412124721456863\n",
      "train loss:0.0009407650441962302\n",
      "train loss:1.3392802606338708e-05\n",
      "train loss:0.0015885613502997634\n",
      "train loss:0.0009186007886850388\n",
      "train loss:0.0007522948652774176\n",
      "train loss:0.0007779016031745891\n",
      "train loss:0.001591220319800344\n",
      "train loss:0.0013162653301354306\n",
      "train loss:0.00176184917373151\n",
      "train loss:1.4248733068411995e-05\n",
      "train loss:0.0007360075021366327\n",
      "train loss:5.042786349803916e-05\n",
      "train loss:0.0020514022362148935\n",
      "train loss:3.8121136404039454e-05\n",
      "train loss:0.0016913028506591917\n",
      "train loss:0.0006483986096309378\n",
      "train loss:0.022877735581151866\n",
      "train loss:0.0007444926925244695\n",
      "train loss:0.0009292798609641735\n",
      "train loss:0.0007394279794238028\n",
      "train loss:0.002053895889042274\n",
      "train loss:0.0004289698633772782\n",
      "train loss:0.0004597436078692716\n",
      "train loss:0.0006731637898269306\n",
      "train loss:0.0020896898820663454\n",
      "train loss:0.0020475122486368286\n",
      "train loss:0.001941933143647147\n",
      "train loss:0.0004701845382133855\n",
      "train loss:7.895122132348425e-05\n",
      "=== epoch:19, train acc:0.999, test acc:0.99 ===\n",
      "train loss:0.00010307734214020949\n",
      "train loss:0.0011961664480774495\n",
      "train loss:0.00010111530572971965\n",
      "train loss:0.0018791628516537733\n",
      "train loss:0.006240546424043127\n",
      "train loss:0.0006211307641862028\n",
      "train loss:4.025960526364458e-05\n",
      "train loss:0.00037770566385378503\n",
      "train loss:0.00020269112953435166\n",
      "train loss:4.706535729803851e-05\n",
      "train loss:0.0007062418902773964\n",
      "train loss:0.00011880186652921708\n",
      "train loss:0.0009162982933819683\n",
      "train loss:0.00035535759974024444\n",
      "train loss:0.000518394414085125\n",
      "train loss:0.0023284896426263722\n",
      "train loss:0.008562052329363502\n",
      "train loss:0.0001913251376803737\n",
      "train loss:0.001849207199432854\n",
      "train loss:0.0008207255473964386\n",
      "train loss:0.0006804776950965558\n",
      "train loss:0.0023689063795802544\n",
      "train loss:0.0009611927810144852\n",
      "train loss:0.0019477943253987096\n",
      "train loss:0.00013728249450328808\n",
      "train loss:0.0059690789277582305\n",
      "train loss:0.00022278779750922712\n",
      "train loss:8.928829653570863e-05\n",
      "train loss:0.002452439379705116\n",
      "train loss:0.0005669658993457061\n",
      "train loss:0.0021976217581675655\n",
      "train loss:7.884919804592511e-05\n",
      "train loss:3.22924935634236e-05\n",
      "train loss:0.0031331675133157238\n",
      "train loss:0.002697237796875837\n",
      "train loss:0.0005352438222012377\n",
      "train loss:0.001120086271706967\n",
      "train loss:0.0029263523593478172\n",
      "train loss:0.005983157262769356\n",
      "train loss:0.0004661710918084543\n",
      "train loss:8.498054257904272e-05\n",
      "train loss:0.0004286193462303337\n",
      "train loss:0.0014416754251647577\n",
      "train loss:0.0037068651933840637\n",
      "train loss:8.578495133960104e-06\n",
      "train loss:0.0003789740950559423\n",
      "train loss:0.0012565635102803662\n",
      "train loss:0.00037075376157445766\n",
      "train loss:0.0008221394838964152\n",
      "train loss:0.001552030760747239\n",
      "train loss:0.005694390297805069\n",
      "train loss:0.001433061247686572\n",
      "train loss:0.0014306699719044073\n",
      "train loss:0.0003914364465178474\n",
      "train loss:4.1169445410264856e-05\n",
      "train loss:0.00016232362688186627\n",
      "train loss:0.00010235976203333516\n",
      "train loss:0.001060218851796544\n",
      "train loss:0.00020558598635919196\n",
      "train loss:0.0004442277288658557\n",
      "train loss:0.0006795305767076042\n",
      "train loss:0.0001324886969053615\n",
      "train loss:0.0011262939117196223\n",
      "train loss:0.0005220803024458449\n",
      "train loss:0.03425010984558188\n",
      "train loss:0.0001832983905982535\n",
      "train loss:0.0030281735626801055\n",
      "train loss:0.0010412499230784775\n",
      "train loss:0.0027264579055588673\n",
      "train loss:0.0004152124832907615\n",
      "train loss:8.544550507397927e-05\n",
      "train loss:0.0017868814392618451\n",
      "train loss:0.00016099996366357214\n",
      "train loss:0.0016223918751058725\n",
      "train loss:0.00037071065121143824\n",
      "train loss:0.0005971554486654574\n",
      "train loss:0.002271078142956291\n",
      "train loss:0.0012770728742688428\n",
      "train loss:0.00017531757222216275\n",
      "train loss:0.0005718901366031391\n",
      "train loss:0.0012089870617641488\n",
      "train loss:5.4620643677741555e-05\n",
      "train loss:0.001231571293792132\n",
      "train loss:7.762306526758954e-05\n",
      "train loss:9.84197586389129e-05\n",
      "train loss:0.0002259010583549389\n",
      "train loss:6.530532813514935e-05\n",
      "train loss:0.00012513627633493017\n",
      "train loss:0.0006724664088745686\n",
      "train loss:0.0006458849992732582\n",
      "train loss:1.9326979606165284e-05\n",
      "train loss:0.0009201741675451945\n",
      "train loss:0.0009214953023195181\n",
      "train loss:0.00043136332807718487\n",
      "train loss:0.010170444937937\n",
      "train loss:0.00015245588608668462\n",
      "train loss:0.024139566130509157\n",
      "train loss:0.00024161171643719253\n",
      "train loss:0.001114732375636907\n",
      "train loss:0.0007799285025191045\n",
      "train loss:0.00010912883025160248\n",
      "train loss:0.0002447250869365351\n",
      "train loss:0.0002277971679267782\n",
      "train loss:0.000378762001087468\n",
      "train loss:0.003587788685358156\n",
      "train loss:0.015946040324684184\n",
      "train loss:0.0029997089582874843\n",
      "train loss:0.0004461661402193915\n",
      "train loss:0.006322432365944903\n",
      "train loss:0.002661727918495657\n",
      "train loss:7.55712878817211e-05\n",
      "train loss:0.0004044730755201917\n",
      "train loss:0.010660941073372582\n",
      "train loss:0.0015003877641069099\n",
      "train loss:6.14983600589855e-05\n",
      "train loss:0.00026045771240039867\n",
      "train loss:0.0022657527473355994\n",
      "train loss:0.00018242378409032248\n",
      "train loss:0.000291074621996271\n",
      "train loss:0.005529723019281099\n",
      "train loss:0.0017271558791043396\n",
      "train loss:0.00027097381480005017\n",
      "train loss:5.748324114730021e-05\n",
      "train loss:0.03605184623666228\n",
      "train loss:0.00016068086521959572\n",
      "train loss:0.0027944606323019017\n",
      "train loss:0.00023200634837219528\n",
      "train loss:0.00014678003901752567\n",
      "train loss:0.0007129281691851461\n",
      "train loss:0.000102978083860023\n",
      "train loss:0.002126832911726073\n",
      "train loss:0.0009626830897388899\n",
      "train loss:0.0007093129625121107\n",
      "train loss:0.005361191364216783\n",
      "train loss:0.0005285381867110719\n",
      "train loss:0.0014688040463713976\n",
      "train loss:0.0006670490589428867\n",
      "train loss:0.0012768950163106227\n",
      "train loss:0.003306715404916007\n",
      "train loss:0.005563142063957107\n",
      "train loss:0.00026293073846863686\n",
      "train loss:5.177566795602747e-05\n",
      "train loss:0.0016654479179116681\n",
      "train loss:0.0006320379158383998\n",
      "train loss:0.0008704520144587186\n",
      "train loss:0.0011647692266863747\n",
      "train loss:0.0002566767691677676\n",
      "train loss:0.001150334661220347\n",
      "train loss:0.00028066703676494007\n",
      "train loss:0.00010819718768874727\n",
      "train loss:0.0001188041882679731\n",
      "train loss:0.001251038608828963\n",
      "train loss:0.002616218301502116\n",
      "train loss:5.571363548601207e-06\n",
      "train loss:0.0001743785817965289\n",
      "train loss:0.004522857164644007\n",
      "train loss:0.0015447250972978515\n",
      "train loss:0.0019371016865767346\n",
      "train loss:0.00011561531077916825\n",
      "train loss:0.0012378211545147526\n",
      "train loss:0.0006696457015840988\n",
      "train loss:0.00023245217736801\n",
      "train loss:0.000566564115358744\n",
      "train loss:0.003029229792171489\n",
      "train loss:0.00038387957878240287\n",
      "train loss:0.0026073881312083476\n",
      "train loss:0.0003112753448807046\n",
      "train loss:0.005612013253525537\n",
      "train loss:0.00014680337367434457\n",
      "train loss:0.00024176196353960702\n",
      "train loss:0.0006976059137392593\n",
      "train loss:0.009046341758190678\n",
      "train loss:0.00032425014571365034\n",
      "train loss:0.00025211194480653516\n",
      "train loss:0.001436794355494042\n",
      "train loss:0.0003069144393888474\n",
      "train loss:0.000478872133798454\n",
      "train loss:0.0006427381460780691\n",
      "train loss:0.006587314698492433\n",
      "train loss:6.15071855780967e-05\n",
      "train loss:0.00586487078141064\n",
      "train loss:0.0007630435569875776\n",
      "train loss:0.004652088504389331\n",
      "train loss:0.0014529076799890102\n",
      "train loss:0.00042867488177469713\n",
      "train loss:0.0023345240994450613\n",
      "train loss:0.0014552271475086725\n",
      "train loss:0.029809434784460617\n",
      "train loss:0.0024868328832138467\n",
      "train loss:0.0035871937756018716\n",
      "train loss:0.0015139284367599413\n",
      "train loss:0.001534529152168702\n",
      "train loss:0.0027393924427411066\n",
      "train loss:0.002211344550710113\n",
      "train loss:0.0016698180560423559\n",
      "train loss:0.002235974029301632\n",
      "train loss:0.0002283361825029534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0024260520911833726\n",
      "train loss:0.0036261379531194534\n",
      "train loss:0.0020630717319781266\n",
      "train loss:0.0024808853482111617\n",
      "train loss:0.0015563447954172263\n",
      "train loss:0.0008548403422608454\n",
      "train loss:0.0019498282472789898\n",
      "train loss:0.00010308925492212672\n",
      "train loss:0.0014901030191522917\n",
      "train loss:0.0005832956058309157\n",
      "train loss:0.00034865727072288925\n",
      "train loss:0.0015855727969144022\n",
      "train loss:0.00025187018684711673\n",
      "train loss:0.0048757597179379785\n",
      "train loss:0.0010472186846943502\n",
      "train loss:0.0032331986422267445\n",
      "train loss:0.0017897664066170993\n",
      "train loss:0.00027067691004891944\n",
      "train loss:0.00098706442649375\n",
      "train loss:0.00038319395124391734\n",
      "train loss:0.002899981142415833\n",
      "train loss:0.0015596291007918498\n",
      "train loss:4.883593052089655e-05\n",
      "train loss:0.0007318843187593371\n",
      "train loss:0.0018142745412517147\n",
      "train loss:0.001909424874020911\n",
      "train loss:0.005116402463104683\n",
      "train loss:0.00011090511286998928\n",
      "train loss:0.0032944626487215124\n",
      "train loss:0.001118075550465026\n",
      "train loss:0.002197895527684434\n",
      "train loss:0.0003659515702936196\n",
      "train loss:0.0017769136792079865\n",
      "train loss:0.0003419215756559157\n",
      "train loss:0.0012951000781746822\n",
      "train loss:0.002326563199093282\n",
      "train loss:9.572741759212146e-05\n",
      "train loss:0.0023405597790942885\n",
      "train loss:0.0003491849468191635\n",
      "train loss:0.00035309265963890497\n",
      "train loss:2.6409434808732545e-05\n",
      "train loss:0.001586083473486003\n",
      "train loss:0.00022618963360955646\n",
      "train loss:0.0013071419404599232\n",
      "train loss:0.00013224311203675229\n",
      "train loss:0.0009163593004162056\n",
      "train loss:0.0022935904021318763\n",
      "train loss:0.00013079448592404985\n",
      "train loss:0.0009364793882839671\n",
      "train loss:0.0008664593761774141\n",
      "train loss:0.0014644414387454444\n",
      "train loss:0.0002874424525038617\n",
      "train loss:0.00033792076050988073\n",
      "train loss:0.004300878277584382\n",
      "train loss:0.00013576465726019535\n",
      "train loss:0.0001638470435463075\n",
      "train loss:0.0010453697907303176\n",
      "train loss:0.0003316619317882034\n",
      "train loss:0.0005425572161879235\n",
      "train loss:0.003244763875823761\n",
      "train loss:0.004583167584383111\n",
      "train loss:0.000958964647160894\n",
      "train loss:0.00012743463815020577\n",
      "train loss:0.003275999400225951\n",
      "train loss:0.0003708613677511543\n",
      "train loss:0.0012913885252246863\n",
      "train loss:0.00021756126234849017\n",
      "train loss:0.004570087302167813\n",
      "train loss:0.0016909200674467568\n",
      "train loss:0.00233647062513123\n",
      "train loss:0.0006308402529425655\n",
      "train loss:0.00029032683337824514\n",
      "train loss:0.0032520997876625923\n",
      "train loss:0.0003464246369997003\n",
      "train loss:0.0036922780638133966\n",
      "train loss:0.008450694976855312\n",
      "train loss:9.15021304153546e-05\n",
      "train loss:0.003789992196840072\n",
      "train loss:0.00015000134547292338\n",
      "train loss:0.000982867870286052\n",
      "train loss:3.9435836215271057e-05\n",
      "train loss:0.004836558601920694\n",
      "train loss:0.000662624746657945\n",
      "train loss:0.0015681380726952573\n",
      "train loss:0.0016789796040903788\n",
      "train loss:0.0011129192656815733\n",
      "train loss:0.0011580476647798522\n",
      "train loss:0.0009773828773739662\n",
      "train loss:0.0006347851723140963\n",
      "train loss:0.0022850324655932174\n",
      "train loss:0.00040335317379561577\n",
      "train loss:0.0006907852771163232\n",
      "train loss:0.00022752958414635785\n",
      "train loss:0.00016735347609675536\n",
      "train loss:0.0021924888432573357\n",
      "train loss:0.0010996894692470295\n",
      "train loss:4.956330839035685e-05\n",
      "train loss:0.0024357519269676588\n",
      "train loss:0.0005911295634370148\n",
      "train loss:5.476078395928235e-05\n",
      "train loss:0.000239104827096338\n",
      "train loss:0.0013962022910342952\n",
      "train loss:0.00013808853681215373\n",
      "train loss:0.000165711031321794\n",
      "train loss:0.001758221954288213\n",
      "train loss:0.0001485075589912625\n",
      "train loss:0.0002587211310802557\n",
      "train loss:0.00043519784295563516\n",
      "train loss:0.00011495685932129709\n",
      "train loss:0.0004068882611995028\n",
      "train loss:0.0006704002002461871\n",
      "train loss:0.000824158591917898\n",
      "train loss:9.52051348791714e-05\n",
      "train loss:0.0002933825185859779\n",
      "train loss:0.0008739117494439702\n",
      "train loss:0.004321780023159611\n",
      "train loss:0.004523165971158776\n",
      "train loss:0.00010918265262073762\n",
      "train loss:0.00028453193834212474\n",
      "train loss:8.463329834386071e-05\n",
      "train loss:0.006688937176731076\n",
      "train loss:5.802685389342737e-06\n",
      "train loss:0.00038523677998401483\n",
      "train loss:9.760459033343163e-05\n",
      "train loss:0.0007937875262807435\n",
      "train loss:0.0009742528587548787\n",
      "train loss:0.00034978361983872976\n",
      "train loss:0.002023173744507626\n",
      "train loss:0.0014693217468000764\n",
      "train loss:0.0016000376965880972\n",
      "train loss:0.0015324365040427091\n",
      "train loss:0.0013099787312948411\n",
      "train loss:0.00013553237627638608\n",
      "train loss:0.0024538055352571106\n",
      "train loss:0.00042528239932237803\n",
      "train loss:0.00012618501957683748\n",
      "train loss:0.00011868067324351422\n",
      "train loss:0.00021061728015419508\n",
      "train loss:0.0010882201023086706\n",
      "train loss:0.0011512152478293505\n",
      "train loss:0.0005414148461380437\n",
      "train loss:0.0003889201833297299\n",
      "train loss:0.0008188364671858889\n",
      "train loss:0.0011639871205002615\n",
      "train loss:0.00014829595396265326\n",
      "train loss:1.2350041034473524e-05\n",
      "train loss:0.002277406665444266\n",
      "train loss:0.0009742323270680104\n",
      "train loss:0.010011900551032606\n",
      "train loss:0.0037316717571728958\n",
      "train loss:1.2624154632398354e-05\n",
      "train loss:0.0016341842406662071\n",
      "train loss:0.0018133174755884309\n",
      "train loss:0.0006758688275597035\n",
      "train loss:0.020987937710011395\n",
      "train loss:6.759723357231494e-05\n",
      "train loss:0.003552641296807392\n",
      "train loss:0.0009964512955071148\n",
      "train loss:0.00016402426737196046\n",
      "train loss:0.0007951772552464376\n",
      "train loss:0.00026313108442256513\n",
      "train loss:0.0024996366277468237\n",
      "train loss:0.00019389302919060213\n",
      "train loss:0.0002810517762639544\n",
      "train loss:0.0003073856290358592\n",
      "train loss:0.0011746766740460038\n",
      "train loss:0.00014868749007571942\n",
      "train loss:0.0007709399856835449\n",
      "train loss:0.0024005535686342123\n",
      "train loss:0.00040003992892878663\n",
      "train loss:0.0013316560891833676\n",
      "train loss:0.0003969335869602051\n",
      "train loss:0.037435884461846466\n",
      "train loss:0.0009379035544605022\n",
      "train loss:0.00017122073516235453\n",
      "train loss:0.0024125203730682083\n",
      "train loss:0.001266529866340839\n",
      "train loss:0.0006059016114121141\n",
      "train loss:0.0003988293149197677\n",
      "train loss:0.0003822156963958395\n",
      "train loss:0.0014099728211647705\n",
      "train loss:0.0034149677557643297\n",
      "train loss:0.004835979642549808\n",
      "train loss:0.010651053838551933\n",
      "train loss:1.002349772752642e-05\n",
      "train loss:0.00040975389844076954\n",
      "train loss:6.936166597627748e-05\n",
      "train loss:0.002500906213898384\n",
      "train loss:0.00037536758586225285\n",
      "train loss:0.000290499545178872\n",
      "train loss:0.0007414648806343099\n",
      "train loss:0.02407081488981623\n",
      "train loss:0.0001114800017962616\n",
      "train loss:0.0009939197714299746\n",
      "train loss:0.0041176578725201215\n",
      "train loss:0.003479589664815802\n",
      "train loss:0.0019377827996400867\n",
      "train loss:0.0021027711935594404\n",
      "train loss:0.00010627770274560724\n",
      "train loss:0.0013332293633895548\n",
      "train loss:0.0016384680010732232\n",
      "train loss:0.00027873721680416683\n",
      "train loss:0.0009680875441577933\n",
      "train loss:0.0007236956314908824\n",
      "train loss:0.00022204909833016315\n",
      "train loss:0.0004415909118317243\n",
      "train loss:0.0011842617396991672\n",
      "train loss:0.0026090835901401307\n",
      "train loss:0.00032989841452982525\n",
      "train loss:0.003908893291449595\n",
      "train loss:0.0008319973822248565\n",
      "train loss:0.000947802697762292\n",
      "train loss:0.005724790973411275\n",
      "train loss:0.0006953349989254087\n",
      "train loss:0.0005298910772033235\n",
      "train loss:0.0015844801962150077\n",
      "train loss:0.00012659575085920174\n",
      "train loss:0.0017345753140958083\n",
      "train loss:0.0004663730368449058\n",
      "train loss:1.7794383554810342e-05\n",
      "train loss:2.8672260913355123e-05\n",
      "train loss:0.004359068072879714\n",
      "train loss:0.00022305263358041372\n",
      "train loss:8.444047141251784e-05\n",
      "train loss:8.098903322549848e-05\n",
      "train loss:0.0016506147089475052\n",
      "train loss:0.001386221115678171\n",
      "train loss:0.00023376742501454077\n",
      "train loss:0.00047009091963198384\n",
      "train loss:0.01225201394015093\n",
      "train loss:0.005163215842348428\n",
      "train loss:0.00041332654440667\n",
      "train loss:0.00048291302980240736\n",
      "train loss:0.00019018525547286454\n",
      "train loss:0.0022638182838677356\n",
      "train loss:0.0008977449517113037\n",
      "train loss:0.0015175688645313412\n",
      "train loss:0.0007558462814485088\n",
      "train loss:0.0007898236249654406\n",
      "train loss:0.0015526859560519549\n",
      "train loss:0.002465650947186907\n",
      "train loss:0.00010103706575174297\n",
      "train loss:0.00048420689887559895\n",
      "train loss:0.0024809583897795234\n",
      "train loss:0.0004103508380794248\n",
      "train loss:0.00017553771683256295\n",
      "train loss:0.0006211357762785214\n",
      "train loss:0.0009086647557672162\n",
      "train loss:0.001102413199346209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0002199694836188728\n",
      "train loss:0.001766901076325904\n",
      "train loss:0.0019250286375545067\n",
      "train loss:0.0012493726129011256\n",
      "train loss:9.365421907110042e-05\n",
      "train loss:0.0013544155382679882\n",
      "train loss:0.0021551588055310007\n",
      "train loss:0.0003698425722986152\n",
      "train loss:0.00033149777314490074\n",
      "train loss:0.00043121094532159196\n",
      "train loss:0.020515983991758486\n",
      "train loss:0.00032491248760963063\n",
      "train loss:8.953995372888457e-05\n",
      "train loss:0.00010154653660621364\n",
      "train loss:0.000961761648084937\n",
      "train loss:1.726720966302241e-05\n",
      "train loss:0.0002577524770577259\n",
      "train loss:0.0007903263337908903\n",
      "train loss:0.0009572662200065582\n",
      "train loss:0.0007686298381293187\n",
      "train loss:0.0005591055026841306\n",
      "train loss:0.0016824193756464283\n",
      "train loss:0.0006694334831860838\n",
      "train loss:0.00017651857418745837\n",
      "train loss:0.006478255927649907\n",
      "train loss:0.00013798067805274416\n",
      "train loss:0.0001752081926782666\n",
      "train loss:0.00016890506379874158\n",
      "train loss:0.005924933434419627\n",
      "train loss:0.00029522498219868796\n",
      "train loss:0.005872522300552118\n",
      "train loss:0.00015395976267431748\n",
      "train loss:0.004355311545616464\n",
      "train loss:0.0008469145052787192\n",
      "train loss:0.0014542897826385404\n",
      "train loss:0.0007118935555085936\n",
      "train loss:0.006863426787232605\n",
      "train loss:0.008714214284319843\n",
      "train loss:0.004675325136030075\n",
      "train loss:0.00023171384113009533\n",
      "train loss:0.00016577343612707263\n",
      "train loss:0.002591051942334085\n",
      "train loss:0.0027770953621352092\n",
      "train loss:0.0016449802950661055\n",
      "train loss:0.0019430846539900618\n",
      "train loss:0.002127219525753498\n",
      "train loss:0.0010289929703036107\n",
      "train loss:0.0020613137897583355\n",
      "train loss:0.00039536167797666526\n",
      "train loss:0.0003859321441589287\n",
      "train loss:0.0002466861469757374\n",
      "train loss:0.0001912138437322821\n",
      "train loss:0.001253781659786938\n",
      "train loss:0.0005973058815854071\n",
      "train loss:0.004409561685955366\n",
      "train loss:7.06569224927582e-05\n",
      "train loss:0.017491696602635786\n",
      "train loss:0.00717870786777345\n",
      "train loss:0.0016704542883594412\n",
      "train loss:0.0001968140992668573\n",
      "train loss:0.003701053632187864\n",
      "train loss:0.0012834102916138269\n",
      "train loss:0.0019514879094145669\n",
      "train loss:0.0024224355427669673\n",
      "train loss:0.007911127751005245\n",
      "train loss:0.0007972544835004353\n",
      "train loss:0.0031853310878293024\n",
      "train loss:0.0011943095580646617\n",
      "train loss:0.0012362445551176225\n",
      "train loss:0.002308878248366282\n",
      "train loss:0.000652236973225801\n",
      "train loss:0.00010410648212290769\n",
      "train loss:0.0005705424118903307\n",
      "train loss:0.0010977134187877926\n",
      "train loss:0.00013062200331219768\n",
      "train loss:0.0006315224325887657\n",
      "train loss:0.002958515922284225\n",
      "train loss:0.00135381228030311\n",
      "train loss:0.00015732162462342236\n",
      "train loss:0.004057489906414009\n",
      "train loss:0.0006961606152188884\n",
      "train loss:0.0007180925963932972\n",
      "train loss:0.0005559682352800009\n",
      "train loss:0.0008750551846645847\n",
      "train loss:0.0030528867464751815\n",
      "train loss:0.00012861909151874623\n",
      "train loss:0.0004516591735039043\n",
      "train loss:0.002043367702125035\n",
      "train loss:0.0006377558733742949\n",
      "train loss:0.006237190050396655\n",
      "train loss:0.000575511765102769\n",
      "train loss:0.0007312552842716365\n",
      "train loss:0.0013783556982917599\n",
      "train loss:0.0069107571112944546\n",
      "train loss:0.0001141325183347487\n",
      "train loss:0.00023067536322576932\n",
      "train loss:0.001408796292603276\n",
      "train loss:0.0008491688971948431\n",
      "train loss:0.004751304265879352\n",
      "train loss:1.4745923011150916e-05\n",
      "train loss:0.00047578731130191586\n",
      "train loss:0.000838941205101894\n",
      "train loss:0.0031227977556721313\n",
      "train loss:0.0002539218435232887\n",
      "train loss:0.00011005081509564035\n",
      "train loss:0.0007538485235895017\n",
      "train loss:0.003374119941174504\n",
      "train loss:4.5994645768017694e-05\n",
      "train loss:0.003912611736485257\n",
      "train loss:0.0008382742508043722\n",
      "train loss:0.0003764236671554523\n",
      "train loss:0.0016489680719252383\n",
      "train loss:0.0010726348474696787\n",
      "train loss:0.00028912801332161474\n",
      "train loss:0.0023273963624884475\n",
      "train loss:0.0006107824423174732\n",
      "train loss:0.007023907687062314\n",
      "train loss:0.0036445657037846415\n",
      "train loss:0.000484554193320031\n",
      "train loss:3.467214267980616e-05\n",
      "train loss:0.0015092841113249448\n",
      "train loss:0.0005704578834334014\n",
      "train loss:0.0011455167958503282\n",
      "train loss:0.0006995279315985621\n",
      "train loss:0.0093917073528654\n",
      "train loss:0.0016055239940026876\n",
      "train loss:0.00020763143205448597\n",
      "train loss:0.0024837601054816852\n",
      "train loss:0.0016741221890255737\n",
      "train loss:0.000192787045285527\n",
      "train loss:0.0013688383120183827\n",
      "train loss:0.00018107682974639896\n",
      "train loss:0.0008832481049017829\n",
      "train loss:0.0018570442775674265\n",
      "train loss:0.002275509346847089\n",
      "train loss:0.0010494404693024418\n",
      "train loss:0.0005075551269494756\n",
      "train loss:0.000154239083827289\n",
      "train loss:0.000392983555630043\n",
      "train loss:0.0006176476874521311\n",
      "train loss:0.006106748860292792\n",
      "train loss:2.2793886013986832e-05\n",
      "train loss:0.0018592737582118937\n",
      "train loss:0.00012709571709700708\n",
      "train loss:0.0004526573846383352\n",
      "train loss:0.0002211438865659301\n",
      "train loss:0.0018437505496842438\n",
      "train loss:0.000490013131625641\n",
      "train loss:0.0003338231276800238\n",
      "train loss:0.00038765684928687184\n",
      "train loss:0.0029192128341398844\n",
      "train loss:0.00028895555154144546\n",
      "train loss:0.0005351024478845044\n",
      "train loss:1.4464845477010506e-05\n",
      "=== epoch:20, train acc:1.0, test acc:0.987 ===\n",
      "train loss:0.0002732872661796007\n",
      "train loss:0.0016153531568868598\n",
      "train loss:0.00012791671396884162\n",
      "train loss:1.9995193901620083e-05\n",
      "train loss:0.0005116896904638803\n",
      "train loss:0.000157081024250866\n",
      "train loss:0.0006112477006156001\n",
      "train loss:0.001329183341876308\n",
      "train loss:0.002959255126101949\n",
      "train loss:0.001115680461146754\n",
      "train loss:0.0012669431951631142\n",
      "train loss:0.0026431718849804103\n",
      "train loss:0.0015103779599078976\n",
      "train loss:0.0054521023252821176\n",
      "train loss:0.0037729063239121635\n",
      "train loss:0.000811787112432351\n",
      "train loss:0.0005500959001677017\n",
      "train loss:0.0007188309857042611\n",
      "train loss:0.0012509901158522835\n",
      "train loss:0.0005402013635588204\n",
      "train loss:0.000685312264677459\n",
      "train loss:0.0002867625037257213\n",
      "train loss:0.0012845186310712472\n",
      "train loss:0.0009558326387467315\n",
      "train loss:6.411854346707782e-05\n",
      "train loss:0.0001557405694554648\n",
      "train loss:0.0010615062614387715\n",
      "train loss:0.0009984564903851288\n",
      "train loss:0.00013340407156188015\n",
      "train loss:0.0033629937150248678\n",
      "train loss:0.0019232524492701335\n",
      "train loss:0.0004482554676843403\n",
      "train loss:0.0003846248188749062\n",
      "train loss:7.396766810902166e-05\n",
      "train loss:0.001476849576151266\n",
      "train loss:0.001942928173060087\n",
      "train loss:0.0011069089130730687\n",
      "train loss:0.0021037426650677175\n",
      "train loss:7.938657518942902e-05\n",
      "train loss:0.0011902016141105997\n",
      "train loss:0.0009374108425059982\n",
      "train loss:1.2965207118509623e-05\n",
      "train loss:0.0003054132880566875\n",
      "train loss:0.0002676356084713395\n",
      "train loss:0.0012896835200832649\n",
      "train loss:5.271012844236005e-06\n",
      "train loss:0.0010429662998155424\n",
      "train loss:0.0010497077890100478\n",
      "train loss:0.002302014485655467\n",
      "train loss:0.0008634125675178338\n",
      "train loss:0.0019825470864056308\n",
      "train loss:0.003197332226549276\n",
      "train loss:6.192680333839468e-05\n",
      "train loss:0.0002972585043207806\n",
      "train loss:0.001732091483359343\n",
      "train loss:0.0009789997455631712\n",
      "train loss:0.0008561668496354695\n",
      "train loss:0.0018776596321165668\n",
      "train loss:0.0008978580234409035\n",
      "train loss:0.00016609099676104762\n",
      "train loss:0.0013457720794658543\n",
      "train loss:0.0008599699342469592\n",
      "train loss:0.00045184121324603983\n",
      "train loss:0.00044257776586301427\n",
      "train loss:0.0016758243973123202\n",
      "train loss:0.0015951315465527233\n",
      "train loss:0.0003527663315142886\n",
      "train loss:0.00016507660878256898\n",
      "train loss:0.0001775032017167741\n",
      "train loss:0.0019405771463345543\n",
      "train loss:0.00020261846079609318\n",
      "train loss:0.0003268533628088227\n",
      "train loss:0.004139112802783355\n",
      "train loss:2.092346526824713e-05\n",
      "train loss:5.182938128291374e-05\n",
      "train loss:0.0005322228319470078\n",
      "train loss:0.00011351629216676303\n",
      "train loss:0.001074403264045745\n",
      "train loss:0.0007726152748397538\n",
      "train loss:0.0008445097042298511\n",
      "train loss:0.00038982604072684455\n",
      "train loss:0.0009779907081431994\n",
      "train loss:0.0009557451510056966\n",
      "train loss:0.0009320333662302374\n",
      "train loss:0.0005469887173837099\n",
      "train loss:0.000229343988514427\n",
      "train loss:0.0006652284628947101\n",
      "train loss:0.01274456715730528\n",
      "train loss:0.0005018974409206873\n",
      "train loss:8.11058295909167e-05\n",
      "train loss:0.0008162809131408104\n",
      "train loss:7.314993044760719e-05\n",
      "train loss:7.187172383297449e-05\n",
      "train loss:0.00017525098060410243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0017337599638001233\n",
      "train loss:0.00034773514161977987\n",
      "train loss:0.0004926617995894125\n",
      "train loss:0.001151641960759134\n",
      "train loss:0.0005125488204738768\n",
      "train loss:0.00036144737040932163\n",
      "train loss:0.0011627117829582283\n",
      "train loss:0.0005648908284244524\n",
      "train loss:0.00010167843391299662\n",
      "train loss:0.004220202902925143\n",
      "train loss:0.0003912013171911597\n",
      "train loss:0.004438729417985232\n",
      "train loss:0.0002493754161902346\n",
      "train loss:0.0022889589817365634\n",
      "train loss:0.004479872877170862\n",
      "train loss:3.5368085077755825e-06\n",
      "train loss:0.0024775428154919037\n",
      "train loss:0.0027964263051906187\n",
      "train loss:0.007835216281208767\n",
      "train loss:0.007604458272270735\n",
      "train loss:0.0013082088339189824\n",
      "train loss:0.0018410463355328435\n",
      "train loss:6.604949297277045e-05\n",
      "train loss:0.0008432986322146997\n",
      "train loss:0.0024634797900692264\n",
      "train loss:0.004384218102944706\n",
      "train loss:0.0008971476570646753\n",
      "train loss:7.82177016632174e-05\n",
      "train loss:0.00107765655230642\n",
      "train loss:0.0017046989975967506\n",
      "train loss:0.002606388191812065\n",
      "train loss:0.0010528214113460586\n",
      "train loss:6.646293460216102e-05\n",
      "train loss:0.0007988408224475323\n",
      "train loss:0.0021626830005114185\n",
      "train loss:0.001010381380454132\n",
      "train loss:0.0030108450771619026\n",
      "train loss:0.00035460041737070007\n",
      "train loss:0.0015553254384817988\n",
      "train loss:0.00010215650298249413\n",
      "train loss:9.002952055441911e-05\n",
      "train loss:0.001802180376389734\n",
      "train loss:0.0009222253914757955\n",
      "train loss:0.006509107466312169\n",
      "train loss:0.0003220322582619844\n",
      "train loss:0.00012113065459624192\n",
      "train loss:0.0035742977365873863\n",
      "train loss:0.0015537956781062864\n",
      "train loss:0.0007404277790040223\n",
      "train loss:0.00020717947298421016\n",
      "train loss:0.00015249995436723404\n",
      "train loss:0.00017240245549906487\n",
      "train loss:0.00012347066427486795\n",
      "train loss:0.002798970627641841\n",
      "train loss:0.0007692971461504243\n",
      "train loss:0.003384314978140337\n",
      "train loss:0.00020844455842636994\n",
      "train loss:0.0005303015386742542\n",
      "train loss:2.009998457112035e-05\n",
      "train loss:0.029565520779683007\n",
      "train loss:0.0004133705021576071\n",
      "train loss:0.01719523756959811\n",
      "train loss:0.00012972004766965154\n",
      "train loss:0.00024059477105635208\n",
      "train loss:3.672988807086845e-05\n",
      "train loss:0.00017462928970692757\n",
      "train loss:9.099544962238567e-05\n",
      "train loss:0.0023878424163036073\n",
      "train loss:7.118830932418592e-05\n",
      "train loss:0.00018079866057923666\n",
      "train loss:0.0008077326758052701\n",
      "train loss:0.0004493323586184273\n",
      "train loss:0.0003307210277191785\n",
      "train loss:0.0005921626335303067\n",
      "train loss:0.004391944760522615\n",
      "train loss:0.00018317281609258744\n",
      "train loss:0.000754668143749271\n",
      "train loss:0.0037068736332635257\n",
      "train loss:0.0008950072615465435\n",
      "train loss:0.002124503269140689\n",
      "train loss:0.0003840329648403256\n",
      "train loss:0.00019017737547711823\n",
      "train loss:0.0005182901467682383\n",
      "train loss:0.0010976743337676683\n",
      "train loss:0.0014981502084834369\n",
      "train loss:0.0016743053449369953\n",
      "train loss:0.0009667171757118265\n",
      "train loss:0.0002742342435434736\n",
      "train loss:0.0003918295284941649\n",
      "train loss:0.00029688674982756853\n",
      "train loss:0.00011732802357784\n",
      "train loss:0.0030571277721372636\n",
      "train loss:0.004309457244047553\n",
      "train loss:0.0004543057024567157\n",
      "train loss:0.01602639710143954\n",
      "train loss:0.0013257327256899231\n",
      "train loss:4.1547809925469974e-05\n",
      "train loss:4.873098737271817e-05\n",
      "train loss:0.00030577203988410155\n",
      "train loss:0.0019771894454084895\n",
      "train loss:0.0006445450656250126\n",
      "train loss:0.0020294564117857533\n",
      "train loss:0.000834986273310905\n",
      "train loss:0.002975162728604355\n",
      "train loss:0.0015960569066347818\n",
      "train loss:0.0007104953671915867\n",
      "train loss:0.0018056197120787626\n",
      "train loss:0.00022989202165330864\n",
      "train loss:0.0022592004383154194\n",
      "train loss:0.0005579439928407915\n",
      "train loss:0.001996557416226753\n",
      "train loss:0.0013215897886557065\n",
      "train loss:6.704026460240097e-05\n",
      "train loss:0.0019077914826199146\n",
      "train loss:0.0004695391425104828\n",
      "train loss:0.001799671784894189\n",
      "train loss:0.0002058476608673309\n",
      "train loss:0.0007844298204775016\n",
      "train loss:0.0029209449537034144\n",
      "train loss:0.000417399698298468\n",
      "train loss:0.0004104807047520915\n",
      "train loss:0.001686211029618246\n",
      "train loss:0.00045851822303577143\n",
      "train loss:0.0010064686343545918\n",
      "train loss:0.0005549460749993514\n",
      "train loss:0.0004047227622588054\n",
      "train loss:0.001409348260440889\n",
      "train loss:0.0025640746285693185\n",
      "train loss:0.0025924789112759094\n",
      "train loss:0.00021810491576691363\n",
      "train loss:0.0001226975694879275\n",
      "train loss:0.0029919588652461155\n",
      "train loss:0.001309806462440633\n",
      "train loss:0.00025068552756364815\n",
      "train loss:0.0022048859638973705\n",
      "train loss:0.0012687769665374051\n",
      "train loss:9.96597986733321e-05\n",
      "train loss:0.0011051232101208209\n",
      "train loss:0.0028377464042330107\n",
      "train loss:0.001305294462219906\n",
      "train loss:0.00023867046262204285\n",
      "train loss:0.0018118869913809545\n",
      "train loss:0.0007534187689968684\n",
      "train loss:0.00016937329770155948\n",
      "train loss:0.00032560970358103646\n",
      "train loss:0.00010829606598985493\n",
      "train loss:0.0003824425426240538\n",
      "train loss:0.00012572055163216126\n",
      "train loss:0.00012399390673339781\n",
      "train loss:3.828121556575234e-05\n",
      "train loss:0.00047049044878947455\n",
      "train loss:0.0008223093353965015\n",
      "train loss:0.0007852707411799024\n",
      "train loss:0.001988668097297008\n",
      "train loss:0.0013112915290440035\n",
      "train loss:0.0015284511411490925\n",
      "train loss:0.00014570977579871547\n",
      "train loss:0.0004515671292158894\n",
      "train loss:5.434458718278274e-06\n",
      "train loss:2.11868324450654e-05\n",
      "train loss:0.00023020920702133835\n",
      "train loss:0.004169361167966128\n",
      "train loss:0.0008994534352839323\n",
      "train loss:0.000804461265060525\n",
      "train loss:2.955807437656276e-05\n",
      "train loss:0.0008030585312909649\n",
      "train loss:0.00046062306141129376\n",
      "train loss:0.0030887434717545886\n",
      "train loss:0.0006816475862238809\n",
      "train loss:0.00015581473448085891\n",
      "train loss:0.00044664496053126347\n",
      "train loss:0.00011282100028133222\n",
      "train loss:0.0012101266722789874\n",
      "train loss:0.0011491465046612021\n",
      "train loss:0.00019738022556812587\n",
      "train loss:0.0007308909497447436\n",
      "train loss:0.00017576363310180956\n",
      "train loss:0.00010782555981375292\n",
      "train loss:0.0011941564651641202\n",
      "train loss:8.267476997084918e-05\n",
      "train loss:0.0024442640283358235\n",
      "train loss:0.0011580003842062538\n",
      "train loss:0.0015374433638014598\n",
      "train loss:0.0002996490612050389\n",
      "train loss:0.0004450962979101715\n",
      "train loss:0.0052799974650758665\n",
      "train loss:0.0008655368102896814\n",
      "train loss:0.00013706761385025843\n",
      "train loss:3.195261694015033e-05\n",
      "train loss:0.004929479235652402\n",
      "train loss:0.00022723437506020047\n",
      "train loss:0.00023635352029031337\n",
      "train loss:0.0002986789987447869\n",
      "train loss:0.0024568720832020678\n",
      "train loss:2.8033257863019607e-05\n",
      "train loss:0.00014293384166296446\n",
      "train loss:4.780055055170316e-05\n",
      "train loss:0.0007564330673056088\n",
      "train loss:0.0009605558427036048\n",
      "train loss:0.00018122715684808\n",
      "train loss:0.0001418989104830382\n",
      "train loss:0.001156378475793688\n",
      "train loss:0.001040322669593632\n",
      "train loss:0.0006857125862434987\n",
      "train loss:0.00018484099008643238\n",
      "train loss:0.000920190025338994\n",
      "train loss:0.00015907214098515677\n",
      "train loss:0.00012624168935462994\n",
      "train loss:0.0006949783617044834\n",
      "train loss:0.003611362501628416\n",
      "train loss:0.0017347907867158634\n",
      "train loss:0.0028009717387899435\n",
      "train loss:0.00019807877478478277\n",
      "train loss:0.00010039524546818071\n",
      "train loss:5.055179173990162e-05\n",
      "train loss:0.0006968057944954031\n",
      "train loss:0.000476715710500453\n",
      "train loss:0.0003234067976629017\n",
      "train loss:0.000570676202897637\n",
      "train loss:0.00018346217908648285\n",
      "train loss:0.00022647721997742567\n",
      "train loss:9.949610715202164e-05\n",
      "train loss:0.00023744581644630637\n",
      "train loss:0.01746499504247475\n",
      "train loss:0.00025744486201471006\n",
      "train loss:0.0004230862258510746\n",
      "train loss:0.00044908210123064724\n",
      "train loss:0.0005185679898156866\n",
      "train loss:4.5576083504828e-05\n",
      "train loss:0.0005265145479168594\n",
      "train loss:0.0005646354734763991\n",
      "train loss:7.683866088982847e-05\n",
      "train loss:0.0006664343031797213\n",
      "train loss:0.00016215549664367438\n",
      "train loss:0.00017663292659728588\n",
      "train loss:0.0006975152453420682\n",
      "train loss:8.250931467195134e-05\n",
      "train loss:0.0017547317077742104\n",
      "train loss:0.0012215879033176244\n",
      "train loss:0.0023705488249952346\n",
      "train loss:0.00017180630082133246\n",
      "train loss:0.0014697257105399715\n",
      "train loss:0.00022805707131496507\n",
      "train loss:0.002095516887853178\n",
      "train loss:6.176156679721289e-05\n",
      "train loss:0.0006728208624017995\n",
      "train loss:0.0018683865475132041\n",
      "train loss:0.0007528635460959501\n",
      "train loss:0.00011799101821746644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00018621396606397598\n",
      "train loss:0.0006488953520687213\n",
      "train loss:0.00014698429659946492\n",
      "train loss:0.0008605589223426846\n",
      "train loss:0.000478654552754963\n",
      "train loss:0.00045391177714199316\n",
      "train loss:0.00011854268767511967\n",
      "train loss:0.00030379713429592715\n",
      "train loss:0.00039384842613955444\n",
      "train loss:0.0001118241345081082\n",
      "train loss:0.0006645520898134572\n",
      "train loss:1.5533247731925776e-06\n",
      "train loss:0.0024513355136764627\n",
      "train loss:0.0010281798954152527\n",
      "train loss:0.0004986524394369365\n",
      "train loss:0.0005655155663834742\n",
      "train loss:0.00030122248514129164\n",
      "train loss:0.0015358339200018257\n",
      "train loss:0.000169980826471391\n",
      "train loss:7.089655813270964e-05\n",
      "train loss:0.014002802434538853\n",
      "train loss:0.00039360544428788426\n",
      "train loss:0.000401800695980722\n",
      "train loss:0.0005831342579910106\n",
      "train loss:0.0005946503646414514\n",
      "train loss:0.0017948559239379235\n",
      "train loss:0.00014932687835855643\n",
      "train loss:0.00021822839591695967\n",
      "train loss:0.00013170892531385296\n",
      "train loss:0.00021461242467681301\n",
      "train loss:0.004307978129063719\n",
      "train loss:0.00017143642315760305\n",
      "train loss:0.0011790357401868122\n",
      "train loss:0.0013334849200178447\n",
      "train loss:0.00019874791619238605\n",
      "train loss:0.00020441105094699791\n",
      "train loss:0.00028698049196349934\n",
      "train loss:0.014156647011714065\n",
      "train loss:0.0027815677504170163\n",
      "train loss:0.00019416564786546028\n",
      "train loss:0.0006165045727106822\n",
      "train loss:8.089936926588117e-06\n",
      "train loss:0.0013508839670966302\n",
      "train loss:0.0018560768053445355\n",
      "train loss:0.0009658531353005716\n",
      "train loss:0.0017648988365488382\n",
      "train loss:0.003858485008447186\n",
      "train loss:0.005030134360579602\n",
      "train loss:0.00010418415905305151\n",
      "train loss:1.119348846886745e-05\n",
      "train loss:0.00014533834656727229\n",
      "train loss:0.0002982481706259295\n",
      "train loss:0.0007594452495449547\n",
      "train loss:0.0030695384762131307\n",
      "train loss:0.0012491491414440693\n",
      "train loss:0.0007837527698924753\n",
      "train loss:0.007819077086724137\n",
      "train loss:0.0005172646374759931\n",
      "train loss:0.0002099079133047222\n",
      "train loss:0.00016603879147652155\n",
      "train loss:0.0011554525128471894\n",
      "train loss:0.0004151490823854826\n",
      "train loss:0.00015637041870053255\n",
      "train loss:0.00034987465191689576\n",
      "train loss:0.0009735949781400166\n",
      "train loss:0.00032782536310738407\n",
      "train loss:0.000250251435213761\n",
      "train loss:0.00022315530709242842\n",
      "train loss:0.0021790898531340664\n",
      "train loss:0.0015580227137522453\n",
      "train loss:0.003831919722674495\n",
      "train loss:0.0009443111707621798\n",
      "train loss:0.0011368494118060874\n",
      "train loss:0.0009712772768272397\n",
      "train loss:0.001150705699671265\n",
      "train loss:0.00022005933798163247\n",
      "train loss:7.78193382752689e-05\n",
      "train loss:0.00019699220085534313\n",
      "train loss:0.0004946245422583493\n",
      "train loss:0.0026334554771175384\n",
      "train loss:0.002107286231016626\n",
      "train loss:0.00014053946204380184\n",
      "train loss:6.387783799632634e-05\n",
      "train loss:0.00063675549591816\n",
      "train loss:0.0010655570759536969\n",
      "train loss:0.00011099796126775723\n",
      "train loss:0.00042768417155801075\n",
      "train loss:0.0007362698977753533\n",
      "train loss:0.0008991741222717723\n",
      "train loss:0.0001282495969725993\n",
      "train loss:0.0009221870381598686\n",
      "train loss:0.0058227719468112405\n",
      "train loss:0.0007771101750786518\n",
      "train loss:0.001764111778331653\n",
      "train loss:0.00036398927842435904\n",
      "train loss:0.00013732373879898964\n",
      "train loss:0.0004899024532587136\n",
      "train loss:0.0014523958275085482\n",
      "train loss:0.0012901554266765863\n",
      "train loss:0.0012694500249357116\n",
      "train loss:0.0023973463438791355\n",
      "train loss:0.00038690885171886844\n",
      "train loss:0.0013853392967691472\n",
      "train loss:0.002386122712651582\n",
      "train loss:0.004889528180439752\n",
      "train loss:0.0008991071604746413\n",
      "train loss:0.0007724989668116348\n",
      "train loss:0.0022062534465545156\n",
      "train loss:0.0018624916406477085\n",
      "train loss:3.1510658414403695e-05\n",
      "train loss:0.00012935587890472824\n",
      "train loss:0.0009432979835896955\n",
      "train loss:0.004874999129689042\n",
      "train loss:0.001864834071417669\n",
      "train loss:0.003329574376279385\n",
      "train loss:0.0019004743003198724\n",
      "train loss:0.00015583259392562578\n",
      "train loss:0.00014717292117939052\n",
      "train loss:0.0003249445073546242\n",
      "train loss:0.0005860252773921765\n",
      "train loss:0.0028760371982006487\n",
      "train loss:9.70636375041025e-07\n",
      "train loss:0.0017837947499411049\n",
      "train loss:0.0007399676854467671\n",
      "train loss:0.002595034113042625\n",
      "train loss:0.004985822956725474\n",
      "train loss:0.004203849799643446\n",
      "train loss:0.0016985155333136518\n",
      "train loss:0.0003045419969237586\n",
      "train loss:0.0013419031024112865\n",
      "train loss:0.015987274860651237\n",
      "train loss:0.000343483688935727\n",
      "train loss:0.001812407805345719\n",
      "train loss:0.002249381973563276\n",
      "train loss:7.529978257020548e-05\n",
      "train loss:0.0007560372989001235\n",
      "train loss:0.0007469127066191908\n",
      "train loss:0.0004903420745863433\n",
      "train loss:0.00010297194906344585\n",
      "train loss:0.004933857245556446\n",
      "train loss:0.001569967656488197\n",
      "train loss:0.0007231127756846069\n",
      "train loss:0.026836814332458988\n",
      "train loss:0.00032309488221403594\n",
      "train loss:0.002334293371911729\n",
      "train loss:0.005097228456018356\n",
      "train loss:9.345965362398172e-05\n",
      "train loss:0.0008807727798438556\n",
      "train loss:3.7373631233110144e-05\n",
      "train loss:0.0007348669127641848\n",
      "train loss:0.00020176225293182593\n",
      "train loss:0.0030899670977871073\n",
      "train loss:0.006211706897074595\n",
      "train loss:0.01229534945546502\n",
      "train loss:0.0004429412479694299\n",
      "train loss:0.0027108818265843887\n",
      "train loss:0.00283497390140683\n",
      "train loss:0.000583992752435742\n",
      "train loss:0.001698122465650613\n",
      "train loss:0.0004856653644112896\n",
      "train loss:0.01234298064397476\n",
      "train loss:8.442398261960866e-05\n",
      "train loss:0.0027763630377591227\n",
      "train loss:0.000508040709173656\n",
      "train loss:0.0014043139884441056\n",
      "train loss:0.00033914415365966246\n",
      "train loss:9.878402860811807e-05\n",
      "train loss:0.001911246189689786\n",
      "train loss:0.0021278949766482397\n",
      "train loss:0.0003642043628153984\n",
      "train loss:5.981598056176614e-05\n",
      "train loss:0.0037985790006104412\n",
      "train loss:0.0012186796107312816\n",
      "train loss:0.0011529789305304615\n",
      "train loss:9.617240580416076e-05\n",
      "train loss:0.0015536128541119554\n",
      "train loss:0.02998401433351794\n",
      "train loss:0.001221317994590629\n",
      "train loss:0.00015842073233822488\n",
      "train loss:0.0004481632002321408\n",
      "train loss:0.00015808600661351195\n",
      "train loss:0.0013735643435610378\n",
      "train loss:6.0194980995046216e-05\n",
      "train loss:6.158035964494627e-05\n",
      "train loss:6.306480874828155e-05\n",
      "train loss:0.0004379192974049687\n",
      "train loss:0.00027496573226337456\n",
      "train loss:0.0037108695132513584\n",
      "train loss:0.000386417214297942\n",
      "train loss:0.00021774023656412467\n",
      "train loss:0.0019966012532252908\n",
      "train loss:0.0006027938770699827\n",
      "train loss:0.0006389078767196837\n",
      "train loss:0.0004946317248461909\n",
      "train loss:0.001436368898086755\n",
      "train loss:4.6167175502993086e-05\n",
      "train loss:0.0022804682677262356\n",
      "train loss:0.0001838351932750683\n",
      "train loss:0.001946696057259897\n",
      "train loss:0.0039189068141075225\n",
      "train loss:0.0006057960362398898\n",
      "train loss:0.0020361265973767393\n",
      "train loss:0.0018226768984393289\n",
      "train loss:0.00039498076523840456\n",
      "train loss:0.0009608351842816541\n",
      "train loss:0.000608397192811648\n",
      "train loss:0.004462852058392095\n",
      "train loss:0.0021506550518106\n",
      "train loss:0.0011414750969289387\n",
      "train loss:5.6812539141605225e-05\n",
      "train loss:0.0015222994626742836\n",
      "train loss:0.0002813224242311462\n",
      "train loss:0.0002506439689721727\n",
      "train loss:0.005361510271746747\n",
      "train loss:0.003374692351627137\n",
      "train loss:0.002296725889360475\n",
      "train loss:0.004345992668135977\n",
      "train loss:0.00017609588309696337\n",
      "train loss:0.0015207181010239948\n",
      "train loss:0.0014425885864065998\n",
      "train loss:0.0002324789837276033\n",
      "train loss:0.003440218808193105\n",
      "train loss:0.0002477594920564839\n",
      "train loss:0.004218230120577534\n",
      "train loss:0.0013220218976795332\n",
      "train loss:0.0017634898965504548\n",
      "train loss:0.0010797090140656814\n",
      "train loss:0.0004821360255874836\n",
      "train loss:0.00016040247408384607\n",
      "train loss:0.0017267573864895816\n",
      "train loss:0.0022224420317151082\n",
      "train loss:0.0023161160475744643\n",
      "train loss:0.00033204108953833013\n",
      "train loss:3.4833259391437695e-05\n",
      "train loss:0.0002319027212632012\n",
      "train loss:0.00024564942369453455\n",
      "train loss:0.0004738165177077152\n",
      "train loss:0.00014004417966850545\n",
      "train loss:0.004829129330931983\n",
      "train loss:0.00011743603345807926\n",
      "train loss:0.0020894472238275493\n",
      "train loss:5.701902655996583e-05\n",
      "train loss:0.0009013891996484563\n",
      "train loss:0.0023626689462710676\n",
      "train loss:0.0007759070691233934\n",
      "train loss:0.00013244341248370273\n",
      "train loss:2.4050090429083928e-05\n",
      "train loss:0.0017376190009456836\n",
      "train loss:0.000248525241832962\n",
      "train loss:4.9009996479141286e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0009657884661573479\n",
      "train loss:0.0010219169883559176\n",
      "train loss:0.00544189610277092\n",
      "train loss:0.0020236374230279772\n",
      "train loss:0.00017871017430528099\n",
      "train loss:0.0015086979854860374\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9887\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAmYklEQVR4nO3de5RcZZnv8e9T1dX3TnenO+GSIERkuKgjYA+jAo4OoyToADpzHHDwOI5jnFHm6FEzwhIRmVlLlHMYhzMKMjOMilcEBUajXBR1eRShCfdrAgdMJyR9Sfp+rarn/LF3J9XVVd3VneyqTu/fZ6VW73r3u2s/tVO1n9qX933N3RERkfhKVDoAERGpLCUCEZGYUyIQEYk5JQIRkZhTIhARiTklAhGRmIssEZjZjWbWbWaPF5lvZnatmW0zs0fN7NSoYhERkeKiPCL4KrB+jvkbgOPCx0bgughjERGRIiJLBO7+S2DPHFXOA77ugfuAFjM7Iqp4RESksKoKrnsNsD3neVdY9lJ+RTPbSHDUQENDw2tPOOGEsgS4XPSPTrFrcJypTJZUMsHhK2ppqU/FYv2+6zEsm55dnqjCDn/14l4TyGR99sNnlw2NT1Gs7X5VwjCM8N++vzPKALOwLJxeqJGJdNEYUskE7o578L6yJfY0YEAyYbMftn+6Kvw7OpmhZ2hiRgwGtDZUU1uVIJOFtGfJZJ1s1knnbcO5IjIgYYYZJBJGwoyEEf4Npo8Y30YVmVnLpkmys/YVwXt33/f+g+fgONmcebn1FuJEe7Ho+p/yoxf0Wke21NHWUL3ACAIPPvhgr7uvKjSvkomgZO5+A3ADQEdHh3d2dlY4okPHbQ/t4NLvP0b71P4PYiqV5LJ3vprzT1kT+frHP/dyaif6ZpfXtFF76fOLft1s1hmaSDM4NkX/6BQDY8Gjf2xy3/TA6BRXPXZm0dc4s/4LC1wnDI5NMTQxO7FMSwCN1Uma61I016W4ae9FrLKBWfV6vJlrXvPDcGcHmWyWjId/ZySXmWWL8cALe4vO+7NT11JdZVQnE1RXhY9kcv90VYKacF4yYQxPpIPtHG7zwZxtPl02NB5sn3T42FLzd0W3wR9MXEcCWFlTtW+bNdelaKnfP90cTjfVpkhnsoxOZhifyjA6mWFsKsPYZPgIy4J5acamsoxPZbh3+Lyi7/+PG7+c874TBadrcp4nEwmqEkYiTHpVySDhTJfl/k3iVPs45//4tKLr//W7f4klq2e8zlzJtbkuRUPN4nbbZvZisXmVTAQ7gKNynq8Ny2QR3J3JTHbfF2JsMvhSnHH763kqOQDJmfV7b2/m+sF7mUxng0cm+Dsx43lmxrzJjIc7pbwdljuZzMxfxOnw190TidlJAKB2oo9XfeZOEgZVyURJXwKAwfH9O6C59ov1VVnW1E7Ouc02tmxZ0DY2M6praqipraO2to66unrq6+upr6unob6BxoZ6mhoaqK6pg6pqSNbAP83eAQKssgE+d/YamBrNeYzB5OjMssmwfGoEMlNQvxIaD5v5aGiHRLLgegD6rjiaNvpnl9NC27uK7hsWLZN1BkcnGRgZZWh4hFU3Fd8GD//NKhqroQqHbBo8A9nRIOvue56GbAY8G2TahR5M3lp81s/O7i39dTwLkyMwMbT/MTwEk0Mzy3If8xw/vOFbJ0CiClINkKoLHtXT0/XBo7o+fN4Ar3onvOx1pcdcokomgjuAi83sO8AfAgPuPuu00CHv6uNgpHt2ecNq2LR1VrG7Mzg6QU/3S+zp2clw3y5G+3czNdhDZnyQwWwNA9laBjK17M3U0peuYU+6ht7JFINexzjV7D+pAC/UFv4StjPAVT9+GoCEkfMrKBn8AirwC6muOrF/Z21GMhn+KirwayjlaVZk++HROTbN0feR8QRpkqTdyHiSNEaaJBk3pjwon/IEGYJTGG0rxmlbOUqrjdDMCI0+REN2mLrMENVTA6QmB0lM9GOTw8HP0Tm8Z+c/zl0hale/vPS6iRQkU0FyyGcJaFgFjavD5HB4zvTqgkkACMpf+FVO8gkTzoyElFM2NQbpcUhPQmYC0hOQmZz1N5meoDUzSWsJJ1FavvGW0rdBFG59/yIXNKhpmvmoboSmI6Bmxczyuz9d/GX++LKcZJ/7gyDc5mN7Z5Yd8fuHViIws28DbwLazawL+AxhLnf364HNwDnANmAUeF9UsVRUoSQQlj/29U+QHe7BxvqonthD/VQ/TdlBmhmm2RZwGsCAmmAya0mmqhrIVDWSqW6EwnkAgGff/jzJ6nqSNY37f4Hk/vrILauqDRYa74eh3TC8G4a7w7+79k9Pzxub6z6BwIbfXVP6eywkWQN1reGjBVYcvX+6rhVqW+DHm4ovf/ECTzG6Bzu8zETOznCuneIE/Oyfir/ehi+Ev/pyt339/rLcX4bJ8Gfw1Nj+bT+0K+f/Ief/YPeTweeuwLWRWb76tuLzkjV5cdQFn4NkdbDTq28LpqtqgrrTR0H5f+faEV7w7eAXcSIR/LVk+DwZPHKfW3JxF0n+taP4vIV+Bqobgp17qiGIuRRzvf83zvH5LKPIEoG7XzjPfAc+HNX6K8nd2TkwzrbtL/FHc9Q76bl/Zy9NDCaaGa1qobfhFXTXtZFobKd6xWrqWw5jRdvhNLcfTqppdfABnByFicECh6FBWWJiiJrJ4f3lA88WXX/1PZct4F1Z8GUstHNJ1kBTeJqi7Vg4+g37fo3yw48Wf8lNz8889M+mg8PvGc8z4XQGcKhtDnbwdS3Bjmk+cyWC9uPmX/5AzZUI/vCDC3+9VB20HhM85pLNBr8mh3fBdW8oXu+9/1U4+VTVQfIg7R7m2hGecM7BWcdileMzcAg4JC4WL2WD41M8s2uIp3cN8cyuQXbt+B1ren7BmZn7OTPxeO5Zmln6PraTtqY62hML+JVT3QCNBS/8F3ZFc/F5n3wx5/B/NO/8dIGybDo8BRHu5KdPQdQ2F/+lNlciaGgr/X0sVsPq4qfmlrNEIti+823jdW8sTzyVVOnPQKXXXwIlghK5O1u7h3nqpUGe3jXE0y8N8syuIXYOjHO07eKtiU7emXqQk3mWBM5w45HsXfceDn/yxqKvubq5vozvoIC6luARpUp/CQpchymrSr//paDS26DSn4FKr78ESgQlunXLDj7xvUcASCVhfesuPtO4hY7kb2gbfQ4AP/zV2AmXwAlvo/GwV9FoBlcUTwRlEfcvYaUthfevz4DMQ4mgRNt2D/JHVY/zxdfsoOV3d2NDO2EkAUefDid8AI4/B2st0DhEX0KpNH0GZB5KBCVat/37XFJ1NTxTB684C064HH7v7OC+7rnoSygiS5wSQYkahl9kiipS//B8cJufiMgyofEISlQ73sNg1UolARFZdpQIStQ41ctI9QJu2xQROUQoEZRgMp1lZXYPk3UxuuVPRGJDiaAEPcMTrLZ+snG691tEYkOJoAQ9e/ppsRGSKzRujogsP0oEJRjoDXrHrmmNvv9+EZFyUyIowVhfkAga2pUIRGT5USIowVT/TgCa2tdWOBIRkYNPiaAE2cFdAFQ16xqBiCw/SgQlSI52kyEB9e2VDkVE5KBTIihBzXg3A8mVpY9IJCJyCNGerQSNk72MVOtoQESWJyWCeWSyTktmD5O16l5CRJYnJYJ59A1PsMr6yTQcVulQREQioUQwj57+IdptEFOrYhFZppQI5tHfEzQmq25RIhCR5UmJYB4j062K29SqWESWJyWCeUyGrYpXrD6qwpGIiERDiWAe2cGXAKhuPrLCkYiIREOJYB6J4d1kMWjQ7aMisjwpEcyjeryHwUQLJKsqHYqISCSUCObRMNnLcEqtikVk+VIimIO705LpY7xOp4VEZPlSIphD/+gUq+gnU69WxSKyfCkRzKF7YJQ2BrAmJQIRWb6UCOawt3cHSXNSLbp1VESWLyWCOYz0dAFQr1bFIrKMKRHMYWJv2KpYYxWLyDKmRDCHTNiquG6ljghEZPmKNBGY2Xoze8bMtpnZJQXmv8zM7jWzh8zsUTM7J8p4FspGdgcTjbpYLCLLV2SJwMySwJeADcBJwIVmdlJetcuAm939FOAC4MtRxbMYNaPdDCaaoaq60qGIiEQmyiOC04Bt7v68u08C3wHOy6vjwIpwuhnYGWE8C1Y32ctQVVulwxARiVSUiWANsD3neVdYlusK4CIz6wI2A39f6IXMbKOZdZpZZ09PTxSxzuLurEj3Ma6xikVkmav0xeILga+6+1rgHOAmM5sVk7vf4O4d7t6xalV5dszDE2na2Uu6fnVZ1iciUilRJoIdQO5oLmvDslzvB24GcPffALXAkujhrXtwjFUMQNPhlQ5FRCRSUSaCB4DjzGydmVUTXAy+I6/O74CzAMzsRIJEUJ5zP/PY0/0SKcuQatZYxSKyvEWWCNw9DVwM3Ak8RXB30BNmdqWZnRtW+zjwATN7BPg28Ffu7lHFtBDDfUGr4rqV6l5CRJa3SEdbcffNBBeBc8suz5l+Ejg9yhgWa7pVcdOql1U4EhGRaFX6YvGSlR4IWhU3tOmIQESWNyWCImxoV/C3SdcIRGR5UyIoIjXWzbA1Qqq20qGIiERKiaCIuoleBtWqWERiQImgiBXpXsZq1KpYRJY/JYICxqcytPlepuqVCERk+VMiKKBncJxV9EOjWhWLyPKnRFBAX99uaixNUq2KRSQGlAgKGOoOOk2tVatiEYkBJYICxqZbFbcfNU9NEZFDnxJBAdOtijVovYjEgRJBAT4YtCpOrNDFYhFZ/pQICkiN7mbU6qCmsdKhiIhETomggFq1KhaRGFEiKKBpqpfR6iUxUJqISOSUCPJMZbK0ZvcyWXdYpUMRESkLJYI8vUPjHGZ78UYlAhGJByWCPL19vdTZJMkValUsIvGgRJBnsCcYq7imVYlAROJBiSDP2J4dADSuUmMyEYkHJYI8U2H3EitWqXsJEYkHJYI8Phy0Kk6p51ERiQklgjxVI92MUw01KyodiohIWSgR5KmZ6GGgqh3MKh2KiEhZKBHkaZrsZUStikUkRpQIcmSzTkt2D5O1GqtYROJDiSDHntFJVtFPtmF1pUMRESkbJYIcPX17aLIxEs0aolJE4kOJIMdgTzBWcU2Lbh0VkfhQIsgx0he0Km5oU6tiEYkPJYIcU/3BWMXNq5UIRCQ+lAhyZAeDRFDTuqbCkYiIlI8SQY7kyG4mSUFda6VDEREpGyWCHDXjPQwkV6pVsYjESqSJwMzWm9kzZrbNzC4pUuddZvakmT1hZt+KMp75NEz2MpLSoPUiEi9VUb2wmSWBLwFvAbqAB8zsDnd/MqfOccClwOnuvtfMKtaSy91pzuxhvO4VlQpBRKQiojwiOA3Y5u7Pu/sk8B3gvLw6HwC+5O57Ady9O8J45jQ4lmY1e8g0aKxiEYmXKBPBGmB7zvOusCzX7wG/Z2b/18zuM7P1hV7IzDaaWaeZdfb09EQSbM/evTTbKIkmJQIRiZdKXyyuAo4D3gRcCPybmbXkV3L3G9y9w907Vq2KpkO4/p6gMVmqRd1LiEi8lJQIzOz7ZvY2M1tI4tgB5I73uDYsy9UF3OHuU+7+/4BnCRJD2Y30BYPW16tVsYjETKk79i8D7wa2mtlVZnZ8Ccs8ABxnZuvMrBq4ALgjr85tBEcDmFk7wami50uM6aCa2BOMVdysQetFJGZKSgTufo+7/yVwKvACcI+Z/drM3mdmqSLLpIGLgTuBp4Cb3f0JM7vSzM4Nq90J9JnZk8C9wCZ37zuwt7Q42cFgrOL6NrUqFpF4Kfn2UTNrAy4C3gM8BHwTOAN4L+Gv+nzuvhnYnFd2ec60Ax8LHxWVGNlNmiRV9RqdTETipaREYGY/AI4HbgL+1N1fCmd918w6owqunKrHuulPtNKeqPT1cxGR8ir1iOBad7+30Ax37ziI8VRMw2QPw6l2dDwgInFT6s/fk3Jv6zSzVjP7UDQhVUZzeg/jtUoDIhI/pSaCD7h7//STsCXwByKJqAJGJ9O0sZdMvRqTiUj8lJoIkmb7u+QM+xGqjiak8uveO0SbDcGKwysdiohI2ZV6jeAnBBeGvxI+/2BYtiz0dweNyVLNGqtYROKn1ETwSYKd/9+Fz+8G/j2SiCpgOGxVXKc2BCISQyUlAnfPAteFj2VnfLpVcftR89QUEVl+Sm1HcBzwOeAkoHa63N1fHlFcZZUJWxU3qXsJEYmhUi8W/yfB0UAaeDPwdeAbUQVVbja8iwwJrLFi4+KIiFRMqYmgzt1/Cpi7v+juVwBviy6s8qoe62Yg0QyJZKVDEREpu1IvFk+EXVBvNbOLCbqTbowurPKqm+hluKqNlZUORESkAko9IvgIUA/8D+C1BJ3PvTeqoMptRbqP0VqdFhKReJr3iCBsPPYX7v4JYBh4X+RRldFEOkO772F3/WsqHYqISEXMe0Tg7hmC7qaXpZ6BEdoYhEZ1LyEi8VTqNYKHzOwO4HvAyHShu38/kqjKaG/PTtaaq1WxiMRWqYmgFugD/jinzIFDPhEM9QStimtXqg2BiMRTqS2Ll9V1gVwTe4JE0NSu7iVEJJ5KbVn8nwRHADO4+18f9IjKbGogaFXcvFrdS4hIPJV6auiHOdO1wDuAnQc/nPKz4d0AJJt0sVhE4qnUU0O35j43s28Dv4okojKrGt1NvzXTUrVshlcQEVmQxY7UfhywLFpg1U/0MFjVVukwREQqptRrBEPMvEawi2CMgkNeU7qPsQaNVSwi8VXqqaGmqAOphEzWac3upa/uxEqHIiJSMSWdGjKzd5hZc87zFjM7P7KoyqRvaIxV9ONNGqtYROKr1GsEn3H3gekn7t4PfCaSiMqor3snVZYluUKtikUkvkpNBIXqlXrr6ZI11LsdgNqVR1Y4EhGRyik1EXSa2TVmdmz4uAZ4MMrAymGsL2gK0dSu7iVEJL5KTQR/D0wC3wW+A4wDH44qqHKZGngJgObVL6twJCIilVPqXUMjwCURx1J+Q0EiqG7WxWIRia9S7xq628xacp63mtmdkUVVJsnRboasEVK1lQ5FRKRiSj011B7eKQSAu+9lGbQsrh3vZSCpVsUiEm+lJoKsme07kW5mx1CgN9JDTdNULyM1alUsIvFW6i2gnwJ+ZWa/AAw4E9gYWVRl4O60Zvewt+7YSociIlJRJR0RuPtPgA7gGeDbwMeBsQjjitzekUna6SfboO6nRSTeSr1Y/DfATwkSwCeAm4ArSlhuvZk9Y2bbzKzoXUdm9mdm5mbWUVrYB663dxc1liapO4ZEJOZKvUbwEeAPgBfd/c3AKUD/XAuYWRL4ErABOAm40MxOKlCvKXz935Ye9oEb7A6GqKxp1RCVIhJvpSaCcXcfBzCzGnd/Gjh+nmVOA7a5+/PuPknQEO28AvX+Efg8QSO1shnrCxJBQ5taFYtIvJWaCLrCdgS3AXeb2e3Ai/MsswbYnvsaYdk+ZnYqcJS7/2iuFzKzjWbWaWadPT09JYY8t8mBoHuJltVKBCISb6W2LH5HOHmFmd0LNAM/OZAVm1kCuAb4qxLWfwNwA0BHR8dBuW3VB4NB6+tW6tSQiMTbgnsQdfdflFh1B3BUzvO1Ydm0JuBVwM/NDOBw4A4zO9fdOxca10IlR7sZpp7G6oaoVyUisqQtdsziUjwAHGdm68ysGrgAuGN6prsPuHu7ux/j7scA9wFlSQIAtWPdDCRXlmNVIiJLWmSJwN3TwMXAncBTwM3u/oSZXWlm50a13lI1TPUxUq1WxSIikQ4u4+6bgc15ZZcXqfumKGPJWxctmT0M1L2mXKsUEVmyojw1tGQNj0+xir1qVSwiQkwTQW9fD3U2SWKFWhWLiMQyEQyErYqrWzRWsYhILBPBSNiquLFdbQhERGKZCCb7gyEqV6w6ap6aIiLLXywTQXYwSAQ6IhARiWkiSA7vZowarGZFpUMREam4WCaC6vEe+pNtEHRtISISa7FMBA2TvQynNGi9iAjENBE0Z/qYqF1V6TBERJaE2CWC8akM7b6XjFoVi4gAMUwEPb17aLRxaDqi0qGIiCwJsUsE/T2/A6C6RYlARARimAhGeoNWxfUamUxEBIhhIpjYG4xVvEJjFYuIADFMBJlwrOLmVS+rcCQiIktD7BKBDe9mghSJ+pZKhyIisiTELhFUj3XTn1ipVsUiIqHYJYL6yR6G1KpYRGSf2CWC5vQexmpXVzoMEZElI1aJYCqTpc33kK5XIhARmRarRNDb30+zjWJN6l5CRGRarBJB/66gMVmqWWMVi4hMi1UiGArHKq5rU6tiEZFpsUoE43t2ALCiXa2KRUSmxSoRZAaCsYpbVmvQehGRabFKBDa8mzRJqhrbKx2KiMiSEatEkBrrZo+thESs3raIyJxitUesm+hVq2IRkTyxSgQr0r2M1ei0kIhIrtgkgkzWWZlVq2IRkXyxSQR7BodZacN44+GVDkVEZEmJRSK47aEdvO9ffwjAfz2f5baHdlQ4IhGRpcPcvdIxLEhHR4d3dnaWXH/8cy+ndqJvdnlNG7WXPn8wQxMRWbLM7EF37yg0L9IjAjNbb2bPmNk2M7ukwPyPmdmTZvaomf3UzI4+2DEUSgJzlYuIxE1kicDMksCXgA3AScCFZnZSXrWHgA53/33gFuALUcUjIiKFRXlEcBqwzd2fd/dJ4DvAebkV3P1edx8Nn94HqBMgEZEyizIRrAG25zzvCsuKeT/w40IzzGyjmXWaWWdPT89BDFFERJbEXUNmdhHQAVxdaL673+DuHe7esWrVqvIGJyKyzEWZCHYAud18rg3LZjCzPwE+BZzr7hMHPYqGIg3IipWLiMRMVYSv/QBwnJmtI0gAFwDvzq1gZqcAXwHWu3t3JFFs2hrJy4qILBeRHRG4exq4GLgTeAq42d2fMLMrzezcsNrVQCPwPTN72MzuiCoeEREpLMojAtx9M7A5r+zynOk/iXL9IiIyv0gTgYjIUjE1NUVXVxfj4+OVDiVStbW1rF27llQqVfIySgQiEgtdXV00NTVxzDHHYGaVDicS7k5fXx9dXV2sW7eu5OWWxO2jIiJRGx8fp62tbdkmAQAzo62tbcFHPUoEIhIbyzkJTFvMe1QiEBGJOSUCEZECbntoB6df9TPWXfIjTr/qZwc8jkl/fz9f/vKXF7zcOeecQ39//wGtez5KBCIieW57aAeXfv8xdvSP4cCO/jEu/f5jB5QMiiWCdDo953KbN2+mpaVl0esthe4aEpHY+ex/PcGTOweLzn/od/1MZrIzysamMvzDLY/y7ft/V3CZk45cwWf+9JVFX/OSSy7hueee4+STTyaVSlFbW0traytPP/00zz77LOeffz7bt29nfHycj3zkI2zcuBGAY445hs7OToaHh9mwYQNnnHEGv/71r1mzZg233347dXV1i9gCM+mIQEQkT34SmK+8FFdddRXHHnssDz/8MFdffTVbtmzhX/7lX3j22WcBuPHGG3nwwQfp7Ozk2muvpa9v9uBZW7du5cMf/jBPPPEELS0t3HrrrYuOJ5eOCEQkdub65Q5w+lU/Y0f/2KzyNS11fPeDrz8oMZx22mkz7vW/9tpr+cEPfgDA9u3b2bp1K21tbTOWWbduHSeffDIAr33ta3nhhRcOSiw6IhARybPp7OOpSyVnlNWlkmw6+/iDto6GhoZ90z//+c+55557+M1vfsMjjzzCKaecUrAtQE1Nzb7pZDI57/WFUumIQEQkz/mnBGNoXX3nM+zsH+PIljo2nX38vvLFaGpqYmhoqOC8gYEBWltbqa+v5+mnn+a+++5b9HoWQ4lARKSA809Zc0A7/nxtbW2cfvrpvOpVr6Kuro7DDjts37z169dz/fXXc+KJJ3L88cfzute97qCttxTm7mVd4YHq6Ojwzs7OSochIoeYp556ihNPPLHSYZRFofdqZg+6e0eh+rpGICISc0oEIiIxp0QgIhJzSgQiIjGnRCAiEnNKBCIiMad2BCIi+a4+Dka6Z5c3rIZNWxf1kv39/XzrW9/iQx/60IKX/eIXv8jGjRupr69f1LrnoyMCEZF8hZLAXOUlWOx4BBAkgtHR0UWvez46IhCR+PnxJbDrscUt+59vK1x++Kthw1VFF8vthvotb3kLq1ev5uabb2ZiYoJ3vOMdfPazn2VkZIR3vetddHV1kclk+PSnP83u3bvZuXMnb37zm2lvb+fee+9dXNxzUCIQESmDq666iscff5yHH36Yu+66i1tuuYX7778fd+fcc8/ll7/8JT09PRx55JH86Ec/AoI+iJqbm7nmmmu49957aW9vjyQ2JQIRiZ85frkDcEVz8Xnv+9EBr/6uu+7irrvu4pRTTgFgeHiYrVu3cuaZZ/Lxj3+cT37yk7z97W/nzDPPPOB1lUKJQESkzNydSy+9lA9+8IOz5m3ZsoXNmzdz2WWXcdZZZ3H55ZdHHo8uFouI5GtYvbDyEuR2Q3322Wdz4403Mjw8DMCOHTvo7u5m586d1NfXc9FFF7Fp0ya2bNkya9ko6IhARCTfIm8RnUtuN9QbNmzg3e9+N69/fTDaWWNjI9/4xjfYtm0bmzZtIpFIkEqluO666wDYuHEj69ev58gjj4zkYrG6oRaRWFA31OqGWkREilAiEBGJOSUCEYmNQ+1U+GIs5j0qEYhILNTW1tLX17esk4G709fXR21t7YKW011DIhILa9eupauri56enkqHEqna2lrWrl27oGWUCEQkFlKpFOvWrat0GEtSpKeGzGy9mT1jZtvM7JIC82vM7Lvh/N+a2TFRxiMiIrNFlgjMLAl8CdgAnARcaGYn5VV7P7DX3V8B/DPw+ajiERGRwqI8IjgN2Obuz7v7JPAd4Ly8OucBXwunbwHOMjOLMCYREckT5TWCNcD2nOddwB8Wq+PuaTMbANqA3txKZrYR2Bg+HTazZxYZU3v+ay8xiu/AKL4Dt9RjVHyLd3SxGYfExWJ3vwG44UBfx8w6izWxXgoU34FRfAduqceo+KIR5amhHcBROc/XhmUF65hZFdAM9EUYk4iI5IkyETwAHGdm68ysGrgAuCOvzh3Ae8PpPwd+5su5tYeIyBIU2amh8Jz/xcCdQBK40d2fMLMrgU53vwP4D+AmM9sG7CFIFlE64NNLEVN8B0bxHbilHqPii8Ah1w21iIgcXOprSEQk5pQIRERiblkmgqXctYWZHWVm95rZk2b2hJl9pECdN5nZgJk9HD6iH7165vpfMLPHwnXPGg7OAteG2+9RMzu1jLEdn7NdHjazQTP7aF6dsm8/M7vRzLrN7PGcspVmdreZbQ3/thZZ9r1hna1m9t5CdSKI7Wozezr8//uBmbUUWXbOz0LEMV5hZjty/h/PKbLsnN/3COP7bk5sL5jZw0WWLcs2PCDuvqweBBemnwNeDlQDjwAn5dX5EHB9OH0B8N0yxncEcGo43QQ8WyC+NwE/rOA2fAFon2P+OcCPAQNeB/y2gv/Xu4CjK739gDcCpwKP55R9AbgknL4E+HyB5VYCz4d/W8Pp1jLE9lagKpz+fKHYSvksRBzjFcAnSvgMzPl9jyq+vPn/G7i8ktvwQB7L8YhgSXdt4e4vufuWcHoIeIqghfWh5Dzg6x64D2gxsyMqEMdZwHPu/mIF1j2Du/+S4M63XLmfs68B5xdY9Gzgbnff4+57gbuB9VHH5u53uXs6fHofQTufiimy/UpRyvf9gM0VX7jveBfw7YO93nJZjomgUNcW+TvaGV1bANNdW5RVeErqFOC3BWa/3sweMbMfm9kryxsZDtxlZg+G3XvkK2Ubl8MFFP/yVXL7TTvM3V8Kp3cBhxWosxS25V8THOEVMt9nIWoXh6evbixyam0pbL8zgd3uvrXI/Epvw3ktx0RwSDCzRuBW4KPuPpg3ewvB6Y7XAP8HuK3M4Z3h7qcS9Bz7YTN7Y5nXP6+wkeK5wPcKzK709pvFg3MES+5ebTP7FJAGvlmkSiU/C9cBxwInAy8RnH5Zii5k7qOBJf99Wo6JYMl3bWFmKYIk8E13/37+fHcfdPfhcHozkDKz9nLF5+47wr/dwA8IDr9zlbKNo7YB2OLuu/NnVHr75dg9fcos/NtdoE7FtqWZ/RXwduAvw0Q1Swmfhci4+253z7h7Fvi3Iuuu6Gcx3H+8E/husTqV3IalWo6JYEl3bRGeT/wP4Cl3v6ZIncOnr1mY2WkE/09lSVRm1mBmTdPTBBcVH8+rdgfw38O7h14HDOScAimXor/CKrn98uR+zt4L3F6gzp3AW82sNTz18dawLFJmth74B+Bcdx8tUqeUz0KUMeZed3pHkXWX8n2P0p8AT7t7V6GZld6GJav01eooHgR3tTxLcDfBp8KyKwk+9AC1BKcUtgH3Ay8vY2xnEJwieBR4OHycA/wt8LdhnYuBJwjugLgPeEMZ43t5uN5Hwhimt19ufEYw6NBzwGNAR5n/fxsIduzNOWUV3X4ESeklYIrgPPX7Ca47/RTYCtwDrAzrdgD/nrPsX4efxW3A+8oU2zaCc+vTn8Hpu+iOBDbP9Vko4/a7Kfx8PUqwcz8iP8bw+azvezniC8u/Ov25y6lbkW14IA91MSEiEnPL8dSQiIgsgBKBiEjMKRGIiMScEoGISMwpEYiIxJwSgUjEwt5Qf1jpOESKUSIQEYk5JQKRkJldZGb3h/3Gf8XMkmY2bGb/bMHYET81s1Vh3ZPN7L6c/vxbw/JXmNk9YYd3W8zs2PDlG83slnAMgG/mtHy+yoKxKR41s/9VobcuMadEIAKY2YnAXwCnu/vJQAb4S4JWzJ3u/krgF8BnwkW+DnzS3X+foPXrdPk3gS950OHdGwhao0LQy+xHgZMIWpuebmZtBF0nvDJ8nX+K8j2KFKNEIBI4C3gt8EA40tRZBDvsLPs7FPsGcIaZNQMt7v6LsPxrwBvDPmXWuPsPANx93Pf343O/u3d50IHaw8AxBN2fjwP/YWbvBAr2+SMSNSUCkYABX3P3k8PH8e5+RYF6i+2TZSJnOkMwOliaoCfKWwh6Af3JIl9b5IAoEYgEfgr8uZmthn3jDR9N8B3587DOu4FfufsAsNfMzgzL3wP8woMR57rM7PzwNWrMrL7YCsMxKZo96Cr7fwKvieB9icyrqtIBiCwF7v6kmV1GMJJUgqCXyQ8DI8Bp4bxugusIEHQrfX24o38eeF9Y/h7gK2Z2Zfga/22O1TYBt5tZLcERyccO8tsSKYl6HxWZg5kNu3tjpeMQiZJODYmIxJyOCEREYk5HBCIiMadEICISc0oEIiIxp0QgIhJzSgQiIjH3/wFo8WYu9/58mAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매개변수 보존\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize_filter.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from simple_convnet import SimpleConvNet\n",
    "\n",
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    \"\"\"\n",
    "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
    "    \"\"\"\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "network = SimpleConvNet()\n",
    "# 무작위(랜덤) 초기화 후의 가중치\n",
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습된 가중치\n",
    "network.load_params(\"params.pkl\")\n",
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradient_check.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 2.3920474403782107e-06\n",
      "b1 7.367634547064133e-06\n",
      "W2 6.017621803661483e-11\n",
      "b2 5.835550886338757e-09\n",
      "W3 2.602480436929538e-10\n",
      "b3 1.7991343141815497e-07\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import numpy as np\n",
    "#from simple_convnet import SimpleConvNet\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,10, 10), \n",
    "                        conv_param = {'filter_num':10, 'filter_size':3, 'pad':0, 'stride':1},\n",
    "                        hidden_size=10, output_size=10, weight_init_std=0.01)\n",
    "\n",
    "X = np.random.rand(100).reshape((1, 1, 10, 10))\n",
    "T = np.array([1]).reshape((1,1))\n",
    "\n",
    "grad_num = network.numerical_gradient(X, T)\n",
    "grad = network.gradient(X, T)\n",
    "\n",
    "for key, val in grad_num.items():\n",
    "    print(key, np.abs(grad_num[key] - grad[key]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# apply_filter.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from simple_convnet import SimpleConvNet\n",
    "from matplotlib.image import imread\n",
    "from common.layers import Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_show(filters, nx=4, show_num=16):\n",
    "    \"\"\"\n",
    "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
    "    \"\"\"\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(show_num / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(show_num):\n",
    "        ax = fig.add_subplot(4, 4, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "\n",
    "# 학습된 가중치\n",
    "network.load_params(\"params.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter_show(network.params['W1'], 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-18bf94a1d3e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#b = b.reshape(1, *b.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mconv_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HomeWorkspace/git/DL-scratch1/common/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mFN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0mout_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mFH\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mout_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mFW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#img = imread('./dataset/lena_gray.png')\n",
    "img = imread('./dataset/lena_gray.png')\n",
    "img = img.reshape(1, 1, *img.shape)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "w_idx = 1\n",
    "\n",
    "for i in range(16):\n",
    "    w = network.params['W1'][i]\n",
    "    b = 0  # network.params['b1'][i]\n",
    "\n",
    "    w = w.reshape(1, *w.shape)\n",
    "    #b = b.reshape(1, *b.shape)\n",
    "    conv_layer = Convolution(w, b) \n",
    "    out = conv_layer.forward(img)\n",
    "    out = out.reshape(out.shape[2], out.shape[3])\n",
    "    \n",
    "    ax = fig.add_subplot(4, 4, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(out, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
